Have loaded the data, total training seqs : 36160
begin the training process
begin epoch : 1
nll_loss: 26.670721314016696
begin epoch : 2
nll_loss: 21.664607053098425
begin epoch : 3
nll_loss: 20.97821149235278
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.671497125541215
begin epoch : 5
nll_loss: 20.612887127631534
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2898
begin the training process
begin epoch : 1
nll_loss: 41.06493869357639
begin epoch : 2
nll_loss: 32.77536095513238
begin epoch : 3
nll_loss: 29.605795033772786
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.53414200676812
begin epoch : 5
nll_loss: 28.268682607014973
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 39656
begin the training process
begin epoch : 1
nll_loss: 25.616793258124677
begin epoch : 2
nll_loss: 20.731226636057716
begin epoch : 3
nll_loss: 20.169760428260716
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.8901612492871
begin epoch : 5
nll_loss: 19.83854128355356
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 13122
begin the training process
begin epoch : 1
nll_loss: 30.279165314465033
begin epoch : 2
nll_loss: 23.258619382904797
begin epoch : 3
nll_loss: 21.264158881582865
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.58744436124476
begin epoch : 5
nll_loss: 20.46271407894972
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 467
begin the training process
begin epoch : 1
nll_loss: 47.062137603759766
begin epoch : 2
nll_loss: 44.532127380371094
begin epoch : 3
nll_loss: 41.24857221330915
The learning rate has beed reduced
begin epoch : 4
nll_loss: 39.37446539742606
begin epoch : 5
nll_loss: 38.88984734671457
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1578
begin the training process
begin epoch : 1
nll_loss: 45.27864138285319
begin epoch : 2
nll_loss: 37.37363529205322
begin epoch : 3
nll_loss: 33.15014537175497
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.225943168004353
begin epoch : 5
nll_loss: 30.702834447224934
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 560719
begin the training process
begin epoch : 1
nll_loss: 22.220825253658514
begin epoch : 2
nll_loss: 20.60459560951187
begin epoch : 3
nll_loss: 20.086912689191568
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.642487321184618
begin epoch : 5
nll_loss: 19.554144794545536
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9724
begin the training process
begin epoch : 1
nll_loss: 33.29802607858418
begin epoch : 2
nll_loss: 25.736727506119685
begin epoch : 3
nll_loss: 23.324052191727997
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.505758626571556
begin epoch : 5
nll_loss: 22.334489291866884
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 45361
begin the training process
begin epoch : 1
nll_loss: 25.92440983131107
begin epoch : 2
nll_loss: 21.254009642843474
begin epoch : 3
nll_loss: 20.64128610104491
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.364619387071684
begin epoch : 5
nll_loss: 20.31664287976626
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 35457
begin the training process
begin epoch : 1
nll_loss: 24.92545884610944
begin epoch : 2
nll_loss: 19.841727573518718
begin epoch : 3
nll_loss: 19.355601307287113
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.148940905767226
begin epoch : 5
nll_loss: 19.10903999521414
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6997
begin the training process
begin epoch : 1
nll_loss: 34.06326425184897
begin epoch : 2
nll_loss: 25.88158967954303
begin epoch : 3
nll_loss: 23.462097640431256
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.329980010286384
begin epoch : 5
nll_loss: 22.027882899713077
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12563
begin the training process
begin epoch : 1
nll_loss: 30.462091815714935
begin epoch : 2
nll_loss: 23.148584142023203
begin epoch : 3
nll_loss: 21.296017753834626
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.65340789483518
begin epoch : 5
nll_loss: 20.52655824349851
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1229
begin the training process
begin epoch : 1
nll_loss: 44.63451726813065
begin epoch : 2
nll_loss: 37.851103130139805
begin epoch : 3
nll_loss: 34.09204703883121
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.312858179995885
begin epoch : 5
nll_loss: 31.73030702691329
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 434340
begin the training process
begin epoch : 1
nll_loss: 21.668057782369626
begin epoch : 2
nll_loss: 19.13585364737765
begin epoch : 3
nll_loss: 18.460587948007355
The learning rate has beed reduced
begin epoch : 4
nll_loss: 17.91082224942856
begin epoch : 5
nll_loss: 17.80245995416144
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1786
begin the training process
begin epoch : 1
nll_loss: 43.61260703757957
begin epoch : 2
nll_loss: 35.1055864404749
begin epoch : 3
nll_loss: 31.326500009607386
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.39385760271991
begin epoch : 5
nll_loss: 28.928835409658927
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6976
begin the training process
begin epoch : 1
nll_loss: 34.26190539018823
begin epoch : 2
nll_loss: 25.671919936433845
begin epoch : 3
nll_loss: 23.18441030519818
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.21424914718768
begin epoch : 5
nll_loss: 21.95676651350949
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6172
begin the training process
begin epoch : 1
nll_loss: 34.942727545897164
begin epoch : 2
nll_loss: 25.593062162399292
begin epoch : 3
nll_loss: 23.353247384230297
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.40688894192378
begin epoch : 5
nll_loss: 22.15539187192917
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2554
begin the training process
begin epoch : 1
nll_loss: 41.94057934100811
begin epoch : 2
nll_loss: 33.413474596463715
begin epoch : 3
nll_loss: 29.107129268157177
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.93188902047964
begin epoch : 5
nll_loss: 27.62522467588767
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9565
begin the training process
begin epoch : 1
nll_loss: 34.176264743676924
begin epoch : 2
nll_loss: 27.145627156200025
begin epoch : 3
nll_loss: 24.984078042459167
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.997747830896568
begin epoch : 5
nll_loss: 23.70974241167107
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 45771
begin the training process
begin epoch : 1
nll_loss: 26.3882186569534
begin epoch : 2
nll_loss: 21.914161351343967
begin epoch : 3
nll_loss: 21.367047794048602
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.107984369451348
begin epoch : 5
nll_loss: 21.05796540533746
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1424
begin the training process
begin epoch : 1
nll_loss: 45.832277124578304
begin epoch : 2
nll_loss: 38.449322960593484
begin epoch : 3
nll_loss: 34.55699209733443
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.767497929659754
begin epoch : 5
nll_loss: 32.31940252130682
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4944
begin the training process
begin epoch : 1
nll_loss: 37.634038652692524
begin epoch : 2
nll_loss: 28.940491614403662
begin epoch : 3
nll_loss: 26.24561463393174
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.128083935031643
begin epoch : 5
nll_loss: 24.850370109855355
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 25732
begin the training process
begin epoch : 1
nll_loss: 28.20354963653716
begin epoch : 2
nll_loss: 22.196948321897594
begin epoch : 3
nll_loss: 20.773514908937674
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.99416493183345
begin epoch : 5
nll_loss: 19.77150649929521
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 123734
begin the training process
begin epoch : 1
nll_loss: 23.58652236531944
begin epoch : 2
nll_loss: 20.82458579867107
begin epoch : 3
nll_loss: 19.76778735315251
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.021315431076815
begin epoch : 5
nll_loss: 18.83752921647626
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2371
begin the training process
begin epoch : 1
nll_loss: 42.68351096075934
begin epoch : 2
nll_loss: 34.79486058209393
begin epoch : 3
nll_loss: 30.887268117956214
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.48007160908467
begin epoch : 5
nll_loss: 29.173606047759186
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2617
begin the training process
begin epoch : 1
nll_loss: 40.6786548614502
begin epoch : 2
nll_loss: 33.06622829437256
begin epoch : 3
nll_loss: 29.466707944869995
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.290953636169434
begin epoch : 5
nll_loss: 28.037908935546874
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 841
begin the training process
begin epoch : 1
nll_loss: 46.462806701660156
begin epoch : 2
nll_loss: 41.341075310340294
begin epoch : 3
nll_loss: 37.516013805682846
The learning rate has beed reduced
begin epoch : 4
nll_loss: 35.91171470055213
begin epoch : 5
nll_loss: 35.38490236722506
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4112
begin the training process
begin epoch : 1
nll_loss: 38.2183612883091
begin epoch : 2
nll_loss: 28.4690280854702
begin epoch : 3
nll_loss: 25.41599202156067
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.39276885986328
begin epoch : 5
nll_loss: 24.09131169319153
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2531
begin the training process
begin epoch : 1
nll_loss: 42.13531699547401
begin epoch : 2
nll_loss: 34.123360756116035
begin epoch : 3
nll_loss: 30.70182164510091
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.554212276752178
begin epoch : 5
nll_loss: 29.295734014266575
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 38670
begin the training process
begin epoch : 1
nll_loss: 26.460026043140335
begin epoch : 2
nll_loss: 21.455717443630395
begin epoch : 3
nll_loss: 20.805099098887666
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.507847350164756
begin epoch : 5
nll_loss: 20.450895899968433
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3042
begin the training process
begin epoch : 1
nll_loss: 39.894335401819106
begin epoch : 2
nll_loss: 31.28093573387633
begin epoch : 3
nll_loss: 27.83348716573512
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.796522181084814
begin epoch : 5
nll_loss: 26.499416067245157
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2267
begin the training process
begin epoch : 1
nll_loss: 42.79145366123745
begin epoch : 2
nll_loss: 34.805116762433734
begin epoch : 3
nll_loss: 30.928495952061244
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.52240447998047
begin epoch : 5
nll_loss: 29.150726209368024
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6417
begin the training process
begin epoch : 1
nll_loss: 34.81612365722656
begin epoch : 2
nll_loss: 25.802458934783935
begin epoch : 3
nll_loss: 23.543911037445067
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.536954040527345
begin epoch : 5
nll_loss: 22.248430519104005
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 11046
begin the training process
begin epoch : 1
nll_loss: 31.669900073561557
begin epoch : 2
nll_loss: 23.72416627129843
begin epoch : 3
nll_loss: 21.401557290276816
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.709785794102867
begin epoch : 5
nll_loss: 20.577851350917374
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1327
begin the training process
begin epoch : 1
nll_loss: 44.85812263488769
begin epoch : 2
nll_loss: 38.744923782348636
begin epoch : 3
nll_loss: 34.884538078308104
The learning rate has beed reduced
begin epoch : 4
nll_loss: 33.02596817016602
begin epoch : 5
nll_loss: 32.532584476470944
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3167
begin the training process
begin epoch : 1
nll_loss: 39.35712767620476
begin epoch : 2
nll_loss: 29.66894363870426
begin epoch : 3
nll_loss: 26.102180169553172
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.057694221029475
begin epoch : 5
nll_loss: 24.753928943556183
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 19558
begin the training process
begin epoch : 1
nll_loss: 28.454161922267225
begin epoch : 2
nll_loss: 22.125451460040985
begin epoch : 3
nll_loss: 20.698808857652008
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.225271468866065
begin epoch : 5
nll_loss: 20.128005356085104
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10283
begin the training process
begin epoch : 1
nll_loss: 31.583113491535187
begin epoch : 2
nll_loss: 24.067029666900634
begin epoch : 3
nll_loss: 21.772679209709167
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.00443192720413
begin epoch : 5
nll_loss: 20.837598860263824
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 37534
begin the training process
begin epoch : 1
nll_loss: 25.1473434077188
begin epoch : 2
nll_loss: 20.29911311413241
begin epoch : 3
nll_loss: 19.795876821967116
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.572058485636532
begin epoch : 5
nll_loss: 19.5322358616383
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1247
begin the training process
begin epoch : 1
nll_loss: 44.80578051115337
begin epoch : 2
nll_loss: 37.4961774725663
begin epoch : 3
nll_loss: 33.00455043190404
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.92927270186575
begin epoch : 5
nll_loss: 30.279281013890316
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 30316
begin the training process
begin epoch : 1
nll_loss: 27.72375417713383
begin epoch : 2
nll_loss: 22.406753544071513
begin epoch : 3
nll_loss: 21.3708303020066
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.992312005912023
begin epoch : 5
nll_loss: 20.915187428415955
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 441
begin the training process
begin epoch : 1
nll_loss: 47.00008328755697
begin epoch : 2
nll_loss: 45.40489260355631
begin epoch : 3
nll_loss: 42.38106218973795
The learning rate has beed reduced
begin epoch : 4
nll_loss: 40.70872243245443
begin epoch : 5
nll_loss: 40.092929204305015
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4688
begin the training process
begin epoch : 1
nll_loss: 38.95310903575322
begin epoch : 2
nll_loss: 30.267271538303323
begin epoch : 3
nll_loss: 27.755559895136585
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.76829792702035
begin epoch : 5
nll_loss: 26.448624832989417
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6764
begin the training process
begin epoch : 1
nll_loss: 34.733661742437455
begin epoch : 2
nll_loss: 26.346030080886113
begin epoch : 3
nll_loss: 24.199251411074684
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.320901452927362
begin epoch : 5
nll_loss: 23.107388596307665
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5403
begin the training process
begin epoch : 1
nll_loss: 35.73519243512835
begin epoch : 2
nll_loss: 26.857580071403866
begin epoch : 3
nll_loss: 24.6193452108474
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.766018231709797
begin epoch : 5
nll_loss: 23.53134130296253
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 108587
begin the training process
begin epoch : 1
nll_loss: 21.746618390083313
begin epoch : 2
nll_loss: 19.603864086124133
begin epoch : 3
nll_loss: 19.442769061844302
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.305712432231545
begin epoch : 5
nll_loss: 19.282420897258902
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1781
begin the training process
begin epoch : 1
nll_loss: 43.225434903745295
begin epoch : 2
nll_loss: 35.546325824878835
begin epoch : 3
nll_loss: 31.91617817348904
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.536708125361688
begin epoch : 5
nll_loss: 30.171339953387225
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1698
begin the training process
begin epoch : 1
nll_loss: 44.30696854224572
begin epoch : 2
nll_loss: 36.392851902888374
begin epoch : 3
nll_loss: 32.67076022808369
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.783725151648888
begin epoch : 5
nll_loss: 30.235038243807278
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1853
begin the training process
begin epoch : 1
nll_loss: 43.63734286172049
begin epoch : 2
nll_loss: 36.19245965140207
begin epoch : 3
nll_loss: 31.524854728153773
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.759369373321533
begin epoch : 5
nll_loss: 29.308839184897288
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3701
begin the training process
begin epoch : 1
nll_loss: 38.875785760712205
begin epoch : 2
nll_loss: 29.913064688966987
begin epoch : 3
nll_loss: 26.980995613231993
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.8490795001649
begin epoch : 5
nll_loss: 25.532347528558027
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 51161
begin the training process
begin epoch : 1
nll_loss: 23.983931091461372
begin epoch : 2
nll_loss: 20.19535382668277
begin epoch : 3
nll_loss: 19.79577366968568
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.561392226714513
begin epoch : 5
nll_loss: 19.512563643377923
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1725
begin the training process
begin epoch : 1
nll_loss: 43.98072169377254
begin epoch : 2
nll_loss: 36.41376744783842
begin epoch : 3
nll_loss: 32.945555686950684
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.424930279071514
begin epoch : 5
nll_loss: 31.089209996736965
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 57200
begin the training process
begin epoch : 1
nll_loss: 25.026807174170003
begin epoch : 2
nll_loss: 21.064877649971514
begin epoch : 3
nll_loss: 20.62665624928234
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.39572624129651
begin epoch : 5
nll_loss: 20.3544593161725
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1355
begin the training process
begin epoch : 1
nll_loss: 45.00749914986746
begin epoch : 2
nll_loss: 38.35375213623047
begin epoch : 3
nll_loss: 34.296523139590306
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.457686288016184
begin epoch : 5
nll_loss: 31.931644076392764
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2788
begin the training process
begin epoch : 1
nll_loss: 41.51967886991279
begin epoch : 2
nll_loss: 33.508486548135444
begin epoch : 3
nll_loss: 30.35561109143634
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.20966219347577
begin epoch : 5
nll_loss: 28.85962765715843
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2817
begin the training process
begin epoch : 1
nll_loss: 40.14202750812877
begin epoch : 2
nll_loss: 31.32090321454135
begin epoch : 3
nll_loss: 27.615202513608065
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.41588120027022
begin epoch : 5
nll_loss: 26.142998478629373
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7846
begin the training process
begin epoch : 1
nll_loss: 35.05568479319088
begin epoch : 2
nll_loss: 27.040005058538718
begin epoch : 3
nll_loss: 24.85696769151531
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.97327277699455
begin epoch : 5
nll_loss: 23.76023919465112
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3237
begin the training process
begin epoch : 1
nll_loss: 41.27626815795898
begin epoch : 2
nll_loss: 32.4311994934082
begin epoch : 3
nll_loss: 29.28528144836426
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.176877517700195
begin epoch : 5
nll_loss: 27.896966171264648
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2545
begin the training process
begin epoch : 1
nll_loss: 42.341304779052734
begin epoch : 2
nll_loss: 33.49883764218061
begin epoch : 3
nll_loss: 29.86505107390575
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.69457958906125
begin epoch : 5
nll_loss: 28.47723569625463
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 59186
begin the training process
begin epoch : 1
nll_loss: 24.601115063671426
begin epoch : 2
nll_loss: 20.859408013232343
begin epoch : 3
nll_loss: 20.430522295303675
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.205870696476527
begin epoch : 5
nll_loss: 20.16597400392805
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 97332
begin the training process
begin epoch : 1
nll_loss: 23.378848198840494
begin epoch : 2
nll_loss: 20.881813571327612
begin epoch : 3
nll_loss: 20.55940309198279
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.313618809298465
begin epoch : 5
nll_loss: 20.257507098348515
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 795293
begin the training process
begin epoch : 1
nll_loss: 21.293742607051616
begin epoch : 2
nll_loss: 20.73285088277412
begin epoch : 3
nll_loss: 20.623139362221618
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.47425266411998
begin epoch : 5
nll_loss: 20.44447916332658
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 204832
begin the training process
begin epoch : 1
nll_loss: 22.476892347335816
begin epoch : 2
nll_loss: 21.03546376645565
begin epoch : 3
nll_loss: 20.835096297264098
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.627307693362237
begin epoch : 5
nll_loss: 20.58013433277607
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2482
begin the training process
begin epoch : 1
nll_loss: 42.831295916908665
begin epoch : 2
nll_loss: 34.43607671637284
begin epoch : 3
nll_loss: 30.87742584630063
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.637777428877982
begin epoch : 5
nll_loss: 29.29069463830245
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1599
begin the training process
begin epoch : 1
nll_loss: 44.038830598195396
begin epoch : 2
nll_loss: 36.10067415237427
begin epoch : 3
nll_loss: 31.962048530578613
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.91320792833964
begin epoch : 5
nll_loss: 29.2671955426534
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 63006
begin the training process
begin epoch : 1
nll_loss: 24.642538123014496
begin epoch : 2
nll_loss: 21.08508818324019
begin epoch : 3
nll_loss: 20.081884186442306
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.31279577666182
begin epoch : 5
nll_loss: 19.097491184870403
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5041
begin the training process
begin epoch : 1
nll_loss: 36.55986350621932
begin epoch : 2
nll_loss: 28.210102497003017
begin epoch : 3
nll_loss: 25.576732073074734
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.281818732237205
begin epoch : 5
nll_loss: 23.901354691921135
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2406
begin the training process
begin epoch : 1
nll_loss: 42.659854992015944
begin epoch : 2
nll_loss: 34.27901499980205
begin epoch : 3
nll_loss: 30.273671639932168
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.856814822635137
begin epoch : 5
nll_loss: 28.61691717199377
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 927
begin the training process
begin epoch : 1
nll_loss: 45.46755599975586
begin epoch : 2
nll_loss: 39.59481348310198
begin epoch : 3
nll_loss: 35.77365739004953
The learning rate has beed reduced
begin epoch : 4
nll_loss: 34.086968830653596
begin epoch : 5
nll_loss: 33.561750411987305
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 14751
begin the training process
begin epoch : 1
nll_loss: 29.60801175158957
begin epoch : 2
nll_loss: 22.825821594569994
begin epoch : 3
nll_loss: 21.20779036646304
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.620891388602878
begin epoch : 5
nll_loss: 20.500668077883514
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 13919
begin the training process
begin epoch : 1
nll_loss: 30.084471012590118
begin epoch : 2
nll_loss: 22.928496998026624
begin epoch : 3
nll_loss: 21.58893013879451
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.08410101332423
begin epoch : 5
nll_loss: 20.96743499298799
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 13013
begin the training process
begin epoch : 1
nll_loss: 30.60169015142131
begin epoch : 2
nll_loss: 23.029049774696087
begin epoch : 3
nll_loss: 21.281966571150154
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.696661314940805
begin epoch : 5
nll_loss: 20.57906517254308
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3334
begin the training process
begin epoch : 1
nll_loss: 40.81552762251634
begin epoch : 2
nll_loss: 31.995968488546517
begin epoch : 3
nll_loss: 28.965758580427902
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.0450559762808
begin epoch : 5
nll_loss: 27.791918094341572
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3632
begin the training process
begin epoch : 1
nll_loss: 39.2789534841265
begin epoch : 2
nll_loss: 30.965808119092667
begin epoch : 3
nll_loss: 28.360469307218278
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.40121909550258
begin epoch : 5
nll_loss: 27.12521161351885
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 16059
begin the training process
begin epoch : 1
nll_loss: 29.696001953125
begin epoch : 2
nll_loss: 22.583483673095703
begin epoch : 3
nll_loss: 20.86890948486328
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.44406866455078
begin epoch : 5
nll_loss: 20.363185195922853
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9759
begin the training process
begin epoch : 1
nll_loss: 32.35115966043974
begin epoch : 2
nll_loss: 24.902489549235295
begin epoch : 3
nll_loss: 22.43444514274597
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.351965628172223
begin epoch : 5
nll_loss: 21.12379382785998
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 67080
begin the training process
begin epoch : 1
nll_loss: 24.8392577280525
begin epoch : 2
nll_loss: 20.944525241851807
begin epoch : 3
nll_loss: 20.59211260125837
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.38537028181644
begin epoch : 5
nll_loss: 20.348677120135942
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7160
begin the training process
begin epoch : 1
nll_loss: 34.317000810090484
begin epoch : 2
nll_loss: 25.709262177750873
begin epoch : 3
nll_loss: 23.348315213177656
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.25175500130868
begin epoch : 5
nll_loss: 21.999521032109993
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 69046
begin the training process
begin epoch : 1
nll_loss: 24.337584693710525
begin epoch : 2
nll_loss: 20.743231228419713
begin epoch : 3
nll_loss: 20.37014746621721
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.162840705192156
begin epoch : 5
nll_loss: 20.127101947734882
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 22440
begin the training process
begin epoch : 1
nll_loss: 29.874448977879116
begin epoch : 2
nll_loss: 23.673603597368512
begin epoch : 3
nll_loss: 22.307112682887485
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.831966078622
begin epoch : 5
nll_loss: 21.731865441458567
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1529
begin the training process
begin epoch : 1
nll_loss: 44.78689724466075
begin epoch : 2
nll_loss: 37.40065068783967
begin epoch : 3
nll_loss: 33.77587243785029
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.099745128465734
begin epoch : 5
nll_loss: 31.607256433238152
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4491
begin the training process
begin epoch : 1
nll_loss: 36.757335908072335
begin epoch : 2
nll_loss: 27.44170355115618
begin epoch : 3
nll_loss: 24.952097402300154
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.875967488970076
begin epoch : 5
nll_loss: 23.531824220929828
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 182965
begin the training process
begin epoch : 1
nll_loss: 21.89409157811052
begin epoch : 2
nll_loss: 20.38120499951928
begin epoch : 3
nll_loss: 20.2224775845559
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.056428506209183
begin epoch : 5
nll_loss: 20.024049862353763
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3499
begin the training process
begin epoch : 1
nll_loss: 40.45897067034686
begin epoch : 2
nll_loss: 31.13113170199924
begin epoch : 3
nll_loss: 27.853460594459815
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.782738403037744
begin epoch : 5
nll_loss: 26.45012127911603
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1094
begin the training process
begin epoch : 1
nll_loss: 46.32204930922564
begin epoch : 2
nll_loss: 39.868289947509766
begin epoch : 3
nll_loss: 36.268254223991846
The learning rate has beed reduced
begin epoch : 4
nll_loss: 34.47904833625345
begin epoch : 5
nll_loss: 34.034183502197266
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1982
begin the training process
begin epoch : 1
nll_loss: 43.528839874267575
begin epoch : 2
nll_loss: 35.26162083943685
begin epoch : 3
nll_loss: 31.128012911478677
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.37840569814046
begin epoch : 5
nll_loss: 29.032166481018066
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6547
begin the training process
begin epoch : 1
nll_loss: 36.1293015386544
begin epoch : 2
nll_loss: 27.51226589726467
begin epoch : 3
nll_loss: 25.11187519746668
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.101014193366556
begin epoch : 5
nll_loss: 23.827299585529403
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 16466
begin the training process
begin epoch : 1
nll_loss: 30.793309690423513
begin epoch : 2
nll_loss: 22.421696696299986
begin epoch : 3
nll_loss: 18.1125282480559
The learning rate has beed reduced
begin epoch : 4
nll_loss: 15.941380326386092
begin epoch : 5
nll_loss: 15.427927250992
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4923
begin the training process
begin epoch : 1
nll_loss: 38.62206388774671
begin epoch : 2
nll_loss: 29.732615044242458
begin epoch : 3
nll_loss: 27.427938310723555
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.283815910941676
begin epoch : 5
nll_loss: 25.953950656087773
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6812
begin the training process
begin epoch : 1
nll_loss: 34.199267081494604
begin epoch : 2
nll_loss: 26.077766472438597
begin epoch : 3
nll_loss: 23.762790769900917
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.820185607334352
begin epoch : 5
nll_loss: 22.599689429661012
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 902
begin the training process
begin epoch : 1
nll_loss: 46.132452556065154
begin epoch : 2
nll_loss: 40.34441239493234
begin epoch : 3
nll_loss: 36.041633878435405
The learning rate has beed reduced
begin epoch : 4
nll_loss: 34.23684174673898
begin epoch : 5
nll_loss: 33.658831460135325
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2460
begin the training process
begin epoch : 1
nll_loss: 42.67151390878778
begin epoch : 2
nll_loss: 34.412153695759024
begin epoch : 3
nll_loss: 30.83272005382337
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.562802917078923
begin epoch : 5
nll_loss: 29.248676049081904
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 13718
begin the training process
begin epoch : 1
nll_loss: 29.948614093744865
begin epoch : 2
nll_loss: 23.053408382094908
begin epoch : 3
nll_loss: 21.625205993652344
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.11967061836029
begin epoch : 5
nll_loss: 21.01041848191591
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3114
begin the training process
begin epoch : 1
nll_loss: 41.373612801233925
begin epoch : 2
nll_loss: 32.30441725254059
begin epoch : 3
nll_loss: 29.210750381151836
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.231495181719463
begin epoch : 5
nll_loss: 27.861878951390583
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1191
begin the training process
begin epoch : 1
nll_loss: 44.60074806213379
begin epoch : 2
nll_loss: 36.999912897745766
begin epoch : 3
nll_loss: 33.42841921912299
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.70195992787679
begin epoch : 5
nll_loss: 31.305154694451225
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9833
begin the training process
begin epoch : 1
nll_loss: 31.670864952935112
begin epoch : 2
nll_loss: 24.325542462417502
begin epoch : 3
nll_loss: 22.71374965493196
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.0469721251843
begin epoch : 5
nll_loss: 21.87464741476221
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5879
begin the training process
begin epoch : 1
nll_loss: 36.72361271197979
begin epoch : 2
nll_loss: 27.846111968323424
begin epoch : 3
nll_loss: 25.43058554680793
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.553374217106747
begin epoch : 5
nll_loss: 24.3263005895929
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 784
begin the training process
begin epoch : 1
nll_loss: 46.244869232177734
begin epoch : 2
nll_loss: 40.91918023427328
begin epoch : 3
nll_loss: 37.37762419382731
The learning rate has beed reduced
begin epoch : 4
nll_loss: 35.903233210245766
begin epoch : 5
nll_loss: 35.42604923248291
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4963
begin the training process
begin epoch : 1
nll_loss: 36.492330575918224
begin epoch : 2
nll_loss: 27.321941895918414
begin epoch : 3
nll_loss: 24.780980617969067
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.852884193519493
begin epoch : 5
nll_loss: 23.589822149896
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 16012
begin the training process
begin epoch : 1
nll_loss: 30.87926293182373
begin epoch : 2
nll_loss: 24.29579030609131
begin epoch : 3
nll_loss: 22.51239762878418
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.849926261901857
begin epoch : 5
nll_loss: 21.704965927124025
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2645
begin the training process
begin epoch : 1
nll_loss: 42.796023299054404
begin epoch : 2
nll_loss: 34.02643785244081
begin epoch : 3
nll_loss: 29.94553980013219
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.70673821612102
begin epoch : 5
nll_loss: 28.36871677491723
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4521
begin the training process
begin epoch : 1
nll_loss: 38.50086612701416
begin epoch : 2
nll_loss: 29.16574380057199
begin epoch : 3
nll_loss: 26.679900523594448
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.58522022792271
begin epoch : 5
nll_loss: 25.31386492592948
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5241
begin the training process
begin epoch : 1
nll_loss: 35.79695958267023
begin epoch : 2
nll_loss: 26.637906204035254
begin epoch : 3
nll_loss: 24.290691399279936
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.30926129847397
begin epoch : 5
nll_loss: 23.088840861379364
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 56140
begin the training process
begin epoch : 1
nll_loss: 24.777478967316473
begin epoch : 2
nll_loss: 20.910658065378325
begin epoch : 3
nll_loss: 20.467407430998957
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.236313081521672
begin epoch : 5
nll_loss: 20.193687145359295
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 473043
begin the training process
begin epoch : 1
nll_loss: 21.45339564918391
begin epoch : 2
nll_loss: 20.71546550668668
begin epoch : 3
nll_loss: 20.612629525668886
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.472109399650243
begin epoch : 5
nll_loss: 20.44566640259045
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1114
begin the training process
begin epoch : 1
nll_loss: 44.53218527401195
begin epoch : 2
nll_loss: 38.553012399112475
begin epoch : 3
nll_loss: 34.69413308536305
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.52957624547622
begin epoch : 5
nll_loss: 31.904045441571405
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2823
begin the training process
begin epoch : 1
nll_loss: 41.713752486489035
begin epoch : 2
nll_loss: 32.48738679018888
begin epoch : 3
nll_loss: 28.90850002115423
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.714800747958098
begin epoch : 5
nll_loss: 27.398096214641225
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 660750
begin the training process
begin epoch : 1
nll_loss: 22.142674262650203
begin epoch : 2
nll_loss: 20.80564773253626
begin epoch : 3
nll_loss: 20.367406592910395
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.975606245479117
begin epoch : 5
nll_loss: 19.896803554200886
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 11311
begin the training process
begin epoch : 1
nll_loss: 31.30883970043876
begin epoch : 2
nll_loss: 23.656509204344317
begin epoch : 3
nll_loss: 21.773059942505576
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.996493989771064
begin epoch : 5
nll_loss: 20.82428170334209
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2879
begin the training process
begin epoch : 1
nll_loss: 40.73310808701949
begin epoch : 2
nll_loss: 31.367531863125887
begin epoch : 3
nll_loss: 27.183867541226473
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.047335407950662
begin epoch : 5
nll_loss: 25.744123588908803
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 790
begin the training process
begin epoch : 1
nll_loss: 45.60625044504801
begin epoch : 2
nll_loss: 40.9836638768514
begin epoch : 3
nll_loss: 37.335343996683754
The learning rate has beed reduced
begin epoch : 4
nll_loss: 35.5705369313558
begin epoch : 5
nll_loss: 35.03711668650309
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 113101
begin the training process
begin epoch : 1
nll_loss: 23.417876170729944
begin epoch : 2
nll_loss: 20.856402529385647
begin epoch : 3
nll_loss: 20.626736093120652
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.452847980009206
begin epoch : 5
nll_loss: 20.4235169713485
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6100
begin the training process
begin epoch : 1
nll_loss: 36.6710379349558
begin epoch : 2
nll_loss: 28.39299649690327
begin epoch : 3
nll_loss: 26.069172929462635
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.077478890669973
begin epoch : 5
nll_loss: 24.786399941695365
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1540
begin the training process
begin epoch : 1
nll_loss: 44.26867707570394
begin epoch : 2
nll_loss: 36.84308544794718
begin epoch : 3
nll_loss: 33.352744579315186
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.572513500849407
begin epoch : 5
nll_loss: 31.034509738286335
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 117776
begin the training process
begin epoch : 1
nll_loss: 23.07729383551556
begin epoch : 2
nll_loss: 20.9739167244538
begin epoch : 3
nll_loss: 20.651708411133807
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.398266272959503
begin epoch : 5
nll_loss: 20.343264795386272
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 13112
begin the training process
begin epoch : 1
nll_loss: 30.87783223507451
begin epoch : 2
nll_loss: 24.2093064364265
begin epoch : 3
nll_loss: 22.379737330418006
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.718350934047326
begin epoch : 5
nll_loss: 21.59213743022844
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10998
begin the training process
begin epoch : 1
nll_loss: 31.013950180589106
begin epoch : 2
nll_loss: 23.47248563710709
begin epoch : 3
nll_loss: 21.34523693999352
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.61860053302252
begin epoch : 5
nll_loss: 20.450376120227123
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4200
begin the training process
begin epoch : 1
nll_loss: 39.04953381465032
begin epoch : 2
nll_loss: 30.497490574763372
begin epoch : 3
nll_loss: 28.246172009981596
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.322565518892727
begin epoch : 5
nll_loss: 27.010195365318886
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1319
begin the training process
begin epoch : 1
nll_loss: 44.814516639709474
begin epoch : 2
nll_loss: 37.082689094543454
begin epoch : 3
nll_loss: 33.19104700088501
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.26553258895874
begin epoch : 5
nll_loss: 30.694751071929932
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 125052
begin the training process
begin epoch : 1
nll_loss: 23.061176785431456
begin epoch : 2
nll_loss: 21.15430239097802
begin epoch : 3
nll_loss: 20.89477328892799
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.66492565973441
begin epoch : 5
nll_loss: 20.612984980062162
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1647
begin the training process
begin epoch : 1
nll_loss: 43.460851440429686
begin epoch : 2
nll_loss: 35.49732833862305
begin epoch : 3
nll_loss: 31.540335540771483
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.614391250610353
begin epoch : 5
nll_loss: 29.11073127746582
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3386
begin the training process
begin epoch : 1
nll_loss: 40.079360448397125
begin epoch : 2
nll_loss: 30.887003385103664
begin epoch : 3
nll_loss: 27.638248516963078
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.62231529675997
begin epoch : 5
nll_loss: 26.307558426490196
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12647
begin the training process
begin epoch : 1
nll_loss: 30.9202196053442
begin epoch : 2
nll_loss: 23.622454038126214
begin epoch : 3
nll_loss: 21.86228679521435
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.175262344670173
begin epoch : 5
nll_loss: 21.02271087762668
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2168
begin the training process
begin epoch : 1
nll_loss: 43.08252646706321
begin epoch : 2
nll_loss: 35.11878747651071
begin epoch : 3
nll_loss: 31.001330982555043
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.3079360037139
begin epoch : 5
nll_loss: 29.00096980008212
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2386
begin the training process
begin epoch : 1
nll_loss: 42.441821639602246
begin epoch : 2
nll_loss: 34.1261570904706
begin epoch : 3
nll_loss: 30.125136865151894
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.792960192706133
begin epoch : 5
nll_loss: 28.520669370084196
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9299
begin the training process
begin epoch : 1
nll_loss: 33.858147127874965
begin epoch : 2
nll_loss: 26.416934796037346
begin epoch : 3
nll_loss: 24.445121791444976
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.596617665784112
begin epoch : 5
nll_loss: 23.371191616716057
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2218
begin the training process
begin epoch : 1
nll_loss: 43.14102318707634
begin epoch : 2
nll_loss: 34.45829043668859
begin epoch : 3
nll_loss: 30.24374069887049
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.6738998188692
begin epoch : 5
nll_loss: 28.343047590816724
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2571
begin the training process
begin epoch : 1
nll_loss: 42.23562421798706
begin epoch : 2
nll_loss: 33.579802942276004
begin epoch : 3
nll_loss: 29.520913887023926
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.32500877380371
begin epoch : 5
nll_loss: 28.039021968841553
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1541
begin the training process
begin epoch : 1
nll_loss: 43.82279380162557
begin epoch : 2
nll_loss: 35.922707875569664
begin epoch : 3
nll_loss: 31.80225070317586
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.59438673655192
begin epoch : 5
nll_loss: 29.016971190770466
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3098
begin the training process
begin epoch : 1
nll_loss: 41.92174140612284
begin epoch : 2
nll_loss: 33.25392440954844
begin epoch : 3
nll_loss: 29.57329301039378
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.56230103969574
begin epoch : 5
nll_loss: 28.267972389856975
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2947
begin the training process
begin epoch : 1
nll_loss: 40.6802742999533
begin epoch : 2
nll_loss: 31.705300496972125
begin epoch : 3
nll_loss: 28.38550795679507
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.336938650711723
begin epoch : 5
nll_loss: 27.05733929509702
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3053
begin the training process
begin epoch : 1
nll_loss: 39.57328260705826
begin epoch : 2
nll_loss: 30.829097220238218
begin epoch : 3
nll_loss: 27.23702735089241
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.05653653246291
begin epoch : 5
nll_loss: 25.80352174474838
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 699
begin the training process
begin epoch : 1
nll_loss: 46.360086822509764
begin epoch : 2
nll_loss: 42.30460891723633
begin epoch : 3
nll_loss: 38.03678398132324
The learning rate has beed reduced
begin epoch : 4
nll_loss: 36.33774681091309
begin epoch : 5
nll_loss: 35.85823364257813
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9962
begin the training process
begin epoch : 1
nll_loss: 31.880813561716387
begin epoch : 2
nll_loss: 24.774089333318894
begin epoch : 3
nll_loss: 22.6869077497913
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.830128602058657
begin epoch : 5
nll_loss: 21.64068549371535
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 156874
begin the training process
begin epoch : 1
nll_loss: 22.45517850476642
begin epoch : 2
nll_loss: 20.8319179818174
begin epoch : 3
nll_loss: 20.58305392193337
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.344836655659172
begin epoch : 5
nll_loss: 20.287670366621075
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7143
begin the training process
begin epoch : 1
nll_loss: 36.11466351070919
begin epoch : 2
nll_loss: 27.934689599114495
begin epoch : 3
nll_loss: 25.272864109761006
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.071463146725215
begin epoch : 5
nll_loss: 23.796430089452244
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5286
begin the training process
begin epoch : 1
nll_loss: 36.90672732562554
begin epoch : 2
nll_loss: 27.77571394385361
begin epoch : 3
nll_loss: 24.96917526896407
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.059784842700495
begin epoch : 5
nll_loss: 23.82216774545065
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1630
begin the training process
begin epoch : 1
nll_loss: 44.35079818725586
begin epoch : 2
nll_loss: 36.975836486816405
begin epoch : 3
nll_loss: 33.02462394714355
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.241081085205078
begin epoch : 5
nll_loss: 30.703813705444336
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 75896
begin the training process
begin epoch : 1
nll_loss: 24.403125309038767
begin epoch : 2
nll_loss: 21.031780036894077
begin epoch : 3
nll_loss: 20.704489064920804
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.516755301238113
begin epoch : 5
nll_loss: 20.48331763834893
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3693
begin the training process
begin epoch : 1
nll_loss: 39.779388762356945
begin epoch : 2
nll_loss: 30.8414799874289
begin epoch : 3
nll_loss: 27.720342937268708
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.513084076998528
begin epoch : 5
nll_loss: 26.186456345675285
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 157894
begin the training process
begin epoch : 1
nll_loss: 22.51231272248638
begin epoch : 2
nll_loss: 20.88295605523798
begin epoch : 3
nll_loss: 20.655469059412617
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.433422218511403
begin epoch : 5
nll_loss: 20.384423509898532
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 808
begin the training process
begin epoch : 1
nll_loss: 45.805121739705406
begin epoch : 2
nll_loss: 40.66610018412272
begin epoch : 3
nll_loss: 36.574293772379555
The learning rate has beed reduced
begin epoch : 4
nll_loss: 34.75194803873698
begin epoch : 5
nll_loss: 34.116716066996254
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3757
begin the training process
begin epoch : 1
nll_loss: 39.51594227757947
begin epoch : 2
nll_loss: 30.19117128437963
begin epoch : 3
nll_loss: 26.987726573286384
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.93502926004344
begin epoch : 5
nll_loss: 25.657815374177076
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 53892
begin the training process
begin epoch : 1
nll_loss: 25.68395472365717
begin epoch : 2
nll_loss: 21.65715576180936
begin epoch : 3
nll_loss: 21.200739140182097
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.960947834114563
begin epoch : 5
nll_loss: 20.916216295292145
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 36186
begin the training process
begin epoch : 1
nll_loss: 27.124794914448156
begin epoch : 2
nll_loss: 22.053344365347805
begin epoch : 3
nll_loss: 21.327761972478005
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.00876901002057
begin epoch : 5
nll_loss: 20.945226210197518
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2071
begin the training process
begin epoch : 1
nll_loss: 42.406789898872375
begin epoch : 2
nll_loss: 35.24967908859253
begin epoch : 3
nll_loss: 31.067178428173065
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.430896639823914
begin epoch : 5
nll_loss: 29.09646427631378
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1773
begin the training process
begin epoch : 1
nll_loss: 43.60279888576932
begin epoch : 2
nll_loss: 36.480741571497035
begin epoch : 3
nll_loss: 32.76743606284813
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.104682569150572
begin epoch : 5
nll_loss: 30.732054745709455
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10961
begin the training process
begin epoch : 1
nll_loss: 31.12224586665282
begin epoch : 2
nll_loss: 23.471044261553136
begin epoch : 3
nll_loss: 21.774398681015995
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.09717879936709
begin epoch : 5
nll_loss: 20.943603582549514
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9443
begin the training process
begin epoch : 1
nll_loss: 32.268777496960695
begin epoch : 2
nll_loss: 24.046148092568327
begin epoch : 3
nll_loss: 21.460590362548828
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.636041835862763
begin epoch : 5
nll_loss: 20.47725584069077
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2518
begin the training process
begin epoch : 1
nll_loss: 43.03639925443209
begin epoch : 2
nll_loss: 34.02527109781901
begin epoch : 3
nll_loss: 30.33076838957958
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.095551026173126
begin epoch : 5
nll_loss: 28.782344524676983
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 39982
begin the training process
begin epoch : 1
nll_loss: 26.095926367319546
begin epoch : 2
nll_loss: 21.363304850382683
begin epoch : 3
nll_loss: 20.761893477195347
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.481671620637943
begin epoch : 5
nll_loss: 20.428879780647083
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12527
begin the training process
begin epoch : 1
nll_loss: 30.60760509784405
begin epoch : 2
nll_loss: 23.215801229232397
begin epoch : 3
nll_loss: 21.6593195499518
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.078133509709286
begin epoch : 5
nll_loss: 20.94775887513772
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5446
begin the training process
begin epoch : 1
nll_loss: 37.56457088694853
begin epoch : 2
nll_loss: 28.834661236931296
begin epoch : 3
nll_loss: 26.545403424431296
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.427285856359145
begin epoch : 5
nll_loss: 25.135082985373103
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1544
begin the training process
begin epoch : 1
nll_loss: 44.33338848749796
begin epoch : 2
nll_loss: 36.92547798156738
begin epoch : 3
nll_loss: 33.10997168223063
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.160595734914143
begin epoch : 5
nll_loss: 30.6225639184316
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5694
begin the training process
begin epoch : 1
nll_loss: 35.727702834389426
begin epoch : 2
nll_loss: 26.34318594499068
begin epoch : 3
nll_loss: 23.652102773839776
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.696334730495106
begin epoch : 5
nll_loss: 22.45526868646795
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2822
begin the training process
begin epoch : 1
nll_loss: 41.51991141926158
begin epoch : 2
nll_loss: 32.842078338969834
begin epoch : 3
nll_loss: 29.42025306008079
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.489349235187877
begin epoch : 5
nll_loss: 28.26018896969882
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1715
begin the training process
begin epoch : 1
nll_loss: 43.33010292053223
begin epoch : 2
nll_loss: 35.488013194157524
begin epoch : 3
nll_loss: 31.50540931408222
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.463759935819187
begin epoch : 5
nll_loss: 28.975763981158916
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2006
begin the training process
begin epoch : 1
nll_loss: 42.80220351680632
begin epoch : 2
nll_loss: 35.3389159171812
begin epoch : 3
nll_loss: 31.907859186972342
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.449165713402532
begin epoch : 5
nll_loss: 30.104218206098004
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2399
begin the training process
begin epoch : 1
nll_loss: 42.53039891011006
begin epoch : 2
nll_loss: 34.48688507080078
begin epoch : 3
nll_loss: 30.685186025258655
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.03157357911806
begin epoch : 5
nll_loss: 28.650022403613942
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1568
begin the training process
begin epoch : 1
nll_loss: 44.48861789703369
begin epoch : 2
nll_loss: 37.124380906422935
begin epoch : 3
nll_loss: 32.83499471346537
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.12073548634847
begin epoch : 5
nll_loss: 30.75077525774638
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 30997
begin the training process
begin epoch : 1
nll_loss: 27.612908907173093
begin epoch : 2
nll_loss: 22.43335610381828
begin epoch : 3
nll_loss: 21.662891561334785
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.337686278603293
begin epoch : 5
nll_loss: 21.270328253753913
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 16693
begin the training process
begin epoch : 1
nll_loss: 30.85348472595215
begin epoch : 2
nll_loss: 24.025128628657413
begin epoch : 3
nll_loss: 22.424296569824218
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.848576868497407
begin epoch : 5
nll_loss: 21.71898313669058
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 18792
begin the training process
begin epoch : 1
nll_loss: 29.63140101644366
begin epoch : 2
nll_loss: 23.336919270277836
begin epoch : 3
nll_loss: 22.021569912750973
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.547037092085176
begin epoch : 5
nll_loss: 21.443817418589934
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10520
begin the training process
begin epoch : 1
nll_loss: 31.08405579590216
begin epoch : 2
nll_loss: 23.54948689297932
begin epoch : 3
nll_loss: 21.555940267516345
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.88106406607279
begin epoch : 5
nll_loss: 20.72773012300817
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7300
begin the training process
begin epoch : 1
nll_loss: 35.66016807890775
begin epoch : 2
nll_loss: 27.384548321104887
begin epoch : 3
nll_loss: 24.982686628375138
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.9897014885618
begin epoch : 5
nll_loss: 23.75065161052503
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8616
begin the training process
begin epoch : 1
nll_loss: 32.54868178581124
begin epoch : 2
nll_loss: 24.487058838801598
begin epoch : 3
nll_loss: 22.362424765060197
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.451332234624605
begin epoch : 5
nll_loss: 21.192767769543092
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 23705
begin the training process
begin epoch : 1
nll_loss: 29.576784551465835
begin epoch : 2
nll_loss: 23.22385097709862
begin epoch : 3
nll_loss: 21.76320364153063
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.279727951256003
begin epoch : 5
nll_loss: 21.181265784598686
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4361
begin the training process
begin epoch : 1
nll_loss: 39.050147505367505
begin epoch : 2
nll_loss: 30.166687797097598
begin epoch : 3
nll_loss: 27.668872552759506
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.61557326597326
begin epoch : 5
nll_loss: 26.28842129426844
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5436
begin the training process
begin epoch : 1
nll_loss: 37.21523909341721
begin epoch : 2
nll_loss: 28.295248758225213
begin epoch : 3
nll_loss: 25.98979902267456
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.943578561147053
begin epoch : 5
nll_loss: 24.68178147361392
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5943
begin the training process
begin epoch : 1
nll_loss: 35.465824127197266
begin epoch : 2
nll_loss: 25.82939340757287
begin epoch : 3
nll_loss: 23.4702090387759
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.570409919904627
begin epoch : 5
nll_loss: 22.27824638200843
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 18407
begin the training process
begin epoch : 1
nll_loss: 29.10020299904853
begin epoch : 2
nll_loss: 22.39661951762874
begin epoch : 3
nll_loss: 20.985013376960357
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.52989856706679
begin epoch : 5
nll_loss: 20.444192879706726
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4692
begin the training process
begin epoch : 1
nll_loss: 37.94041529093703
begin epoch : 2
nll_loss: 28.883739471435547
begin epoch : 3
nll_loss: 26.659076298752876
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.648674455407548
begin epoch : 5
nll_loss: 25.381150520011172
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1481
begin the training process
begin epoch : 1
nll_loss: 45.233917733897336
begin epoch : 2
nll_loss: 38.035005154817
begin epoch : 3
nll_loss: 33.360738837200664
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.284369510153066
begin epoch : 5
nll_loss: 30.79122949683148
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 53748
begin the training process
begin epoch : 1
nll_loss: 23.51586000853983
begin epoch : 2
nll_loss: 19.742029017288154
begin epoch : 3
nll_loss: 19.45251904284144
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.279205490494228
begin epoch : 5
nll_loss: 19.25041589748305
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 336040
begin the training process
begin epoch : 1
nll_loss: 21.6409375726609
begin epoch : 2
nll_loss: 19.02058555167062
begin epoch : 3
nll_loss: 18.303076835087367
The learning rate has beed reduced
begin epoch : 4
nll_loss: 17.762136761256627
begin epoch : 5
nll_loss: 17.65581179210118
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2517
begin the training process
begin epoch : 1
nll_loss: 41.84642097277519
begin epoch : 2
nll_loss: 33.60208501571264
begin epoch : 3
nll_loss: 29.759021710126827
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.52395502726237
begin epoch : 5
nll_loss: 28.248831431070965
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5094
begin the training process
begin epoch : 1
nll_loss: 37.678458250021635
begin epoch : 2
nll_loss: 29.159635954265354
begin epoch : 3
nll_loss: 26.797843232939513
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.703776178480705
begin epoch : 5
nll_loss: 25.41940952252738
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4124
begin the training process
begin epoch : 1
nll_loss: 39.27677422761917
begin epoch : 2
nll_loss: 30.425709545612335
begin epoch : 3
nll_loss: 27.735066294670105
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.622126936912537
begin epoch : 5
nll_loss: 26.3427571952343
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 27094
begin the training process
begin epoch : 1
nll_loss: 27.27189896405448
begin epoch : 2
nll_loss: 21.58672498247584
begin epoch : 3
nll_loss: 20.086301690861408
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.167747799668188
begin epoch : 5
nll_loss: 18.905892834313935
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 149946
begin the training process
begin epoch : 1
nll_loss: 22.800683191757138
begin epoch : 2
nll_loss: 21.180237248858052
begin epoch : 3
nll_loss: 20.93987676651431
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.707685144816985
begin epoch : 5
nll_loss: 20.65335211114533
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7396
begin the training process
begin epoch : 1
nll_loss: 33.20104748269786
begin epoch : 2
nll_loss: 24.817645860754926
begin epoch : 3
nll_loss: 22.475664122208304
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.476591359014098
begin epoch : 5
nll_loss: 21.237104482236116
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2475
begin the training process
begin epoch : 1
nll_loss: 42.24269515589664
begin epoch : 2
nll_loss: 33.41742299732409
begin epoch : 3
nll_loss: 29.445284943831595
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.98110409786827
begin epoch : 5
nll_loss: 27.674491781937448
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2694
begin the training process
begin epoch : 1
nll_loss: 43.04051181248256
begin epoch : 2
nll_loss: 34.206503141494025
begin epoch : 3
nll_loss: 29.978882335481188
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.834754943847656
begin epoch : 5
nll_loss: 28.552143778119767
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8380
begin the training process
begin epoch : 1
nll_loss: 32.75038456550011
begin epoch : 2
nll_loss: 24.448008918762206
begin epoch : 3
nll_loss: 22.398347355769232
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.424907405559832
begin epoch : 5
nll_loss: 21.185427196209247
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2456
begin the training process
begin epoch : 1
nll_loss: 42.82441450420179
begin epoch : 2
nll_loss: 33.742191214310495
begin epoch : 3
nll_loss: 30.09198505000064
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.864395743922184
begin epoch : 5
nll_loss: 28.56880464051899
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 23370
begin the training process
begin epoch : 1
nll_loss: 27.405105261606714
begin epoch : 2
nll_loss: 21.271274775674897
begin epoch : 3
nll_loss: 20.253550782922197
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.962100219726562
begin epoch : 5
nll_loss: 19.901290809944886
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2980
begin the training process
begin epoch : 1
nll_loss: 40.20938010837721
begin epoch : 2
nll_loss: 31.531847083050273
begin epoch : 3
nll_loss: 27.692735423212465
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.471737737241
begin epoch : 5
nll_loss: 26.172848991725754
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 29118
begin the training process
begin epoch : 1
nll_loss: 28.181276418038927
begin epoch : 2
nll_loss: 22.563944446883013
begin epoch : 3
nll_loss: 21.57447238115487
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.188749443591956
begin epoch : 5
nll_loss: 21.115619100663107
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8834
begin the training process
begin epoch : 1
nll_loss: 32.57007679040881
begin epoch : 2
nll_loss: 24.68299522952757
begin epoch : 3
nll_loss: 22.30428976252459
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.472244691157687
begin epoch : 5
nll_loss: 21.27554189986077
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2898
begin the training process
begin epoch : 1
nll_loss: 41.99033465915256
begin epoch : 2
nll_loss: 32.69445805019802
begin epoch : 3
nll_loss: 29.473307122124567
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.48992042541504
begin epoch : 5
nll_loss: 28.196892674763998
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 18883
begin the training process
begin epoch : 1
nll_loss: 28.468348467552055
begin epoch : 2
nll_loss: 21.854949621426858
begin epoch : 3
nll_loss: 20.593787468085853
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.219316023487156
begin epoch : 5
nll_loss: 20.14669879977986
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1534
begin the training process
begin epoch : 1
nll_loss: 45.35763632732889
begin epoch : 2
nll_loss: 38.0201591823412
begin epoch : 3
nll_loss: 33.53310137209685
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.6272960331129
begin epoch : 5
nll_loss: 31.09467199574346
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8934
begin the training process
begin epoch : 1
nll_loss: 33.68224074000077
begin epoch : 2
nll_loss: 25.504103461615472
begin epoch : 3
nll_loss: 23.26753580655983
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.401852504812556
begin epoch : 5
nll_loss: 22.225967791440677
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9502
begin the training process
begin epoch : 1
nll_loss: 31.84021974254299
begin epoch : 2
nll_loss: 24.144943675479375
begin epoch : 3
nll_loss: 22.273870970751787
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.469257767136032
begin epoch : 5
nll_loss: 21.26251475875442
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2440
begin the training process
begin epoch : 1
nll_loss: 41.413787841796875
begin epoch : 2
nll_loss: 32.44539511831183
begin epoch : 3
nll_loss: 28.096207518326608
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.747144046582672
begin epoch : 5
nll_loss: 26.476938147293893
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2457
begin the training process
begin epoch : 1
nll_loss: 41.859690716392116
begin epoch : 2
nll_loss: 32.55159814734208
begin epoch : 3
nll_loss: 28.266374487625924
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.952009702983656
begin epoch : 5
nll_loss: 26.66849994659424
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 48016
begin the training process
begin epoch : 1
nll_loss: 25.661836346944174
begin epoch : 2
nll_loss: 21.78794480895996
begin epoch : 3
nll_loss: 21.290371810913086
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.96020262145996
begin epoch : 5
nll_loss: 20.882227816263836
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6143
begin the training process
begin epoch : 1
nll_loss: 36.01218819869192
begin epoch : 2
nll_loss: 26.810483229787724
begin epoch : 3
nll_loss: 24.134381786145664
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.046271494815223
begin epoch : 5
nll_loss: 22.794925749929327
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2223
begin the training process
begin epoch : 1
nll_loss: 41.54084463680492
begin epoch : 2
nll_loss: 33.436563043033374
begin epoch : 3
nll_loss: 28.815136348499973
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.14585865245146
begin epoch : 5
nll_loss: 26.747746411491843
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1081
begin the training process
begin epoch : 1
nll_loss: 45.17799258232117
begin epoch : 2
nll_loss: 38.66996788978577
begin epoch : 3
nll_loss: 35.11671781539917
The learning rate has beed reduced
begin epoch : 4
nll_loss: 33.35805332660675
begin epoch : 5
nll_loss: 32.95134627819061
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1135
begin the training process
begin epoch : 1
nll_loss: 46.36159425623276
begin epoch : 2
nll_loss: 40.64049709544462
begin epoch : 3
nll_loss: 37.113124398624194
The learning rate has beed reduced
begin epoch : 4
nll_loss: 35.49337589039522
begin epoch : 5
nll_loss: 34.90384157966165
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5018
begin the training process
begin epoch : 1
nll_loss: 38.55377123906062
begin epoch : 2
nll_loss: 29.25179415482741
begin epoch : 3
nll_loss: 26.710522382687298
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.506575315426556
begin epoch : 5
nll_loss: 25.171971859076084
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 151518
begin the training process
begin epoch : 1
nll_loss: 22.702998248746137
begin epoch : 2
nll_loss: 20.908237051147925
begin epoch : 3
nll_loss: 20.649699212329317
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.413928469878286
begin epoch : 5
nll_loss: 20.361487860411696
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1379
begin the training process
begin epoch : 1
nll_loss: 44.460807618640715
begin epoch : 2
nll_loss: 37.346678960891
begin epoch : 3
nll_loss: 33.255322774251304
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.307497569492885
begin epoch : 5
nll_loss: 30.772446496146067
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4842
begin the training process
begin epoch : 1
nll_loss: 38.10329500834147
begin epoch : 2
nll_loss: 29.502649612426758
begin epoch : 3
nll_loss: 26.966022288004556
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.96635533650716
begin epoch : 5
nll_loss: 25.73841074625651
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1924
begin the training process
begin epoch : 1
nll_loss: 42.58351058959961
begin epoch : 2
nll_loss: 35.52478841145833
begin epoch : 3
nll_loss: 31.37899621327718
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.743923568725585
begin epoch : 5
nll_loss: 29.404696337382
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 386524
begin the training process
begin epoch : 1
nll_loss: 21.578373233891813
begin epoch : 2
nll_loss: 20.71365013886888
begin epoch : 3
nll_loss: 20.554976922389113
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.373931969094503
begin epoch : 5
nll_loss: 20.336641929425593
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1586
begin the training process
begin epoch : 1
nll_loss: 44.29541905721029
begin epoch : 2
nll_loss: 36.791966120402016
begin epoch : 3
nll_loss: 33.06095965703329
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.281246821085613
begin epoch : 5
nll_loss: 30.770642201105755
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5181
begin the training process
begin epoch : 1
nll_loss: 36.8346275806427
begin epoch : 2
nll_loss: 26.94607560634613
begin epoch : 3
nll_loss: 24.4130535364151
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.40484473705292
begin epoch : 5
nll_loss: 23.112612462043764
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2090
begin the training process
begin epoch : 1
nll_loss: 44.04993462562561
begin epoch : 2
nll_loss: 35.76943647861481
begin epoch : 3
nll_loss: 31.6927490234375
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.058132767677307
begin epoch : 5
nll_loss: 29.691910684108734
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4926
begin the training process
begin epoch : 1
nll_loss: 36.51222904104935
begin epoch : 2
nll_loss: 27.720043859983747
begin epoch : 3
nll_loss: 25.1755176092449
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.036420219822933
begin epoch : 5
nll_loss: 23.721300702346
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 17290
begin the training process
begin epoch : 1
nll_loss: 30.12312345151548
begin epoch : 2
nll_loss: 23.41213168391475
begin epoch : 3
nll_loss: 21.871420012580025
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.31477722591824
begin epoch : 5
nll_loss: 21.190668000115288
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12877
begin the training process
begin epoch : 1
nll_loss: 30.684459050496418
begin epoch : 2
nll_loss: 23.12156319499609
begin epoch : 3
nll_loss: 21.2426577705649
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.69605730540717
begin epoch : 5
nll_loss: 20.582100664205218
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 14846
begin the training process
begin epoch : 1
nll_loss: 29.318933470424636
begin epoch : 2
nll_loss: 22.463144789526474
begin epoch : 3
nll_loss: 21.077121800674504
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.60765065775289
begin epoch : 5
nll_loss: 20.50905755278352
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1152
begin the training process
begin epoch : 1
nll_loss: 44.096295250786675
begin epoch : 2
nll_loss: 37.36235343085395
begin epoch : 3
nll_loss: 33.58702585432265
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.808277236090767
begin epoch : 5
nll_loss: 31.258462376064724
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5128
begin the training process
begin epoch : 1
nll_loss: 37.82807333469391
begin epoch : 2
nll_loss: 29.061527276039122
begin epoch : 3
nll_loss: 26.637806963920593
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.70569293498993
begin epoch : 5
nll_loss: 25.45648136138916
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4190
begin the training process
begin epoch : 1
nll_loss: 36.933163716242866
begin epoch : 2
nll_loss: 27.791287290132964
begin epoch : 3
nll_loss: 25.066554495004507
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.888562804002028
begin epoch : 5
nll_loss: 23.553203758826623
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1536
begin the training process
begin epoch : 1
nll_loss: 43.326170126597084
begin epoch : 2
nll_loss: 35.23139524459839
begin epoch : 3
nll_loss: 31.42418320973714
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.49666420618693
begin epoch : 5
nll_loss: 28.889127175013225
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3048
begin the training process
begin epoch : 1
nll_loss: 39.820009596804354
begin epoch : 2
nll_loss: 30.627995714228202
begin epoch : 3
nll_loss: 26.957301687687
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.89674495128875
begin epoch : 5
nll_loss: 25.63234771566188
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 120035
begin the training process
begin epoch : 1
nll_loss: 22.74076787109375
begin epoch : 2
nll_loss: 20.63184150390625
begin epoch : 3
nll_loss: 20.345787280273438
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.09746525777181
begin epoch : 5
nll_loss: 20.03811389160156
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3818
begin the training process
begin epoch : 1
nll_loss: 38.43818884380793
begin epoch : 2
nll_loss: 29.192453384399414
begin epoch : 3
nll_loss: 25.712237535896946
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.469000767853302
begin epoch : 5
nll_loss: 24.161867368019234
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1983
begin the training process
begin epoch : 1
nll_loss: 43.96699358622233
begin epoch : 2
nll_loss: 36.13575210571289
begin epoch : 3
nll_loss: 31.69700870513916
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.68984292348226
begin epoch : 5
nll_loss: 29.166591199239097
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3808
begin the training process
begin epoch : 1
nll_loss: 39.63368819931806
begin epoch : 2
nll_loss: 30.79505089582023
begin epoch : 3
nll_loss: 27.694759692175914
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.51301351644225
begin epoch : 5
nll_loss: 26.177259057255114
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1575
begin the training process
begin epoch : 1
nll_loss: 44.742592334747314
begin epoch : 2
nll_loss: 37.76687240600586
begin epoch : 3
nll_loss: 33.758330504099526
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.866769711176556
begin epoch : 5
nll_loss: 31.392685810724895
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 13575
begin the training process
begin epoch : 1
nll_loss: 30.79766759332621
begin epoch : 2
nll_loss: 23.47574476925832
begin epoch : 3
nll_loss: 21.87191824643117
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.39188108804091
begin epoch : 5
nll_loss: 21.296972238792563
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2112
begin the training process
begin epoch : 1
nll_loss: 42.31442688450669
begin epoch : 2
nll_loss: 33.843318650216766
begin epoch : 3
nll_loss: 29.751704013708867
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.228001507845793
begin epoch : 5
nll_loss: 27.85230862010609
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1348
begin the training process
begin epoch : 1
nll_loss: 43.94683238438198
begin epoch : 2
nll_loss: 37.43350201561337
begin epoch : 3
nll_loss: 33.27823956807455
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.2336615607852
begin epoch : 5
nll_loss: 30.60276848929269
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 63872
begin the training process
begin epoch : 1
nll_loss: 24.72495477710793
begin epoch : 2
nll_loss: 21.112448277597675
begin epoch : 3
nll_loss: 20.70682212967194
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.488227737212707
begin epoch : 5
nll_loss: 20.448567782231944
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 872
begin the training process
begin epoch : 1
nll_loss: 46.18546265822191
begin epoch : 2
nll_loss: 40.11535732562725
begin epoch : 3
nll_loss: 36.82203146127554
The learning rate has beed reduced
begin epoch : 4
nll_loss: 35.354603694035454
begin epoch : 5
nll_loss: 34.965007488544174
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 569
begin the training process
begin epoch : 1
nll_loss: 47.25876188278198
begin epoch : 2
nll_loss: 43.92308282852173
begin epoch : 3
nll_loss: 40.56503915786743
The learning rate has beed reduced
begin epoch : 4
nll_loss: 38.27786827087402
begin epoch : 5
nll_loss: 37.73679542541504
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2535
begin the training process
begin epoch : 1
nll_loss: 42.224203745524086
begin epoch : 2
nll_loss: 33.998319674760864
begin epoch : 3
nll_loss: 30.517067444630158
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.31733693832006
begin epoch : 5
nll_loss: 29.00450549981533
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5834
begin the training process
begin epoch : 1
nll_loss: 36.024971427498286
begin epoch : 2
nll_loss: 26.33873015183669
begin epoch : 3
nll_loss: 23.905463774125653
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.031539665473687
begin epoch : 5
nll_loss: 22.783652693360718
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3752
begin the training process
begin epoch : 1
nll_loss: 38.71607385832688
begin epoch : 2
nll_loss: 29.29117067928972
begin epoch : 3
nll_loss: 26.335675436874915
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.323559103340937
begin epoch : 5
nll_loss: 24.977714966083393
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4411
begin the training process
begin epoch : 1
nll_loss: 38.66019978242762
begin epoch : 2
nll_loss: 29.45008580824908
begin epoch : 3
nll_loss: 27.024461157181683
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.010141484877643
begin epoch : 5
nll_loss: 25.684855657465317
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2414
begin the training process
begin epoch : 1
nll_loss: 42.7235482705606
begin epoch : 2
nll_loss: 33.8208321751775
begin epoch : 3
nll_loss: 30.032870988588076
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.740592544143265
begin epoch : 5
nll_loss: 28.4753935530379
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 37675
begin the training process
begin epoch : 1
nll_loss: 26.382081781114852
begin epoch : 2
nll_loss: 21.44308653331938
begin epoch : 3
nll_loss: 20.764352454620155
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.472602549053374
begin epoch : 5
nll_loss: 20.414525317496995
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6135
begin the training process
begin epoch : 1
nll_loss: 36.79830743890059
begin epoch : 2
nll_loss: 28.273120077032793
begin epoch : 3
nll_loss: 26.104124089291222
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.15584329303942
begin epoch : 5
nll_loss: 24.9006138450221
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 19465
begin the training process
begin epoch : 1
nll_loss: 28.64617293131979
begin epoch : 2
nll_loss: 21.83987904222388
begin epoch : 3
nll_loss: 20.460874438285828
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.054863973667747
begin epoch : 5
nll_loss: 19.974232366210536
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3897
begin the training process
begin epoch : 1
nll_loss: 39.10270201365153
begin epoch : 2
nll_loss: 30.598616695404054
begin epoch : 3
nll_loss: 27.874833456675212
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.820806376139323
begin epoch : 5
nll_loss: 26.47835658391317
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4899
begin the training process
begin epoch : 1
nll_loss: 37.642653364884225
begin epoch : 2
nll_loss: 29.05925070612054
begin epoch : 3
nll_loss: 26.713887038983795
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.645460254267643
begin epoch : 5
nll_loss: 25.352375808515045
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3173
begin the training process
begin epoch : 1
nll_loss: 40.693249605139904
begin epoch : 2
nll_loss: 31.74300649214764
begin epoch : 3
nll_loss: 28.568156573237204
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.618150749985052
begin epoch : 5
nll_loss: 27.355087397049886
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3051
begin the training process
begin epoch : 1
nll_loss: 40.61327199733004
begin epoch : 2
nll_loss: 31.708772415810444
begin epoch : 3
nll_loss: 28.55355920182898
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.61232104199998
begin epoch : 5
nll_loss: 27.353141338267225
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3178
begin the training process
begin epoch : 1
nll_loss: 41.30554386061065
begin epoch : 2
nll_loss: 33.052213552046794
begin epoch : 3
nll_loss: 29.927046561727717
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.93571203582141
begin epoch : 5
nll_loss: 28.64174208349111
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 20899
begin the training process
begin epoch : 1
nll_loss: 29.200756505954484
begin epoch : 2
nll_loss: 22.85749176236018
begin epoch : 3
nll_loss: 21.51479745057463
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.04529437550738
begin epoch : 5
nll_loss: 20.947811951666523
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 16597
begin the training process
begin epoch : 1
nll_loss: 30.889660978869582
begin epoch : 2
nll_loss: 24.486845222679346
begin epoch : 3
nll_loss: 22.731980298016524
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.06366474195797
begin epoch : 5
nll_loss: 21.919958099895464
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8126
begin the training process
begin epoch : 1
nll_loss: 33.061131689283584
begin epoch : 2
nll_loss: 24.51443328554668
begin epoch : 3
nll_loss: 22.4338597948589
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.60057803562709
begin epoch : 5
nll_loss: 21.368907292683918
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4332
begin the training process
begin epoch : 1
nll_loss: 37.58108882050016
begin epoch : 2
nll_loss: 27.90992691267782
begin epoch : 3
nll_loss: 25.23956908040972
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.22967492288618
begin epoch : 5
nll_loss: 23.948707722905855
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8772
begin the training process
begin epoch : 1
nll_loss: 34.331548857862934
begin epoch : 2
nll_loss: 26.21695386232251
begin epoch : 3
nll_loss: 24.015653874752296
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.098724657601682
begin epoch : 5
nll_loss: 22.88100356777219
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 57103
begin the training process
begin epoch : 1
nll_loss: 24.95278988611538
begin epoch : 2
nll_loss: 21.31711267248932
begin epoch : 3
nll_loss: 20.515969058323336
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.94779321003388
begin epoch : 5
nll_loss: 19.79198894158607
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 33554
begin the training process
begin epoch : 1
nll_loss: 27.58142685708199
begin epoch : 2
nll_loss: 22.074002939326164
begin epoch : 3
nll_loss: 21.25429312145437
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.91167757529339
begin epoch : 5
nll_loss: 20.84900379908904
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3483
begin the training process
begin epoch : 1
nll_loss: 40.47494888305664
begin epoch : 2
nll_loss: 31.874462339613174
begin epoch : 3
nll_loss: 28.977455421730323
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.95453089254874
begin epoch : 5
nll_loss: 27.6450632236622
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 883553
begin the training process
begin epoch : 1
nll_loss: 21.551043287924518
begin epoch : 2
nll_loss: 19.9370052525549
begin epoch : 3
nll_loss: 19.530815214732556
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.104025749502213
begin epoch : 5
nll_loss: 19.028219309236555
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1704
begin the training process
begin epoch : 1
nll_loss: 44.27476868262658
begin epoch : 2
nll_loss: 36.669787627000076
begin epoch : 3
nll_loss: 32.93109915806697
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.21329505626972
begin epoch : 5
nll_loss: 30.82744627732497
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2292
begin the training process
begin epoch : 1
nll_loss: 43.437354278564456
begin epoch : 2
nll_loss: 35.4850348336356
begin epoch : 3
nll_loss: 31.296225902012416
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.61569584437779
begin epoch : 5
nll_loss: 29.297366387503487
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 60680
begin the training process
begin epoch : 1
nll_loss: 24.54269721035213
begin epoch : 2
nll_loss: 20.737044933979018
begin epoch : 3
nll_loss: 20.153068727581815
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.794226499549445
begin epoch : 5
nll_loss: 19.70705454057782
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1424
begin the training process
begin epoch : 1
nll_loss: 45.56648393110795
begin epoch : 2
nll_loss: 38.27439186789773
begin epoch : 3
nll_loss: 34.33659778941762
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.43075925653631
begin epoch : 5
nll_loss: 31.923167142001066
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 124523
begin the training process
begin epoch : 1
nll_loss: 23.036066161207184
begin epoch : 2
nll_loss: 20.88663962101875
begin epoch : 3
nll_loss: 20.647172610128447
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.443357845198527
begin epoch : 5
nll_loss: 20.40192790975301
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5363
begin the training process
begin epoch : 1
nll_loss: 35.50828324743064
begin epoch : 2
nll_loss: 25.933400579245692
begin epoch : 3
nll_loss: 23.68397112926805
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.701152410851904
begin epoch : 5
nll_loss: 22.442911194031495
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 23392
begin the training process
begin epoch : 1
nll_loss: 27.04390137554848
begin epoch : 2
nll_loss: 21.60854688147976
begin epoch : 3
nll_loss: 20.73630982490435
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.392429571282374
begin epoch : 5
nll_loss: 20.32276867905708
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1731
begin the training process
begin epoch : 1
nll_loss: 44.46533725879811
begin epoch : 2
nll_loss: 36.875193136709704
begin epoch : 3
nll_loss: 32.69330625180845
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.608979119194878
begin epoch : 5
nll_loss: 30.075211701569735
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 50686
begin the training process
begin epoch : 1
nll_loss: 25.203933944895052
begin epoch : 2
nll_loss: 21.084917326491944
begin epoch : 3
nll_loss: 20.611590225084694
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.368662415804664
begin epoch : 5
nll_loss: 20.326831000191824
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2577
begin the training process
begin epoch : 1
nll_loss: 41.210085010528566
begin epoch : 2
nll_loss: 32.0347978591919
begin epoch : 3
nll_loss: 27.66670980453491
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.32199192047119
begin epoch : 5
nll_loss: 26.01561508178711
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 52736
begin the training process
begin epoch : 1
nll_loss: 23.27725272039765
begin epoch : 2
nll_loss: 19.566255997685552
begin epoch : 3
nll_loss: 19.283959305402146
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.11254487222838
begin epoch : 5
nll_loss: 19.082504855776296
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3378
begin the training process
begin epoch : 1
nll_loss: 40.60124998826247
begin epoch : 2
nll_loss: 31.909785820887638
begin epoch : 3
nll_loss: 28.886992821326622
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.93220754770132
begin epoch : 5
nll_loss: 27.59656025813176
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 14492
begin the training process
begin epoch : 1
nll_loss: 31.672139142466857
begin epoch : 2
nll_loss: 24.96381909024399
begin epoch : 3
nll_loss: 23.021691406722617
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.224156075874262
begin epoch : 5
nll_loss: 22.050464807358463
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1196
begin the training process
begin epoch : 1
nll_loss: 44.42119534810384
begin epoch : 2
nll_loss: 37.191445456610786
begin epoch : 3
nll_loss: 33.55492930942111
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.867921087476944
begin epoch : 5
nll_loss: 31.368054813808865
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2685
begin the training process
begin epoch : 1
nll_loss: 42.253490820163634
begin epoch : 2
nll_loss: 33.37155030413372
begin epoch : 3
nll_loss: 29.548542999639743
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.476140836390055
begin epoch : 5
nll_loss: 28.22078565271889
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 36701
begin the training process
begin epoch : 1
nll_loss: 26.727717051747373
begin epoch : 2
nll_loss: 21.771089620407132
begin epoch : 3
nll_loss: 21.03938521806274
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.731936479738245
begin epoch : 5
nll_loss: 20.67526625921173
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1482
begin the training process
begin epoch : 1
nll_loss: 45.887356633725375
begin epoch : 2
nll_loss: 38.78819324659265
begin epoch : 3
nll_loss: 34.20639303456182
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.846566158792246
begin epoch : 5
nll_loss: 31.288704830667246
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 113100
begin the training process
begin epoch : 1
nll_loss: 23.631680734156213
begin epoch : 2
nll_loss: 20.254873395573302
begin epoch : 3
nll_loss: 18.71863306668362
The learning rate has beed reduced
begin epoch : 4
nll_loss: 17.792366100153682
begin epoch : 5
nll_loss: 17.579149742752534
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1637
begin the training process
begin epoch : 1
nll_loss: 43.75585144042969
begin epoch : 2
nll_loss: 36.80514724731445
begin epoch : 3
nll_loss: 32.97608993530273
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.046507034301758
begin epoch : 5
nll_loss: 30.547551498413085
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5595
begin the training process
begin epoch : 1
nll_loss: 35.720576165736404
begin epoch : 2
nll_loss: 26.885786494989503
begin epoch : 3
nll_loss: 24.456171978479144
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.341689252305304
begin epoch : 5
nll_loss: 23.047804733802533
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3998
begin the training process
begin epoch : 1
nll_loss: 38.048104224666474
begin epoch : 2
nll_loss: 28.81463115446029
begin epoch : 3
nll_loss: 25.910295794087073
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.88763793822258
begin epoch : 5
nll_loss: 24.59109607819588
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3022
begin the training process
begin epoch : 1
nll_loss: 39.87633912106778
begin epoch : 2
nll_loss: 30.58869706823471
begin epoch : 3
nll_loss: 27.081367817330868
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.010313845695332
begin epoch : 5
nll_loss: 25.75254529587766
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 41656
begin the training process
begin epoch : 1
nll_loss: 26.78971450512226
begin epoch : 2
nll_loss: 21.89200524843656
begin epoch : 3
nll_loss: 21.088801237253044
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.759145554762622
begin epoch : 5
nll_loss: 20.695390657278207
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2547
begin the training process
begin epoch : 1
nll_loss: 42.47427778977614
begin epoch : 2
nll_loss: 33.78039247561724
begin epoch : 3
nll_loss: 29.525286650046326
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.16913037422376
begin epoch : 5
nll_loss: 27.89520977704953
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7532
begin the training process
begin epoch : 1
nll_loss: 33.87066881880801
begin epoch : 2
nll_loss: 25.692427382509933
begin epoch : 3
nll_loss: 23.24192945366232
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.370081681471603
begin epoch : 5
nll_loss: 22.152480312901684
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 11059
begin the training process
begin epoch : 1
nll_loss: 31.446625964586126
begin epoch : 2
nll_loss: 24.116691012715183
begin epoch : 3
nll_loss: 21.963183768959933
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.193695123805558
begin epoch : 5
nll_loss: 21.022626289101535
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7814
begin the training process
begin epoch : 1
nll_loss: 34.02526611578269
begin epoch : 2
nll_loss: 26.11354494876549
begin epoch : 3
nll_loss: 23.803213479088956
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.80441409251729
begin epoch : 5
nll_loss: 22.539790872667655
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5114
begin the training process
begin epoch : 1
nll_loss: 36.683915560758564
begin epoch : 2
nll_loss: 27.86230495308019
begin epoch : 3
nll_loss: 25.583016673220865
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.463500469545775
begin epoch : 5
nll_loss: 24.15003250218645
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1770
begin the training process
begin epoch : 1
nll_loss: 44.52119431672273
begin epoch : 2
nll_loss: 36.92269826818396
begin epoch : 3
nll_loss: 32.91874666567202
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.0876139888057
begin epoch : 5
nll_loss: 30.58782605771665
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 44851
begin the training process
begin epoch : 1
nll_loss: 25.65879704611642
begin epoch : 2
nll_loss: 21.23691332953317
begin epoch : 3
nll_loss: 20.676020663125176
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.40694159099034
begin epoch : 5
nll_loss: 20.35729847771781
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2864
begin the training process
begin epoch : 1
nll_loss: 41.22844141179865
begin epoch : 2
nll_loss: 32.33521487496116
begin epoch : 3
nll_loss: 29.08467721939087
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.128059907393023
begin epoch : 5
nll_loss: 27.911649227142334
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6429
begin the training process
begin epoch : 1
nll_loss: 34.79957786560058
begin epoch : 2
nll_loss: 26.11070899963379
begin epoch : 3
nll_loss: 23.61613233566284
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.522785930633546
begin epoch : 5
nll_loss: 22.25996488571167
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2111
begin the training process
begin epoch : 1
nll_loss: 43.21261692047119
begin epoch : 2
nll_loss: 35.224692583084106
begin epoch : 3
nll_loss: 31.143405318260193
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.740188479423523
begin epoch : 5
nll_loss: 29.461416840553284
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 78171
begin the training process
begin epoch : 1
nll_loss: 24.003860331479885
begin epoch : 2
nll_loss: 20.532822628474253
begin epoch : 3
nll_loss: 20.212935129801433
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.022302588510474
begin epoch : 5
nll_loss: 19.989328176637443
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1477
begin the training process
begin epoch : 1
nll_loss: 44.70365938932999
begin epoch : 2
nll_loss: 38.32914733886719
begin epoch : 3
nll_loss: 34.3642637833305
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.56609344482422
begin epoch : 5
nll_loss: 32.029186912204906
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2692
begin the training process
begin epoch : 1
nll_loss: 41.466163271949405
begin epoch : 2
nll_loss: 32.46153123038156
begin epoch : 3
nll_loss: 28.70394166310628
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.430786632356188
begin epoch : 5
nll_loss: 27.106825465247745
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1630
begin the training process
begin epoch : 1
nll_loss: 43.41126495361328
begin epoch : 2
nll_loss: 35.20446937561035
begin epoch : 3
nll_loss: 31.521139450073242
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.646075973510744
begin epoch : 5
nll_loss: 29.033635482788085
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2231
begin the training process
begin epoch : 1
nll_loss: 43.30066377976362
begin epoch : 2
nll_loss: 35.68108435238109
begin epoch : 3
nll_loss: 31.438334352829877
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.674313096439136
begin epoch : 5
nll_loss: 29.32095017152674
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 76260
begin the training process
begin epoch : 1
nll_loss: 22.409693686727913
begin epoch : 2
nll_loss: 19.58696024884305
begin epoch : 3
nll_loss: 19.38051781546259
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.23167586146434
begin epoch : 5
nll_loss: 19.207282536376134
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1514
begin the training process
begin epoch : 1
nll_loss: 44.20690138443656
begin epoch : 2
nll_loss: 36.66401722120202
begin epoch : 3
nll_loss: 33.116156204887055
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.416741495547086
begin epoch : 5
nll_loss: 30.951131737750508
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 780932
begin the training process
begin epoch : 1
nll_loss: 21.613519058640208
begin epoch : 2
nll_loss: 20.93273453539736
begin epoch : 3
nll_loss: 20.747358187869462
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.529438014109395
begin epoch : 5
nll_loss: 20.485131946201697
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2687
begin the training process
begin epoch : 1
nll_loss: 41.401754891000145
begin epoch : 2
nll_loss: 32.55906830764398
begin epoch : 3
nll_loss: 28.92167147194467
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.99073512379716
begin epoch : 5
nll_loss: 27.71055454161109
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3907
begin the training process
begin epoch : 1
nll_loss: 39.54767414780914
begin epoch : 2
nll_loss: 30.684494675182904
begin epoch : 3
nll_loss: 27.89567762906434
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.838069040267193
begin epoch : 5
nll_loss: 26.533188679179208
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2087
begin the training process
begin epoch : 1
nll_loss: 42.58242106437683
begin epoch : 2
nll_loss: 34.40853214263916
begin epoch : 3
nll_loss: 30.09059238433838
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.99653321504593
begin epoch : 5
nll_loss: 27.600090861320496
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1341
begin the training process
begin epoch : 1
nll_loss: 45.182535552978514
begin epoch : 2
nll_loss: 37.83741912841797
begin epoch : 3
nll_loss: 34.03981819152832
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.57111644744873
begin epoch : 5
nll_loss: 32.099387073516844
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 29170
begin the training process
begin epoch : 1
nll_loss: 28.503783974280726
begin epoch : 2
nll_loss: 22.74658781198355
begin epoch : 3
nll_loss: 21.609880602490772
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.1627686552949
begin epoch : 5
nll_loss: 21.07309439103682
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 18120
begin the training process
begin epoch : 1
nll_loss: 30.58382670533952
begin epoch : 2
nll_loss: 23.731221519173666
begin epoch : 3
nll_loss: 22.098555217783357
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.583519265003
begin epoch : 5
nll_loss: 21.46869612919568
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6259
begin the training process
begin epoch : 1
nll_loss: 34.757319420883334
begin epoch : 2
nll_loss: 25.614544642340277
begin epoch : 3
nll_loss: 23.562088838557607
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.811700860249626
begin epoch : 5
nll_loss: 22.61671738772048
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 46774
begin the training process
begin epoch : 1
nll_loss: 26.241866501063516
begin epoch : 2
nll_loss: 21.628884059435702
begin epoch : 3
nll_loss: 21.03832051786658
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.767798899297844
begin epoch : 5
nll_loss: 20.71625167115094
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2609
begin the training process
begin epoch : 1
nll_loss: 42.05828199386597
begin epoch : 2
nll_loss: 33.234119749069215
begin epoch : 3
nll_loss: 29.64390540122986
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.525257873535157
begin epoch : 5
nll_loss: 28.193913984298707
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2705
begin the training process
begin epoch : 1
nll_loss: 42.57139523824056
begin epoch : 2
nll_loss: 34.01358913239979
begin epoch : 3
nll_loss: 29.909192811875116
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.8509129569644
begin epoch : 5
nll_loss: 28.574660392034623
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 15793
begin the training process
begin epoch : 1
nll_loss: 28.878514685281893
begin epoch : 2
nll_loss: 21.617479122751128
begin epoch : 3
nll_loss: 20.24738513357271
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.849727684889384
begin epoch : 5
nll_loss: 19.76447131769444
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7504
begin the training process
begin epoch : 1
nll_loss: 33.531214021209976
begin epoch : 2
nll_loss: 25.336208098973984
begin epoch : 3
nll_loss: 22.904173272287743
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.880320589766544
begin epoch : 5
nll_loss: 21.644694548386795
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2437
begin the training process
begin epoch : 1
nll_loss: 42.84104036030016
begin epoch : 2
nll_loss: 33.87666335858797
begin epoch : 3
nll_loss: 29.68400182222065
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.42041432230096
begin epoch : 5
nll_loss: 28.15809520922209
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3572
begin the training process
begin epoch : 1
nll_loss: 40.945070925625885
begin epoch : 2
nll_loss: 31.625881507179955
begin epoch : 3
nll_loss: 28.5173414403742
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.496906661987303
begin epoch : 5
nll_loss: 27.179058907248756
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 934
begin the training process
begin epoch : 1
nll_loss: 45.24054227556501
begin epoch : 2
nll_loss: 39.24556922912598
begin epoch : 3
nll_loss: 35.2072696685791
The learning rate has beed reduced
begin epoch : 4
nll_loss: 33.4775630405971
begin epoch : 5
nll_loss: 32.88716288975307
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 101827
begin the training process
begin epoch : 1
nll_loss: 21.49849741808054
begin epoch : 2
nll_loss: 19.213797174258325
begin epoch : 3
nll_loss: 19.038418483913958
The learning rate has beed reduced
begin epoch : 4
nll_loss: 18.8975672694889
begin epoch : 5
nll_loss: 18.8749361104144
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5259
begin the training process
begin epoch : 1
nll_loss: 35.88893427499911
begin epoch : 2
nll_loss: 26.80681321679092
begin epoch : 3
nll_loss: 24.43660666302937
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.348048140362994
begin epoch : 5
nll_loss: 23.060737795946075
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2252
begin the training process
begin epoch : 1
nll_loss: 43.367154584612166
begin epoch : 2
nll_loss: 34.76344255719866
begin epoch : 3
nll_loss: 30.287394605364117
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.691287449428014
begin epoch : 5
nll_loss: 28.396056093488422
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8217
begin the training process
begin epoch : 1
nll_loss: 34.784734681248665
begin epoch : 2
nll_loss: 26.24554881453514
begin epoch : 3
nll_loss: 24.19012661278248
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.378593742847443
begin epoch : 5
nll_loss: 23.181060269474983
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1012
begin the training process
begin epoch : 1
nll_loss: 46.730673472086586
begin epoch : 2
nll_loss: 40.461822764078775
begin epoch : 3
nll_loss: 36.33466161092122
The learning rate has beed reduced
begin epoch : 4
nll_loss: 34.54712905883789
begin epoch : 5
nll_loss: 33.956129455566405
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 689250
begin the training process
begin epoch : 1
nll_loss: 22.255837983435956
begin epoch : 2
nll_loss: 20.863509660002272
begin epoch : 3
nll_loss: 20.41494141861261
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.007451425035725
begin epoch : 5
nll_loss: 19.927420686198783
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 84897
begin the training process
begin epoch : 1
nll_loss: 22.085193646979008
begin epoch : 2
nll_loss: 19.421883381689657
begin epoch : 3
nll_loss: 19.19731969387463
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.043584225224514
begin epoch : 5
nll_loss: 19.01705630836084
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 22168
begin the training process
begin epoch : 1
nll_loss: 29.452845441123653
begin epoch : 2
nll_loss: 22.117940621568977
begin epoch : 3
nll_loss: 18.957825859158024
The learning rate has beed reduced
begin epoch : 4
nll_loss: 17.15124851017329
begin epoch : 5
nll_loss: 16.668872337120806
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4498
begin the training process
begin epoch : 1
nll_loss: 38.83128588540213
begin epoch : 2
nll_loss: 29.869251087733677
begin epoch : 3
nll_loss: 27.360988671439035
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.349637140546527
begin epoch : 5
nll_loss: 26.12266821180071
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 34494
begin the training process
begin epoch : 1
nll_loss: 27.124841824783267
begin epoch : 2
nll_loss: 21.700411598035394
begin epoch : 3
nll_loss: 20.915103082763217
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.596678411207236
begin epoch : 5
nll_loss: 20.535209648671202
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 16707
begin the training process
begin epoch : 1
nll_loss: 30.92484809612406
begin epoch : 2
nll_loss: 24.533024652707624
begin epoch : 3
nll_loss: 22.799731492082735
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.133253784472
begin epoch : 5
nll_loss: 21.992967890596937
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3163
begin the training process
begin epoch : 1
nll_loss: 40.616889019401704
begin epoch : 2
nll_loss: 31.952693705656092
begin epoch : 3
nll_loss: 29.05404114236637
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.910451577634227
begin epoch : 5
nll_loss: 27.59787758029237
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 40879
begin the training process
begin epoch : 1
nll_loss: 26.468229404437505
begin epoch : 2
nll_loss: 21.67479892658963
begin epoch : 3
nll_loss: 21.02436322777249
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.73699513797102
begin epoch : 5
nll_loss: 20.680754724341128
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2228
begin the training process
begin epoch : 1
nll_loss: 42.69118690490723
begin epoch : 2
nll_loss: 34.52988938724293
begin epoch : 3
nll_loss: 30.07245910868925
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.383124239304486
begin epoch : 5
nll_loss: 28.0232515335083
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 62031
begin the training process
begin epoch : 1
nll_loss: 22.810897067358372
begin epoch : 2
nll_loss: 19.497574555246455
begin epoch : 3
nll_loss: 19.27255634823574
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.12244681997073
begin epoch : 5
nll_loss: 19.097766514040984
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 342256
begin the training process
begin epoch : 1
nll_loss: 21.982924911002478
begin epoch : 2
nll_loss: 19.44147603998279
begin epoch : 3
nll_loss: 18.707585145541167
The learning rate has beed reduced
begin epoch : 4
nll_loss: 18.163172894155554
begin epoch : 5
nll_loss: 18.051830341687978
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1948
begin the training process
begin epoch : 1
nll_loss: 41.81503499348958
begin epoch : 2
nll_loss: 33.93670711517334
begin epoch : 3
nll_loss: 29.886929257710776
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.129919560750327
begin epoch : 5
nll_loss: 27.709966087341307
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7106
begin the training process
begin epoch : 1
nll_loss: 34.044922356132986
begin epoch : 2
nll_loss: 25.43177202585581
begin epoch : 3
nll_loss: 23.380197903057475
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.559267250267236
begin epoch : 5
nll_loss: 22.32545876717782
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 125389
begin the training process
begin epoch : 1
nll_loss: 23.23342779061209
begin epoch : 2
nll_loss: 21.348119193403743
begin epoch : 3
nll_loss: 21.00203438642501
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.690215321570527
begin epoch : 5
nll_loss: 20.610883408021174
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 48527
begin the training process
begin epoch : 1
nll_loss: 25.5553321813216
begin epoch : 2
nll_loss: 21.335643058716464
begin epoch : 3
nll_loss: 20.871571462827497
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.628906521759436
begin epoch : 5
nll_loss: 20.58253541659554
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6549
begin the training process
begin epoch : 1
nll_loss: 33.809524928822235
begin epoch : 2
nll_loss: 25.439204384298886
begin epoch : 3
nll_loss: 23.213552643271054
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.2983538683723
begin epoch : 5
nll_loss: 22.061248106115006
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1797
begin the training process
begin epoch : 1
nll_loss: 45.1147643498012
begin epoch : 2
nll_loss: 36.98835645403181
begin epoch : 3
nll_loss: 32.55950934546335
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.592421872275217
begin epoch : 5
nll_loss: 30.133738926478795
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3830
begin the training process
begin epoch : 1
nll_loss: 39.66757499565512
begin epoch : 2
nll_loss: 30.79999438786911
begin epoch : 3
nll_loss: 28.17996959363
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.200986635887016
begin epoch : 5
nll_loss: 26.931959184549623
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6774
begin the training process
begin epoch : 1
nll_loss: 36.2657719930013
begin epoch : 2
nll_loss: 27.83426428295317
begin epoch : 3
nll_loss: 25.570950299217586
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.496793674287343
begin epoch : 5
nll_loss: 24.262642451695033
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4798
begin the training process
begin epoch : 1
nll_loss: 38.225417575320684
begin epoch : 2
nll_loss: 28.703275706316973
begin epoch : 3
nll_loss: 26.02453847833582
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.06949994370744
begin epoch : 5
nll_loss: 24.779540474350387
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 121105
begin the training process
begin epoch : 1
nll_loss: 21.29946644865685
begin epoch : 2
nll_loss: 19.23379582632924
begin epoch : 3
nll_loss: 19.09163601353103
The learning rate has beed reduced
begin epoch : 4
nll_loss: 18.962847296329684
begin epoch : 5
nll_loss: 18.941586803936303
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10262
begin the training process
begin epoch : 1
nll_loss: 32.295554840564726
begin epoch : 2
nll_loss: 24.080694174766542
begin epoch : 3
nll_loss: 21.906307923793793
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.08406274318695
begin epoch : 5
nll_loss: 20.904192245006563
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5021
begin the training process
begin epoch : 1
nll_loss: 37.90312639872233
begin epoch : 2
nll_loss: 29.437806056096004
begin epoch : 3
nll_loss: 26.882683142637596
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.700818917690178
begin epoch : 5
nll_loss: 25.40983151166867
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 334212
begin the training process
begin epoch : 1
nll_loss: 21.058086260485492
begin epoch : 2
nll_loss: 20.069104280110203
begin epoch : 3
nll_loss: 19.96339810647895
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.832514857113566
begin epoch : 5
nll_loss: 19.80962284129043
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 534862
begin the training process
begin epoch : 1
nll_loss: 21.60678022735439
begin epoch : 2
nll_loss: 19.774676645773514
begin epoch : 3
nll_loss: 19.251839383389942
The learning rate has beed reduced
begin epoch : 4
nll_loss: 18.795059882411977
begin epoch : 5
nll_loss: 18.704271424939304
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1424
begin the training process
begin epoch : 1
nll_loss: 44.654448075727984
begin epoch : 2
nll_loss: 37.57807592912154
begin epoch : 3
nll_loss: 34.35697451504794
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.675124168395996
begin epoch : 5
nll_loss: 32.139492295005105
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 393794
begin the training process
begin epoch : 1
nll_loss: 21.712256984131017
begin epoch : 2
nll_loss: 19.33718079651117
begin epoch : 3
nll_loss: 18.685864471021404
The learning rate has beed reduced
begin epoch : 4
nll_loss: 18.1626945506765
begin epoch : 5
nll_loss: 18.0596184280274
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 17546
begin the training process
begin epoch : 1
nll_loss: 29.355043306837988
begin epoch : 2
nll_loss: 22.818046110389876
begin epoch : 3
nll_loss: 21.5348201807398
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.122624828867668
begin epoch : 5
nll_loss: 21.03531503329312
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 19509
begin the training process
begin epoch : 1
nll_loss: 27.554412961006165
begin epoch : 2
nll_loss: 21.381611466407776
begin epoch : 3
nll_loss: 20.253054298852618
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.84224414198022
begin epoch : 5
nll_loss: 19.747823545807286
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5227
begin the training process
begin epoch : 1
nll_loss: 37.30524260909469
begin epoch : 2
nll_loss: 28.787353421434943
begin epoch : 3
nll_loss: 26.581337916998216
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.65059475839874
begin epoch : 5
nll_loss: 25.37400151476448
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 92780
begin the training process
begin epoch : 1
nll_loss: 23.035833340336158
begin epoch : 2
nll_loss: 20.27025756546347
begin epoch : 3
nll_loss: 20.033279126722128
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.85175275572256
begin epoch : 5
nll_loss: 19.82057814272294
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 14865
begin the training process
begin epoch : 1
nll_loss: 30.471056058489044
begin epoch : 2
nll_loss: 23.426560105948614
begin epoch : 3
nll_loss: 21.974087320525072
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.454206885962652
begin epoch : 5
nll_loss: 21.33850359916687
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2355
begin the training process
begin epoch : 1
nll_loss: 42.992110464308
begin epoch : 2
nll_loss: 34.75583102968004
begin epoch : 3
nll_loss: 31.04802147547404
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.85990826288859
begin epoch : 5
nll_loss: 29.536603768666584
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 13029
begin the training process
begin epoch : 1
nll_loss: 32.338309602784406
begin epoch : 2
nll_loss: 25.201923154257788
begin epoch : 3
nll_loss: 23.14751407078334
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.37481529724422
begin epoch : 5
nll_loss: 22.196619231125403
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6352
begin the training process
begin epoch : 1
nll_loss: 36.3272349617698
begin epoch : 2
nll_loss: 27.89332898457845
begin epoch : 3
nll_loss: 25.665509734490904
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.71546298325664
begin epoch : 5
nll_loss: 24.442483747848357
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 14650
begin the training process
begin epoch : 1
nll_loss: 29.468392045874346
begin epoch : 2
nll_loss: 22.616710102348996
begin epoch : 3
nll_loss: 21.156024288712885
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.600977136377704
begin epoch : 5
nll_loss: 20.47134260545697
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3595
begin the training process
begin epoch : 1
nll_loss: 38.67855330875942
begin epoch : 2
nll_loss: 29.409577131271362
begin epoch : 3
nll_loss: 26.523226976394653
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.611436469214304
begin epoch : 5
nll_loss: 25.33674168586731
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 54305
begin the training process
begin epoch : 1
nll_loss: 23.735598186276995
begin epoch : 2
nll_loss: 20.366184322339183
begin epoch : 3
nll_loss: 20.041741899724276
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.838588584144162
begin epoch : 5
nll_loss: 19.797678067999065
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2439
begin the training process
begin epoch : 1
nll_loss: 41.21815821998998
begin epoch : 2
nll_loss: 32.177306275618704
begin epoch : 3
nll_loss: 28.10980355112176
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.784272294295462
begin epoch : 5
nll_loss: 26.437626186170075
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 95115
begin the training process
begin epoch : 1
nll_loss: 22.815652145190644
begin epoch : 2
nll_loss: 20.390463809787345
begin epoch : 3
nll_loss: 20.079933239666
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.840146422867498
begin epoch : 5
nll_loss: 19.78473398149575
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4253
begin the training process
begin epoch : 1
nll_loss: 39.038106455947414
begin epoch : 2
nll_loss: 30.16575154391202
begin epoch : 3
nll_loss: 27.554922277277168
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.591874209317293
begin epoch : 5
nll_loss: 26.31783930460612
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 818
begin the training process
begin epoch : 1
nll_loss: 45.445425033569336
begin epoch : 2
nll_loss: 40.341657638549805
begin epoch : 3
nll_loss: 36.71387195587158
The learning rate has beed reduced
begin epoch : 4
nll_loss: 34.99299971262614
begin epoch : 5
nll_loss: 34.46536954243978
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 100391
begin the training process
begin epoch : 1
nll_loss: 22.92565072555931
begin epoch : 2
nll_loss: 20.669456546403925
begin epoch : 3
nll_loss: 20.33041624268707
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.041519610249267
begin epoch : 5
nll_loss: 19.973947514076624
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4319
begin the training process
begin epoch : 1
nll_loss: 38.43291951649225
begin epoch : 2
nll_loss: 29.647355293160054
begin epoch : 3
nll_loss: 27.22315663010327
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.185005301859842
begin epoch : 5
nll_loss: 25.876258309207746
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12197
begin the training process
begin epoch : 1
nll_loss: 31.46317754042776
begin epoch : 2
nll_loss: 24.073366667094984
begin epoch : 3
nll_loss: 22.27276043139006
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.72085582331607
begin epoch : 5
nll_loss: 21.60475317302503
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4201
begin the training process
begin epoch : 1
nll_loss: 37.840442569439226
begin epoch : 2
nll_loss: 28.117404292179987
begin epoch : 3
nll_loss: 25.28061872629019
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.286856108445388
begin epoch : 5
nll_loss: 23.95386355473445
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 14266
begin the training process
begin epoch : 1
nll_loss: 31.809987695367486
begin epoch : 2
nll_loss: 24.91712419836371
begin epoch : 3
nll_loss: 22.882412730036556
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.14424095497475
begin epoch : 5
nll_loss: 21.96845429222863
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6005
begin the training process
begin epoch : 1
nll_loss: 34.60967035191033
begin epoch : 2
nll_loss: 26.231260463755618
begin epoch : 3
nll_loss: 24.174435482230237
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.269237887474798
begin epoch : 5
nll_loss: 23.032152360485448
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8225
begin the training process
begin epoch : 1
nll_loss: 34.853524670004845
begin epoch : 2
nll_loss: 27.306794360280037
begin epoch : 3
nll_loss: 25.25067773461342
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.296914130449295
begin epoch : 5
nll_loss: 24.008297756314278
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3325
begin the training process
begin epoch : 1
nll_loss: 40.14159475588331
begin epoch : 2
nll_loss: 31.816652746761548
begin epoch : 3
nll_loss: 28.57048397438199
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.419233733532476
begin epoch : 5
nll_loss: 27.113631341971605
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 434423
begin the training process
begin epoch : 1
nll_loss: 20.26546136145917
begin epoch : 2
nll_loss: 19.494259852978026
begin epoch : 3
nll_loss: 19.41010407065193
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.29258346754338
begin epoch : 5
nll_loss: 19.273090512056633
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1377
begin the training process
begin epoch : 1
nll_loss: 45.18696103777204
begin epoch : 2
nll_loss: 37.76787240164621
begin epoch : 3
nll_loss: 33.995504288446334
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.174160548618865
begin epoch : 5
nll_loss: 31.71884282430013
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1134194
begin the training process
begin epoch : 1
nll_loss: 21.567841180418544
begin epoch : 2
nll_loss: 20.920669671691478
begin epoch : 3
nll_loss: 20.721369232148458
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.48429695864737
begin epoch : 5
nll_loss: 20.436583222509284
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12114
begin the training process
begin epoch : 1
nll_loss: 30.764606374912162
begin epoch : 2
nll_loss: 23.408237053603724
begin epoch : 3
nll_loss: 21.234452303124485
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.521444542698127
begin epoch : 5
nll_loss: 20.385965498666916
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3414
begin the training process
begin epoch : 1
nll_loss: 38.71050388408157
begin epoch : 2
nll_loss: 29.220381574810677
begin epoch : 3
nll_loss: 26.155620898840564
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.18108436296571
begin epoch : 5
nll_loss: 24.881488260233176
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 18879
begin the training process
begin epoch : 1
nll_loss: 29.69006174437854
begin epoch : 2
nll_loss: 23.044674399758684
begin epoch : 3
nll_loss: 21.719991314167878
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.260031142202365
begin epoch : 5
nll_loss: 21.170997360125693
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 855
begin the training process
begin epoch : 1
nll_loss: 46.8334605877216
begin epoch : 2
nll_loss: 42.59965515136719
begin epoch : 3
nll_loss: 38.819974165696365
The learning rate has beed reduced
begin epoch : 4
nll_loss: 36.89699583787184
begin epoch : 5
nll_loss: 36.294322380652794
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 13842
begin the training process
begin epoch : 1
nll_loss: 30.96368987471969
begin epoch : 2
nll_loss: 23.514276645801687
begin epoch : 3
nll_loss: 21.31348172823588
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.67869950223852
begin epoch : 5
nll_loss: 20.557762958385325
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 840
begin the training process
begin epoch : 1
nll_loss: 46.10708500788762
begin epoch : 2
nll_loss: 41.24487275343675
begin epoch : 3
nll_loss: 37.2650381234976
The learning rate has beed reduced
begin epoch : 4
nll_loss: 35.51942150409405
begin epoch : 5
nll_loss: 34.94173959585336
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1321
begin the training process
begin epoch : 1
nll_loss: 45.629340934753415
begin epoch : 2
nll_loss: 38.76750259399414
begin epoch : 3
nll_loss: 35.01807880401611
The learning rate has beed reduced
begin epoch : 4
nll_loss: 33.18437461853027
begin epoch : 5
nll_loss: 32.61257524490357
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1807
begin the training process
begin epoch : 1
nll_loss: 43.52628667013986
begin epoch : 2
nll_loss: 35.37788881574358
begin epoch : 3
nll_loss: 31.675923074994767
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.911534922463552
begin epoch : 5
nll_loss: 29.494837760925293
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6465
begin the training process
begin epoch : 1
nll_loss: 34.69203803562882
begin epoch : 2
nll_loss: 25.762652161097762
begin epoch : 3
nll_loss: 23.176488026533978
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.897863671331123
begin epoch : 5
nll_loss: 21.61133873816764
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1927
begin the training process
begin epoch : 1
nll_loss: 44.61841163635254
begin epoch : 2
nll_loss: 36.86607259114583
begin epoch : 3
nll_loss: 32.27396055857341
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.62040812174479
begin epoch : 5
nll_loss: 30.261590894063314
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4822
begin the training process
begin epoch : 1
nll_loss: 37.756204249064126
begin epoch : 2
nll_loss: 28.87960594177246
begin epoch : 3
nll_loss: 26.044573872884115
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.936700642903645
begin epoch : 5
nll_loss: 24.62193229675293
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 139314
begin the training process
begin epoch : 1
nll_loss: 22.67531737246934
begin epoch : 2
nll_loss: 20.87381633940865
begin epoch : 3
nll_loss: 20.60230426490307
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.353400771232213
begin epoch : 5
nll_loss: 20.29653663933277
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6518
begin the training process
begin epoch : 1
nll_loss: 36.96038181947009
begin epoch : 2
nll_loss: 28.75175681916794
begin epoch : 3
nll_loss: 26.487027574293684
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.3901681239062
begin epoch : 5
nll_loss: 25.115432739257812
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1715
begin the training process
begin epoch : 1
nll_loss: 44.201173048753006
begin epoch : 2
nll_loss: 36.951159697312576
begin epoch : 3
nll_loss: 33.29907336601844
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.535761466393105
begin epoch : 5
nll_loss: 31.026935797471268
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3496
begin the training process
begin epoch : 1
nll_loss: 41.10919217710142
begin epoch : 2
nll_loss: 32.07294902095088
begin epoch : 3
nll_loss: 29.03222536157679
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.012686164290816
begin epoch : 5
nll_loss: 27.750449816385906
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 34207
begin the training process
begin epoch : 1
nll_loss: 26.746513498856334
begin epoch : 2
nll_loss: 21.58693081430728
begin epoch : 3
nll_loss: 20.909626564283048
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.603327983327574
begin epoch : 5
nll_loss: 20.546535599097776
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6269
begin the training process
begin epoch : 1
nll_loss: 36.21829046662321
begin epoch : 2
nll_loss: 28.319736697010157
begin epoch : 3
nll_loss: 26.16106605529785
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.15777511203412
begin epoch : 5
nll_loss: 24.865476844237023
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 773701
begin the training process
begin epoch : 1
nll_loss: 21.784000116361362
begin epoch : 2
nll_loss: 21.08226389904276
begin epoch : 3
nll_loss: 20.920370050336107
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.726159538087916
begin epoch : 5
nll_loss: 20.68642707955345
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3014
begin the training process
begin epoch : 1
nll_loss: 40.11754762365463
begin epoch : 2
nll_loss: 30.77327724213296
begin epoch : 3
nll_loss: 27.430363066652987
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.30497952725025
begin epoch : 5
nll_loss: 25.989538071003366
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7927
begin the training process
begin epoch : 1
nll_loss: 33.24610869865107
begin epoch : 2
nll_loss: 25.0146853594276
begin epoch : 3
nll_loss: 22.645461167746443
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.643744771073504
begin epoch : 5
nll_loss: 21.3938215767465
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1460
begin the training process
begin epoch : 1
nll_loss: 44.95851447365501
begin epoch : 2
nll_loss: 38.477664947509766
begin epoch : 3
nll_loss: 34.8485331101851
The learning rate has beed reduced
begin epoch : 4
nll_loss: 33.124246250499375
begin epoch : 5
nll_loss: 32.60471933538263
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3951
begin the training process
begin epoch : 1
nll_loss: 38.207599358480486
begin epoch : 2
nll_loss: 28.737949902894066
begin epoch : 3
nll_loss: 25.89262912312492
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.90517497453533
begin epoch : 5
nll_loss: 24.58622841756852
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 473
begin the training process
begin epoch : 1
nll_loss: 47.46388135637556
begin epoch : 2
nll_loss: 44.89767074584961
begin epoch : 3
nll_loss: 41.76574107578823
The learning rate has beed reduced
begin epoch : 4
nll_loss: 39.828430720738005
begin epoch : 5
nll_loss: 39.445247650146484
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12322
begin the training process
begin epoch : 1
nll_loss: 32.42832873264948
begin epoch : 2
nll_loss: 25.101782610019047
begin epoch : 3
nll_loss: 22.87429003914197
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.06693120797475
begin epoch : 5
nll_loss: 21.916250973939896
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 89867
begin the training process
begin epoch : 1
nll_loss: 23.94326022139981
begin epoch : 2
nll_loss: 21.0307340458927
begin epoch : 3
nll_loss: 20.582413995367848
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.265808576871866
begin epoch : 5
nll_loss: 20.19227467778741
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8744
begin the training process
begin epoch : 1
nll_loss: 33.719517553553864
begin epoch : 2
nll_loss: 25.486331771401797
begin epoch : 3
nll_loss: 23.21145211949068
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.37245775671566
begin epoch : 5
nll_loss: 22.16833459629732
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2662
begin the training process
begin epoch : 1
nll_loss: 41.15865065411823
begin epoch : 2
nll_loss: 32.63766163151438
begin epoch : 3
nll_loss: 28.749316006171995
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.32127459456281
begin epoch : 5
nll_loss: 27.04509925842285
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3282
begin the training process
begin epoch : 1
nll_loss: 40.490536633659815
begin epoch : 2
nll_loss: 31.04842305650898
begin epoch : 3
nll_loss: 27.563943975112018
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.44341771742877
begin epoch : 5
nll_loss: 26.144623438517254
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9941
begin the training process
begin epoch : 1
nll_loss: 32.235984285416144
begin epoch : 2
nll_loss: 24.353745651245116
begin epoch : 3
nll_loss: 22.09716033935547
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.17893568469632
begin epoch : 5
nll_loss: 20.994711586736862
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 33683
begin the training process
begin epoch : 1
nll_loss: 27.32583796570056
begin epoch : 2
nll_loss: 21.967275434573793
begin epoch : 3
nll_loss: 21.17037006929347
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.847924964962804
begin epoch : 5
nll_loss: 20.782001408334015
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2178
begin the training process
begin epoch : 1
nll_loss: 41.42861220415901
begin epoch : 2
nll_loss: 32.797437723945166
begin epoch : 3
nll_loss: 29.046437600079706
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.564287858850815
begin epoch : 5
nll_loss: 27.219907311832202
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1597
begin the training process
begin epoch : 1
nll_loss: 45.09087880452474
begin epoch : 2
nll_loss: 37.652360121409096
begin epoch : 3
nll_loss: 33.476599295934044
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.471137921015423
begin epoch : 5
nll_loss: 30.971794764200848
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2334
begin the training process
begin epoch : 1
nll_loss: 42.80707677205404
begin epoch : 2
nll_loss: 34.01086579428779
begin epoch : 3
nll_loss: 29.940825515323215
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.522530873616535
begin epoch : 5
nll_loss: 28.200648731655544
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2397
begin the training process
begin epoch : 1
nll_loss: 42.911677798709356
begin epoch : 2
nll_loss: 35.11735503737991
begin epoch : 3
nll_loss: 31.509608294512773
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.252209019016576
begin epoch : 5
nll_loss: 29.931876878480654
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 143881
begin the training process
begin epoch : 1
nll_loss: 22.996422568249958
begin epoch : 2
nll_loss: 21.06362058004875
begin epoch : 3
nll_loss: 20.57929626817805
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.162637561241503
begin epoch : 5
nll_loss: 20.053106116230378
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1501
begin the training process
begin epoch : 1
nll_loss: 43.7689731432044
begin epoch : 2
nll_loss: 35.583741727082625
begin epoch : 3
nll_loss: 32.00208249299423
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.26271737140158
begin epoch : 5
nll_loss: 29.75329142031462
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2870
begin the training process
begin epoch : 1
nll_loss: 42.15149359269576
begin epoch : 2
nll_loss: 33.30636085163463
begin epoch : 3
nll_loss: 29.77809784629128
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.69320873780684
begin epoch : 5
nll_loss: 28.398882909254596
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 38069
begin the training process
begin epoch : 1
nll_loss: 25.268696730385727
begin epoch : 2
nll_loss: 20.350163523998326
begin epoch : 3
nll_loss: 19.797139305859705
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.558614759734184
begin epoch : 5
nll_loss: 19.517874033764155
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7034
begin the training process
begin epoch : 1
nll_loss: 34.06506116674581
begin epoch : 2
nll_loss: 25.66130109664497
begin epoch : 3
nll_loss: 23.276407854272684
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.197132128094314
begin epoch : 5
nll_loss: 21.929537571898294
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5136
begin the training process
begin epoch : 1
nll_loss: 35.798041224479675
begin epoch : 2
nll_loss: 26.34788136482239
begin epoch : 3
nll_loss: 23.849167132377623
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.992364907264708
begin epoch : 5
nll_loss: 22.778743267059326
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12199
begin the training process
begin epoch : 1
nll_loss: 32.609252959803534
begin epoch : 2
nll_loss: 24.83899679685894
begin epoch : 3
nll_loss: 22.880496978759766
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.278744567068
begin epoch : 5
nll_loss: 22.145062968605444
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1998
begin the training process
begin epoch : 1
nll_loss: 41.86818645846459
begin epoch : 2
nll_loss: 34.14795530996015
begin epoch : 3
nll_loss: 30.322508781186997
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.286936667657667
begin epoch : 5
nll_loss: 27.710908151442005
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 174760
begin the training process
begin epoch : 1
nll_loss: 22.24381712819194
begin epoch : 2
nll_loss: 20.747094282213148
begin epoch : 3
nll_loss: 20.532078153309804
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.315663093175644
begin epoch : 5
nll_loss: 20.265658414232863
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2658
begin the training process
begin epoch : 1
nll_loss: 42.26842182438548
begin epoch : 2
nll_loss: 33.36118288737972
begin epoch : 3
nll_loss: 29.44403760026141
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.305416665426115
begin epoch : 5
nll_loss: 28.060815857677923
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2629
begin the training process
begin epoch : 1
nll_loss: 41.739039630424685
begin epoch : 2
nll_loss: 33.22041618533251
begin epoch : 3
nll_loss: 29.352202159602466
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.183555556506647
begin epoch : 5
nll_loss: 27.88486694708103
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 18430
begin the training process
begin epoch : 1
nll_loss: 28.709694726126536
begin epoch : 2
nll_loss: 21.811627836592937
begin epoch : 3
nll_loss: 20.257810665755322
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.815041472272174
begin epoch : 5
nll_loss: 19.74079946856881
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 25130
begin the training process
begin epoch : 1
nll_loss: 27.12107438943824
begin epoch : 2
nll_loss: 21.404087251546432
begin epoch : 3
nll_loss: 20.475040314148885
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.138929907156495
begin epoch : 5
nll_loss: 20.069915863932394
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10987
begin the training process
begin epoch : 1
nll_loss: 31.415554091247202
begin epoch : 2
nll_loss: 23.37476681268703
begin epoch : 3
nll_loss: 21.23572429857756
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.594313136318274
begin epoch : 5
nll_loss: 20.461173498142532
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2940
begin the training process
begin epoch : 1
nll_loss: 40.05214708116319
begin epoch : 2
nll_loss: 30.850047726101344
begin epoch : 3
nll_loss: 26.64488826327854
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.4268499162462
begin epoch : 5
nll_loss: 25.096517266167535
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4371
begin the training process
begin epoch : 1
nll_loss: 38.87207451988669
begin epoch : 2
nll_loss: 29.508766651153564
begin epoch : 3
nll_loss: 26.598479242885816
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.51454765656415
begin epoch : 5
nll_loss: 25.250972018522376
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 17528
begin the training process
begin epoch : 1
nll_loss: 30.561343636704887
begin epoch : 2
nll_loss: 24.10070394858336
begin epoch : 3
nll_loss: 22.492321279896046
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.879429597121018
begin epoch : 5
nll_loss: 21.744455086005914
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 11800
begin the training process
begin epoch : 1
nll_loss: 31.37921785271686
begin epoch : 2
nll_loss: 23.982520155284714
begin epoch : 3
nll_loss: 21.759635272233382
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.90350914001465
begin epoch : 5
nll_loss: 20.735062163809072
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1494
begin the training process
begin epoch : 1
nll_loss: 43.32029193380605
begin epoch : 2
nll_loss: 35.46888898766559
begin epoch : 3
nll_loss: 31.25190021680749
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.454122792119566
begin epoch : 5
nll_loss: 28.844937034275222
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9751
begin the training process
begin epoch : 1
nll_loss: 33.362322317926505
begin epoch : 2
nll_loss: 26.099564401726973
begin epoch : 3
nll_loss: 23.926202648564388
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.93287633594714
begin epoch : 5
nll_loss: 22.68138787620946
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2971
begin the training process
begin epoch : 1
nll_loss: 41.41530949136485
begin epoch : 2
nll_loss: 32.48726558685303
begin epoch : 3
nll_loss: 28.949867829032566
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.90881820346998
begin epoch : 5
nll_loss: 27.625004561051078
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2632
begin the training process
begin epoch : 1
nll_loss: 42.39312706924066
begin epoch : 2
nll_loss: 34.066246823566715
begin epoch : 3
nll_loss: 30.23479684969274
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.034938207486782
begin epoch : 5
nll_loss: 28.760097689744903
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6896
begin the training process
begin epoch : 1
nll_loss: 34.876785527879946
begin epoch : 2
nll_loss: 26.31340312066479
begin epoch : 3
nll_loss: 23.88991182986821
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.612726104593722
begin epoch : 5
nll_loss: 22.27280393939152
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10518
begin the training process
begin epoch : 1
nll_loss: 31.137743426532282
begin epoch : 2
nll_loss: 23.4937914871588
begin epoch : 3
nll_loss: 21.79980466423965
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.05677708183847
begin epoch : 5
nll_loss: 20.87321852474678
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2933
begin the training process
begin epoch : 1
nll_loss: 40.1128406100803
begin epoch : 2
nll_loss: 31.258886761135525
begin epoch : 3
nll_loss: 27.62224015129937
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.555406697591145
begin epoch : 5
nll_loss: 26.260080422295463
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2289
begin the training process
begin epoch : 1
nll_loss: 42.66984677995954
begin epoch : 2
nll_loss: 34.9796859741211
begin epoch : 3
nll_loss: 31.299009704589842
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.663024520874025
begin epoch : 5
nll_loss: 29.27482239859445
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 705
begin the training process
begin epoch : 1
nll_loss: 46.42194019664418
begin epoch : 2
nll_loss: 41.812753503972836
begin epoch : 3
nll_loss: 37.782623291015625
The learning rate has beed reduced
begin epoch : 4
nll_loss: 36.11971040205522
begin epoch : 5
nll_loss: 35.618587493896484
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7010
begin the training process
begin epoch : 1
nll_loss: 35.854050277569975
begin epoch : 2
nll_loss: 27.324604244407166
begin epoch : 3
nll_loss: 24.818255363254373
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.710175365482996
begin epoch : 5
nll_loss: 23.440822443830857
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 55875
begin the training process
begin epoch : 1
nll_loss: 25.400216424861178
begin epoch : 2
nll_loss: 21.019425797435154
begin epoch : 3
nll_loss: 19.32375722188174
The learning rate has beed reduced
begin epoch : 4
nll_loss: 18.168708539091025
begin epoch : 5
nll_loss: 17.868173763104732
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2045
begin the training process
begin epoch : 1
nll_loss: 43.0464240043394
begin epoch : 2
nll_loss: 34.69153804163779
begin epoch : 3
nll_loss: 30.918042152158677
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.824143809656942
begin epoch : 5
nll_loss: 28.28299940786054
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10469
begin the training process
begin epoch : 1
nll_loss: 31.875646825217032
begin epoch : 2
nll_loss: 24.498178224622105
begin epoch : 3
nll_loss: 22.401136842973393
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.516605377197266
begin epoch : 5
nll_loss: 21.338272235144867
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3363
begin the training process
begin epoch : 1
nll_loss: 39.634930463937614
begin epoch : 2
nll_loss: 30.25799252436711
begin epoch : 3
nll_loss: 26.265203035794773
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.15870002599863
begin epoch : 5
nll_loss: 24.84779273546659
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7906
begin the training process
begin epoch : 1
nll_loss: 35.35831665411228
begin epoch : 2
nll_loss: 27.26388222609109
begin epoch : 3
nll_loss: 25.00527287304886
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.91835845389017
begin epoch : 5
nll_loss: 23.672132399024033
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 291248
begin the training process
begin epoch : 1
nll_loss: 21.346833323803576
begin epoch : 2
nll_loss: 18.011683708232837
begin epoch : 3
nll_loss: 17.202742102905944
The learning rate has beed reduced
begin epoch : 4
nll_loss: 16.621525503724484
begin epoch : 5
nll_loss: 16.510945357228373
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3151
begin the training process
begin epoch : 1
nll_loss: 39.43237690049775
begin epoch : 2
nll_loss: 29.901567147702586
begin epoch : 3
nll_loss: 26.112012318202428
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.079348194355866
begin epoch : 5
nll_loss: 24.808762063785476
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5667
begin the training process
begin epoch : 1
nll_loss: 37.05177456682379
begin epoch : 2
nll_loss: 28.466508930379693
begin epoch : 3
nll_loss: 26.19894983551719
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.315864021127876
begin epoch : 5
nll_loss: 25.10500366037542
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 340542
begin the training process
begin epoch : 1
nll_loss: 21.268489132429423
begin epoch : 2
nll_loss: 18.740425479860235
begin epoch : 3
nll_loss: 18.108977176730793
The learning rate has beed reduced
begin epoch : 4
nll_loss: 17.619830870628356
begin epoch : 5
nll_loss: 17.523996988812783
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3212
begin the training process
begin epoch : 1
nll_loss: 39.123777885437015
begin epoch : 2
nll_loss: 29.93153636932373
begin epoch : 3
nll_loss: 26.290441513061523
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.11822696685791
begin epoch : 5
nll_loss: 24.820372276306152
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3505
begin the training process
begin epoch : 1
nll_loss: 38.42017625879358
begin epoch : 2
nll_loss: 28.689604300039786
begin epoch : 3
nll_loss: 25.510288344489204
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.399122556050617
begin epoch : 5
nll_loss: 24.076380411783855
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9866
begin the training process
begin epoch : 1
nll_loss: 32.39425583628865
begin epoch : 2
nll_loss: 24.66789300101144
begin epoch : 3
nll_loss: 22.655340120389862
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.901745920057422
begin epoch : 5
nll_loss: 21.706109046936035
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1723
begin the training process
begin epoch : 1
nll_loss: 43.4445319542518
begin epoch : 2
nll_loss: 35.50118725116436
begin epoch : 3
nll_loss: 31.431139799264763
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.412308546213005
begin epoch : 5
nll_loss: 28.86822142967811
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 25145
begin the training process
begin epoch : 1
nll_loss: 28.518751231991516
begin epoch : 2
nll_loss: 22.884050967741985
begin epoch : 3
nll_loss: 21.76873247477473
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.361457357601243
begin epoch : 5
nll_loss: 21.272966623306274
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8393
begin the training process
begin epoch : 1
nll_loss: 34.63611538719585
begin epoch : 2
nll_loss: 27.153634617346842
begin epoch : 3
nll_loss: 24.82886692949834
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.660969129955497
begin epoch : 5
nll_loss: 23.391137902063267
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 874
begin the training process
begin epoch : 1
nll_loss: 45.25701317420373
begin epoch : 2
nll_loss: 40.690859867976265
begin epoch : 3
nll_loss: 36.697687295766976
The learning rate has beed reduced
begin epoch : 4
nll_loss: 34.66771962092473
begin epoch : 5
nll_loss: 34.11537815974309
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5190
begin the training process
begin epoch : 1
nll_loss: 36.226768776222514
begin epoch : 2
nll_loss: 27.17823664347331
begin epoch : 3
nll_loss: 24.661042743259006
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.73203190462089
begin epoch : 5
nll_loss: 23.467625347184548
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2743
begin the training process
begin epoch : 1
nll_loss: 40.19845635550363
begin epoch : 2
nll_loss: 32.08189260391962
begin epoch : 3
nll_loss: 27.800815627688454
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.359822909037273
begin epoch : 5
nll_loss: 26.004717191060383
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1731
begin the training process
begin epoch : 1
nll_loss: 43.633146639223455
begin epoch : 2
nll_loss: 35.658229686595774
begin epoch : 3
nll_loss: 31.31928867763943
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.276629553900825
begin epoch : 5
nll_loss: 28.799087524414062
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5258
begin the training process
begin epoch : 1
nll_loss: 37.279547342439976
begin epoch : 2
nll_loss: 28.388542477677507
begin epoch : 3
nll_loss: 26.12784139121451
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.07127464108351
begin epoch : 5
nll_loss: 24.772250082434677
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9968
begin the training process
begin epoch : 1
nll_loss: 32.59412619067776
begin epoch : 2
nll_loss: 24.706997816024288
begin epoch : 3
nll_loss: 22.746387740104428
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.945334120719664
begin epoch : 5
nll_loss: 21.784587601692447
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2899
begin the training process
begin epoch : 1
nll_loss: 40.098546769883896
begin epoch : 2
nll_loss: 30.793638526068793
begin epoch : 3
nll_loss: 27.09772644042969
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.005304718017577
begin epoch : 5
nll_loss: 25.73434172736274
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3498
begin the training process
begin epoch : 1
nll_loss: 40.04144972342032
begin epoch : 2
nll_loss: 31.425449265374077
begin epoch : 3
nll_loss: 28.228193636293764
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.274836292973273
begin epoch : 5
nll_loss: 26.95639557308621
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 811
begin the training process
begin epoch : 1
nll_loss: 46.72742621103922
begin epoch : 2
nll_loss: 42.20558293660482
begin epoch : 3
nll_loss: 38.351173400878906
The learning rate has beed reduced
begin epoch : 4
nll_loss: 36.31964651743571
begin epoch : 5
nll_loss: 35.825433095296226
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2119
begin the training process
begin epoch : 1
nll_loss: 42.0016862117883
begin epoch : 2
nll_loss: 33.21230125427246
begin epoch : 3
nll_loss: 29.04881379098603
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.693710384946883
begin epoch : 5
nll_loss: 27.41727534207431
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2242
begin the training process
begin epoch : 1
nll_loss: 42.82888750348772
begin epoch : 2
nll_loss: 34.9857129233224
begin epoch : 3
nll_loss: 31.522529220581056
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.020374189104352
begin epoch : 5
nll_loss: 29.64785679408482
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 546437
begin the training process
begin epoch : 1
nll_loss: 22.21274127164918
begin epoch : 2
nll_loss: 20.38193568504228
begin epoch : 3
nll_loss: 19.81377465888582
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.345690040070103
begin epoch : 5
nll_loss: 19.252779783033102
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1586
begin the training process
begin epoch : 1
nll_loss: 43.86552953720093
begin epoch : 2
nll_loss: 36.46840222676595
begin epoch : 3
nll_loss: 32.53255502382914
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.485363245010376
begin epoch : 5
nll_loss: 30.008266766866047
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4108
begin the training process
begin epoch : 1
nll_loss: 37.57874235510826
begin epoch : 2
nll_loss: 27.47059178352356
begin epoch : 3
nll_loss: 24.410854548215866
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.427197992801666
begin epoch : 5
nll_loss: 23.186250120401382
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1664
begin the training process
begin epoch : 1
nll_loss: 44.594660392174355
begin epoch : 2
nll_loss: 36.8609372652494
begin epoch : 3
nll_loss: 32.4029363485483
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.486865557157078
begin epoch : 5
nll_loss: 30.03381773141714
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2606
begin the training process
begin epoch : 1
nll_loss: 40.46739501953125
begin epoch : 2
nll_loss: 32.07523484230042
begin epoch : 3
nll_loss: 28.037163639068602
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.736593627929686
begin epoch : 5
nll_loss: 26.42617311477661
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2286
begin the training process
begin epoch : 1
nll_loss: 42.972149985177175
begin epoch : 2
nll_loss: 34.358338601248605
begin epoch : 3
nll_loss: 30.097434834071567
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.519083186558316
begin epoch : 5
nll_loss: 28.229344994681224
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 40326
begin the training process
begin epoch : 1
nll_loss: 25.027439695691307
begin epoch : 2
nll_loss: 20.23739673069545
begin epoch : 3
nll_loss: 19.793539761740064
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.583538194686646
begin epoch : 5
nll_loss: 19.546873816232832
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2848
begin the training process
begin epoch : 1
nll_loss: 41.88607059825551
begin epoch : 2
nll_loss: 33.39824520457875
begin epoch : 3
nll_loss: 29.536194801330566
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.27430885488337
begin epoch : 5
nll_loss: 27.962636774236504
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4284
begin the training process
begin epoch : 1
nll_loss: 38.77355303908839
begin epoch : 2
nll_loss: 29.74796011953643
begin epoch : 3
nll_loss: 27.145323782256156
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.141101577065207
begin epoch : 5
nll_loss: 25.852282524108887
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2554
begin the training process
begin epoch : 1
nll_loss: 41.005589607434395
begin epoch : 2
nll_loss: 32.32831465892303
begin epoch : 3
nll_loss: 28.49513073456593
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.239154766767452
begin epoch : 5
nll_loss: 26.937960795867138
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3101
begin the training process
begin epoch : 1
nll_loss: 40.570865074793495
begin epoch : 2
nll_loss: 31.42716145515442
begin epoch : 3
nll_loss: 27.556429783503216
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.332804759343464
begin epoch : 5
nll_loss: 26.00002400080363
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2032
begin the training process
begin epoch : 1
nll_loss: 41.47952405868038
begin epoch : 2
nll_loss: 33.151598099739324
begin epoch : 3
nll_loss: 29.583192763790006
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.86797554262223
begin epoch : 5
nll_loss: 27.501044919413904
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 832
begin the training process
begin epoch : 1
nll_loss: 46.74747760479267
begin epoch : 2
nll_loss: 41.800888354961685
begin epoch : 3
nll_loss: 38.171755864070015
The learning rate has beed reduced
begin epoch : 4
nll_loss: 36.455984555757965
begin epoch : 5
nll_loss: 35.930353311391976
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2441
begin the training process
begin epoch : 1
nll_loss: 43.149071542840254
begin epoch : 2
nll_loss: 34.0087574406674
begin epoch : 3
nll_loss: 30.152803722180817
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.00649070739746
begin epoch : 5
nll_loss: 28.73443061427066
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4538
begin the training process
begin epoch : 1
nll_loss: 38.19014467511858
begin epoch : 2
nll_loss: 28.429498263767787
begin epoch : 3
nll_loss: 25.6681521824428
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.55555030277797
begin epoch : 5
nll_loss: 24.223096575055802
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1551
begin the training process
begin epoch : 1
nll_loss: 43.78804381688436
begin epoch : 2
nll_loss: 35.336666425069176
begin epoch : 3
nll_loss: 31.31004532178243
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.468551953633625
begin epoch : 5
nll_loss: 28.993361632029217
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12595
begin the training process
begin epoch : 1
nll_loss: 30.57111812124447
begin epoch : 2
nll_loss: 23.283433534661118
begin epoch : 3
nll_loss: 21.310401897041164
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.627411122224768
begin epoch : 5
nll_loss: 20.497291370313995
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 244816
begin the training process
begin epoch : 1
nll_loss: 20.758086475546843
begin epoch : 2
nll_loss: 16.560457106197582
begin epoch : 3
nll_loss: 15.776189262789059
The learning rate has beed reduced
begin epoch : 4
nll_loss: 15.23949271183388
begin epoch : 5
nll_loss: 15.140767647487666
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8006
begin the training process
begin epoch : 1
nll_loss: 33.43985577392578
begin epoch : 2
nll_loss: 25.011757385253905
begin epoch : 3
nll_loss: 22.858523559570312
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.909185134887696
begin epoch : 5
nll_loss: 21.682522384643555
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 64595
begin the training process
begin epoch : 1
nll_loss: 24.77200981457713
begin epoch : 2
nll_loss: 21.232621154180247
begin epoch : 3
nll_loss: 20.867232212108238
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.657191793557082
begin epoch : 5
nll_loss: 20.619977440659188
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4792
begin the training process
begin epoch : 1
nll_loss: 38.67517561525912
begin epoch : 2
nll_loss: 29.853713035583496
begin epoch : 3
nll_loss: 27.367159327945195
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.350325146236933
begin epoch : 5
nll_loss: 26.03375210633149
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2000
begin the training process
begin epoch : 1
nll_loss: 42.68023927750126
begin epoch : 2
nll_loss: 34.96037575506395
begin epoch : 3
nll_loss: 30.861017965501354
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.01432861820344
begin epoch : 5
nll_loss: 28.565269900906472
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1832
begin the training process
begin epoch : 1
nll_loss: 43.074160712105886
begin epoch : 2
nll_loss: 35.43361404963902
begin epoch : 3
nll_loss: 31.59293065752302
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.560660226004465
begin epoch : 5
nll_loss: 29.121115139552526
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9363
begin the training process
begin epoch : 1
nll_loss: 32.293755296158466
begin epoch : 2
nll_loss: 24.522613381686277
begin epoch : 3
nll_loss: 22.324268876689754
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.39940184763033
begin epoch : 5
nll_loss: 21.173595415402765
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 85843
begin the training process
begin epoch : 1
nll_loss: 23.774310953309516
begin epoch : 2
nll_loss: 20.76253886297512
begin epoch : 3
nll_loss: 20.44812366448615
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.255186136403605
begin epoch : 5
nll_loss: 20.221706282283545
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3068
begin the training process
begin epoch : 1
nll_loss: 41.023549343677274
begin epoch : 2
nll_loss: 31.412184654398168
begin epoch : 3
nll_loss: 28.41369251494712
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.501090272944023
begin epoch : 5
nll_loss: 27.232150179274537
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 13683
begin the training process
begin epoch : 1
nll_loss: 31.023636652270394
begin epoch : 2
nll_loss: 24.33184684610143
begin epoch : 3
nll_loss: 22.533092059999564
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.868614877333663
begin epoch : 5
nll_loss: 21.7245341556173
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 26910
begin the training process
begin epoch : 1
nll_loss: 26.309260831560408
begin epoch : 2
nll_loss: 20.509057857876734
begin epoch : 3
nll_loss: 19.86094566526867
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.580658917199997
begin epoch : 5
nll_loss: 19.526803420838856
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2420
begin the training process
begin epoch : 1
nll_loss: 42.55391321955501
begin epoch : 2
nll_loss: 34.03829363230113
begin epoch : 3
nll_loss: 30.19670867919922
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.00017078502758
begin epoch : 5
nll_loss: 28.716065741874075
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4443
begin the training process
begin epoch : 1
nll_loss: 38.63599583722543
begin epoch : 2
nll_loss: 29.812486399774965
begin epoch : 3
nll_loss: 27.53414659914763
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.344178213589434
begin epoch : 5
nll_loss: 25.904119049293406
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2536
begin the training process
begin epoch : 1
nll_loss: 40.95794022388947
begin epoch : 2
nll_loss: 32.49561882019043
begin epoch : 3
nll_loss: 28.72286023849096
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.36221582461626
begin epoch : 5
nll_loss: 27.052106319329678
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2657
begin the training process
begin epoch : 1
nll_loss: 41.77619887561333
begin epoch : 2
nll_loss: 33.15050027428604
begin epoch : 3
nll_loss: 29.66606507650236
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.53895257158977
begin epoch : 5
nll_loss: 28.288067050096465
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5948
begin the training process
begin epoch : 1
nll_loss: 37.127200893733814
begin epoch : 2
nll_loss: 28.92578929403554
begin epoch : 3
nll_loss: 26.746376597363017
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.638736144356105
begin epoch : 5
nll_loss: 25.297780451567277
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 26102
begin the training process
begin epoch : 1
nll_loss: 26.838419368284633
begin epoch : 2
nll_loss: 21.042750782697148
begin epoch : 3
nll_loss: 20.324639669507377
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.0600186940786
begin epoch : 5
nll_loss: 20.00567169564362
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1547
begin the training process
begin epoch : 1
nll_loss: 43.39730501174927
begin epoch : 2
nll_loss: 35.856536865234375
begin epoch : 3
nll_loss: 32.2100285689036
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.449944734573364
begin epoch : 5
nll_loss: 29.96076464653015
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5036
begin the training process
begin epoch : 1
nll_loss: 37.407922867016914
begin epoch : 2
nll_loss: 28.9725284576416
begin epoch : 3
nll_loss: 26.68781615526248
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.604710701184395
begin epoch : 5
nll_loss: 25.255719600579678
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 448
begin the training process
begin epoch : 1
nll_loss: 46.348328181675505
begin epoch : 2
nll_loss: 43.6930171421596
begin epoch : 3
nll_loss: 40.68851579938616
The learning rate has beed reduced
begin epoch : 4
nll_loss: 38.799187251499724
begin epoch : 5
nll_loss: 38.14237594604492
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 724394
begin the training process
begin epoch : 1
nll_loss: 22.098221812068754
begin epoch : 2
nll_loss: 21.132883172507924
begin epoch : 3
nll_loss: 20.81707747561031
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.50440226799398
begin epoch : 5
nll_loss: 20.439460664402997
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 23409
begin the training process
begin epoch : 1
nll_loss: 27.021539134195407
begin epoch : 2
nll_loss: 20.966844083185066
begin epoch : 3
nll_loss: 20.294903491294548
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.027077510258923
begin epoch : 5
nll_loss: 19.96763254453058
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3227
begin the training process
begin epoch : 1
nll_loss: 39.7762718963623
begin epoch : 2
nll_loss: 30.347946014404297
begin epoch : 3
nll_loss: 26.617964897155762
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.63944267272949
begin epoch : 5
nll_loss: 25.332604217529298
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5258
begin the training process
begin epoch : 1
nll_loss: 35.84584792067365
begin epoch : 2
nll_loss: 26.53897255222972
begin epoch : 3
nll_loss: 24.04678363334842
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.197097662018567
begin epoch : 5
nll_loss: 22.975375128955378
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 23308
begin the training process
begin epoch : 1
nll_loss: 29.18454505585052
begin epoch : 2
nll_loss: 22.84473167670952
begin epoch : 3
nll_loss: 21.788724474854522
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.380672994550768
begin epoch : 5
nll_loss: 21.291333921663053
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 49247
begin the training process
begin epoch : 1
nll_loss: 26.301398496789027
begin epoch : 2
nll_loss: 21.83902738990337
begin epoch : 3
nll_loss: 21.211607175313606
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.92437429390896
begin epoch : 5
nll_loss: 20.872499470902977
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2406
begin the training process
begin epoch : 1
nll_loss: 42.66940926216744
begin epoch : 2
nll_loss: 34.82413054801322
begin epoch : 3
nll_loss: 30.971635148331927
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.563225565729915
begin epoch : 5
nll_loss: 29.227199915293102
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2857
begin the training process
begin epoch : 1
nll_loss: 40.89197904413397
begin epoch : 2
nll_loss: 31.583191438154742
begin epoch : 3
nll_loss: 27.746873118660666
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.63546679236672
begin epoch : 5
nll_loss: 26.344796874306418
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3526
begin the training process
begin epoch : 1
nll_loss: 38.54302486072887
begin epoch : 2
nll_loss: 29.609882181340996
begin epoch : 3
nll_loss: 26.5675311348655
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.485395431518555
begin epoch : 5
nll_loss: 25.18823706886985
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4367
begin the training process
begin epoch : 1
nll_loss: 38.41072775335873
begin epoch : 2
nll_loss: 30.32072126164156
begin epoch : 3
nll_loss: 27.940491956823013
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.860397282768698
begin epoch : 5
nll_loss: 26.57600997476017
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2013
begin the training process
begin epoch : 1
nll_loss: 43.39639245310137
begin epoch : 2
nll_loss: 35.91042130993259
begin epoch : 3
nll_loss: 31.45855817487163
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.583752724432177
begin epoch : 5
nll_loss: 29.202226392684445
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 430337
begin the training process
begin epoch : 1
nll_loss: 21.199810189763966
begin epoch : 2
nll_loss: 20.197530143109198
begin epoch : 3
nll_loss: 19.984677090097367
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.76129948305701
begin epoch : 5
nll_loss: 19.7148845361713
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3714
begin the training process
begin epoch : 1
nll_loss: 39.10692017653893
begin epoch : 2
nll_loss: 30.304969064120588
begin epoch : 3
nll_loss: 27.058521895573058
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.8339272860823
begin epoch : 5
nll_loss: 25.50387872498611
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4874
begin the training process
begin epoch : 1
nll_loss: 38.02416179054662
begin epoch : 2
nll_loss: 28.64767092152646
begin epoch : 3
nll_loss: 26.082238172229967
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.13158901114213
begin epoch : 5
nll_loss: 24.891003608703613
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4911
begin the training process
begin epoch : 1
nll_loss: 36.8945830495734
begin epoch : 2
nll_loss: 27.549680709838867
begin epoch : 3
nll_loss: 25.02848876150031
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.99198112989727
begin epoch : 5
nll_loss: 23.679938993955915
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7041
begin the training process
begin epoch : 1
nll_loss: 34.00880941911177
begin epoch : 2
nll_loss: 25.406437995217065
begin epoch : 3
nll_loss: 22.950856330178002
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.909524380077016
begin epoch : 5
nll_loss: 21.66972758553245
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3718
begin the training process
begin epoch : 1
nll_loss: 38.481829676134836
begin epoch : 2
nll_loss: 28.57230419948183
begin epoch : 3
nll_loss: 25.792273389882055
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.999669075012207
begin epoch : 5
nll_loss: 24.748101957913104
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 27035
begin the training process
begin epoch : 1
nll_loss: 26.330188068733396
begin epoch : 2
nll_loss: 20.909464510696193
begin epoch : 3
nll_loss: 20.216515328646835
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.935052812946918
begin epoch : 5
nll_loss: 19.868453911695436
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4859
begin the training process
begin epoch : 1
nll_loss: 36.5513198852539
begin epoch : 2
nll_loss: 27.00815434773763
begin epoch : 3
nll_loss: 24.609553502400715
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.622989247639975
begin epoch : 5
nll_loss: 23.389773763020834
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 58868
begin the training process
begin epoch : 1
nll_loss: 25.210546277682333
begin epoch : 2
nll_loss: 21.23218295415934
begin epoch : 3
nll_loss: 20.81176755114401
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.580264561583608
begin epoch : 5
nll_loss: 20.53780925987335
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 773
begin the training process
begin epoch : 1
nll_loss: 45.86187267303467
begin epoch : 2
nll_loss: 41.03515625
begin epoch : 3
nll_loss: 37.02377160390218
The learning rate has beed reduced
begin epoch : 4
nll_loss: 35.33970959981283
begin epoch : 5
nll_loss: 34.81677563985189
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 927
begin the training process
begin epoch : 1
nll_loss: 46.10294778006418
begin epoch : 2
nll_loss: 40.19364520481655
begin epoch : 3
nll_loss: 36.05561855861119
The learning rate has beed reduced
begin epoch : 4
nll_loss: 34.127040318080354
begin epoch : 5
nll_loss: 33.55131993974958
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 19127
begin the training process
begin epoch : 1
nll_loss: 29.13139358622916
begin epoch : 2
nll_loss: 22.95685208723849
begin epoch : 3
nll_loss: 21.608002118616294
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.163884598136747
begin epoch : 5
nll_loss: 21.071464020133817
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 100895
begin the training process
begin epoch : 1
nll_loss: 23.21819171445624
begin epoch : 2
nll_loss: 20.39319374234543
begin epoch : 3
nll_loss: 20.15354180941122
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.983261696578282
begin epoch : 5
nll_loss: 19.956158859475615
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5581
begin the training process
begin epoch : 1
nll_loss: 37.58723335704584
begin epoch : 2
nll_loss: 28.669899688369927
begin epoch : 3
nll_loss: 26.611794745785065
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.738367409541688
begin epoch : 5
nll_loss: 25.462029950372106
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2640
begin the training process
begin epoch : 1
nll_loss: 41.9452101544636
begin epoch : 2
nll_loss: 33.5275282976104
begin epoch : 3
nll_loss: 29.843944363477753
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.643554780541397
begin epoch : 5
nll_loss: 28.37669958719393
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 11786
begin the training process
begin epoch : 1
nll_loss: 30.51530978990638
begin epoch : 2
nll_loss: 23.405167973559834
begin epoch : 3
nll_loss: 21.916906864746757
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.269440536913663
begin epoch : 5
nll_loss: 21.108438740605894
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4668
begin the training process
begin epoch : 1
nll_loss: 37.78494148784213
begin epoch : 2
nll_loss: 28.98516188727485
begin epoch : 3
nll_loss: 26.73913155661689
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.648672607209946
begin epoch : 5
nll_loss: 25.345627625783283
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 18461
begin the training process
begin epoch : 1
nll_loss: 29.570532659689587
begin epoch : 2
nll_loss: 23.036895169152153
begin epoch : 3
nll_loss: 21.609874924023945
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.1939363612069
begin epoch : 5
nll_loss: 21.102586328983307
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 114141
begin the training process
begin epoch : 1
nll_loss: 22.881909993546635
begin epoch : 2
nll_loss: 20.252639754461693
begin epoch : 3
nll_loss: 20.00724753113991
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.83829644203721
begin epoch : 5
nll_loss: 19.809337293974682
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6702
begin the training process
begin epoch : 1
nll_loss: 34.21357556489798
begin epoch : 2
nll_loss: 24.978506014897274
begin epoch : 3
nll_loss: 22.571586425487812
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.680430082174446
begin epoch : 5
nll_loss: 21.42164573302636
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2516
begin the training process
begin epoch : 1
nll_loss: 41.909036978697166
begin epoch : 2
nll_loss: 33.48720721709422
begin epoch : 3
nll_loss: 29.544865877200397
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.29714031708546
begin epoch : 5
nll_loss: 28.043335205469376
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6833
begin the training process
begin epoch : 1
nll_loss: 36.23769141143223
begin epoch : 2
nll_loss: 27.677031319096404
begin epoch : 3
nll_loss: 25.36715525501179
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.26557603872047
begin epoch : 5
nll_loss: 23.991537507974876
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9452
begin the training process
begin epoch : 1
nll_loss: 33.61684459245124
begin epoch : 2
nll_loss: 25.904198678983313
begin epoch : 3
nll_loss: 23.83483005705334
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.019392454705272
begin epoch : 5
nll_loss: 22.79074898544623
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 331746
begin the training process
begin epoch : 1
nll_loss: 21.85886417354324
begin epoch : 2
nll_loss: 18.90269971321661
begin epoch : 3
nll_loss: 18.105621558691162
The learning rate has beed reduced
begin epoch : 4
nll_loss: 17.507838159230324
begin epoch : 5
nll_loss: 17.388336476777344
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2857
begin the training process
begin epoch : 1
nll_loss: 41.469857389276676
begin epoch : 2
nll_loss: 32.449111765081234
begin epoch : 3
nll_loss: 28.845150210640647
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.77094403180209
begin epoch : 5
nll_loss: 27.468343604694713
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12501
begin the training process
begin epoch : 1
nll_loss: 30.322273381551106
begin epoch : 2
nll_loss: 22.897982083834133
begin epoch : 3
nll_loss: 21.278498243674253
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.605800794943786
begin epoch : 5
nll_loss: 20.46268056233724
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1117
begin the training process
begin epoch : 1
nll_loss: 45.857834086698645
begin epoch : 2
nll_loss: 40.67115514418658
begin epoch : 3
nll_loss: 36.577592064352594
The learning rate has beed reduced
begin epoch : 4
nll_loss: 34.42334320965935
begin epoch : 5
nll_loss: 33.870332156910614
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 43316
begin the training process
begin epoch : 1
nll_loss: 25.619107362081312
begin epoch : 2
nll_loss: 21.13849718613032
begin epoch : 3
nll_loss: 20.559657167400832
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.28503925278342
begin epoch : 5
nll_loss: 20.235783633395766
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3167
begin the training process
begin epoch : 1
nll_loss: 40.33194413477061
begin epoch : 2
nll_loss: 31.160975125371195
begin epoch : 3
nll_loss: 27.909943989345006
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.82685758629624
begin epoch : 5
nll_loss: 26.535809847773336
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1446
begin the training process
begin epoch : 1
nll_loss: 45.66119662198153
begin epoch : 2
nll_loss: 38.413632132790305
begin epoch : 3
nll_loss: 34.19391085884788
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.20512416146018
begin epoch : 5
nll_loss: 31.661244652488016
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3710
begin the training process
begin epoch : 1
nll_loss: 39.79110998856394
begin epoch : 2
nll_loss: 30.70295330516079
begin epoch : 3
nll_loss: 27.92929766470926
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.972969791345427
begin epoch : 5
nll_loss: 26.678074987311113
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9482
begin the training process
begin epoch : 1
nll_loss: 32.082637851302685
begin epoch : 2
nll_loss: 24.442617609694196
begin epoch : 3
nll_loss: 22.43356566815763
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.546305308470856
begin epoch : 5
nll_loss: 21.31349264608847
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 70421
begin the training process
begin epoch : 1
nll_loss: 23.52995367570357
begin epoch : 2
nll_loss: 20.674510059356688
begin epoch : 3
nll_loss: 20.28426358829845
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.985863604112104
begin epoch : 5
nll_loss: 19.909470518285577
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2879
begin the training process
begin epoch : 1
nll_loss: 41.36033110185103
begin epoch : 2
nll_loss: 32.61260262402621
begin epoch : 3
nll_loss: 29.018140619451348
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.01059579849243
begin epoch : 5
nll_loss: 27.79070910540494
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 461383
begin the training process
begin epoch : 1
nll_loss: 21.79658946363915
begin epoch : 2
nll_loss: 20.092812395935862
begin epoch : 3
nll_loss: 19.581430763258385
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.157288820274925
begin epoch : 5
nll_loss: 19.07017623715104
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 759
begin the training process
begin epoch : 1
nll_loss: 45.81204882535067
begin epoch : 2
nll_loss: 41.809505462646484
begin epoch : 3
nll_loss: 38.18393741954457
The learning rate has beed reduced
begin epoch : 4
nll_loss: 36.49486194957387
begin epoch : 5
nll_loss: 35.933367642489344
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2551
begin the training process
begin epoch : 1
nll_loss: 42.233805827605416
begin epoch : 2
nll_loss: 33.442033327542816
begin epoch : 3
nll_loss: 29.566781459710537
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.373764282617813
begin epoch : 5
nll_loss: 28.092459947634968
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 28011
begin the training process
begin epoch : 1
nll_loss: 26.015993646407836
begin epoch : 2
nll_loss: 20.38498124268835
begin epoch : 3
nll_loss: 19.676048213338962
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.413091934518356
begin epoch : 5
nll_loss: 19.36345172855892
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2686
begin the training process
begin epoch : 1
nll_loss: 39.75690255514005
begin epoch : 2
nll_loss: 31.05443345046625
begin epoch : 3
nll_loss: 27.529616937404725
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.367434013180617
begin epoch : 5
nll_loss: 26.13055392009456
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3540
begin the training process
begin epoch : 1
nll_loss: 40.29824849909002
begin epoch : 2
nll_loss: 31.414315657182172
begin epoch : 3
nll_loss: 28.395756704157048
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.278386688232423
begin epoch : 5
nll_loss: 26.95468777743253
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 327
begin the training process
begin epoch : 1
nll_loss: 48.037776184082034
begin epoch : 2
nll_loss: 46.498861694335936
begin epoch : 3
nll_loss: 44.37017822265625
The learning rate has beed reduced
begin epoch : 4
nll_loss: 42.66337356567383
begin epoch : 5
nll_loss: 42.266587829589845
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3222
begin the training process
begin epoch : 1
nll_loss: 40.69636962890625
begin epoch : 2
nll_loss: 32.037957954406735
begin epoch : 3
nll_loss: 28.725734939575194
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.660185089111327
begin epoch : 5
nll_loss: 27.35132080078125
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5515
begin the training process
begin epoch : 1
nll_loss: 37.29122206222179
begin epoch : 2
nll_loss: 28.156033205431562
begin epoch : 3
nll_loss: 25.70081265028133
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.678704195244368
begin epoch : 5
nll_loss: 24.43605848800304
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12078
begin the training process
begin epoch : 1
nll_loss: 32.96852109787312
begin epoch : 2
nll_loss: 25.711230551942865
begin epoch : 3
nll_loss: 23.45577419565079
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.634328416053286
begin epoch : 5
nll_loss: 22.453314263769922
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 257173
begin the training process
begin epoch : 1
nll_loss: 21.60645712638388
begin epoch : 2
nll_loss: 20.411311870667994
begin epoch : 3
nll_loss: 20.287298862349044
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.1496113800421
begin epoch : 5
nll_loss: 20.12462181425498
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1658
begin the training process
begin epoch : 1
nll_loss: 45.58281341552734
begin epoch : 2
nll_loss: 38.33955291748047
begin epoch : 3
nll_loss: 33.99418464660644
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.951431503295897
begin epoch : 5
nll_loss: 31.381220245361327
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6592
begin the training process
begin epoch : 1
nll_loss: 34.69860995394512
begin epoch : 2
nll_loss: 26.01389203488248
begin epoch : 3
nll_loss: 23.89266621487812
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.10679543134078
begin epoch : 5
nll_loss: 22.900755539681146
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 25024
begin the training process
begin epoch : 1
nll_loss: 28.804045757674196
begin epoch : 2
nll_loss: 22.843648617834692
begin epoch : 3
nll_loss: 21.769682540308178
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.34041287649013
begin epoch : 5
nll_loss: 21.257436279140776
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5281
begin the training process
begin epoch : 1
nll_loss: 38.236735460234854
begin epoch : 2
nll_loss: 29.204571002867162
begin epoch : 3
nll_loss: 26.631338840577662
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.515781332806842
begin epoch : 5
nll_loss: 25.23443694230987
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 26833
begin the training process
begin epoch : 1
nll_loss: 27.52485590732183
begin epoch : 2
nll_loss: 21.671891915769738
begin epoch : 3
nll_loss: 20.957318158024535
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.651233859733637
begin epoch : 5
nll_loss: 20.595221335108356
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6444
begin the training process
begin epoch : 1
nll_loss: 34.25102298736572
begin epoch : 2
nll_loss: 25.754157123565673
begin epoch : 3
nll_loss: 23.469221458435058
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.614438934326174
begin epoch : 5
nll_loss: 22.395362644195558
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 11056
begin the training process
begin epoch : 1
nll_loss: 30.99319727476253
begin epoch : 2
nll_loss: 23.22530570141105
begin epoch : 3
nll_loss: 21.454057172287342
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.809308273847712
begin epoch : 5
nll_loss: 20.653933292211487
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 13039
begin the training process
begin epoch : 1
nll_loss: 30.712417931392274
begin epoch : 2
nll_loss: 23.485358083189414
begin epoch : 3
nll_loss: 21.75616744468952
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.184135324262044
begin epoch : 5
nll_loss: 21.05788369953926
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 119164
begin the training process
begin epoch : 1
nll_loss: 22.781406250901917
begin epoch : 2
nll_loss: 20.75023465000257
begin epoch : 3
nll_loss: 20.518233364336854
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.30837699996727
begin epoch : 5
nll_loss: 20.265752907147785
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2034
begin the training process
begin epoch : 1
nll_loss: 43.2912222339261
begin epoch : 2
nll_loss: 36.07051061814831
begin epoch : 3
nll_loss: 31.68316404281124
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.591283121416645
begin epoch : 5
nll_loss: 29.129397423036636
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3347
begin the training process
begin epoch : 1
nll_loss: 40.118559250464806
begin epoch : 2
nll_loss: 30.597573867210976
begin epoch : 3
nll_loss: 27.876705976632927
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.048906252934383
begin epoch : 5
nll_loss: 26.768788227668175
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 50019
begin the training process
begin epoch : 1
nll_loss: 26.154714887181868
begin epoch : 2
nll_loss: 22.124834644351818
begin epoch : 3
nll_loss: 21.176402061452634
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.48840718629571
begin epoch : 5
nll_loss: 20.287490876475005
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3936
begin the training process
begin epoch : 1
nll_loss: 39.840133416848104
begin epoch : 2
nll_loss: 30.571238564663247
begin epoch : 3
nll_loss: 27.586298051427622
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.518633232742058
begin epoch : 5
nll_loss: 26.21761375177102
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12332
begin the training process
begin epoch : 1
nll_loss: 30.50458613038063
begin epoch : 2
nll_loss: 23.375008126099903
begin epoch : 3
nll_loss: 21.972875674565632
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.32228182752927
begin epoch : 5
nll_loss: 21.161493996779125
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1398
begin the training process
begin epoch : 1
nll_loss: 44.289376395089285
begin epoch : 2
nll_loss: 37.2577269417899
begin epoch : 3
nll_loss: 33.48446155729748
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.513539722987584
begin epoch : 5
nll_loss: 30.900634674798873
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 50409
begin the training process
begin epoch : 1
nll_loss: 26.16072654724121
begin epoch : 2
nll_loss: 21.68249970015607
begin epoch : 3
nll_loss: 21.159471310684612
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.908498141180907
begin epoch : 5
nll_loss: 20.866335642231768
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5559
begin the training process
begin epoch : 1
nll_loss: 36.09391651597134
begin epoch : 2
nll_loss: 27.72061212672744
begin epoch : 3
nll_loss: 25.44043864760288
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.344454476999683
begin epoch : 5
nll_loss: 24.057824112648188
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 89253
begin the training process
begin epoch : 1
nll_loss: 23.952857527876517
begin epoch : 2
nll_loss: 20.70363372983344
begin epoch : 3
nll_loss: 20.429379940717087
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.243545807245987
begin epoch : 5
nll_loss: 20.212062783699636
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 464
begin the training process
begin epoch : 1
nll_loss: 47.61975261143276
begin epoch : 2
nll_loss: 45.50570460728237
begin epoch : 3
nll_loss: 42.17210224696568
The learning rate has beed reduced
begin epoch : 4
nll_loss: 40.13219560895647
begin epoch : 5
nll_loss: 39.532776423863005
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 40209
begin the training process
begin epoch : 1
nll_loss: 26.19344813960373
begin epoch : 2
nll_loss: 21.447946791436262
begin epoch : 3
nll_loss: 20.866484608619835
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.600489127408167
begin epoch : 5
nll_loss: 20.550006398729458
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2706
begin the training process
begin epoch : 1
nll_loss: 40.8103696732294
begin epoch : 2
nll_loss: 32.251701082502095
begin epoch : 3
nll_loss: 28.375566119239444
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.980290957859584
begin epoch : 5
nll_loss: 26.632496606735955
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 81415
begin the training process
begin epoch : 1
nll_loss: 21.94261222365517
begin epoch : 2
nll_loss: 19.44799037849378
begin epoch : 3
nll_loss: 19.27519267759983
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.138267256178946
begin epoch : 5
nll_loss: 19.116632323594963
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 15746
begin the training process
begin epoch : 1
nll_loss: 31.091812102775265
begin epoch : 2
nll_loss: 24.179616284564258
begin epoch : 3
nll_loss: 22.371110404410015
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.705516412006162
begin epoch : 5
nll_loss: 21.55736961209677
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 20740
begin the training process
begin epoch : 1
nll_loss: 30.563895808325874
begin epoch : 2
nll_loss: 23.907453619403604
begin epoch : 3
nll_loss: 22.31167032689224
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.720513114222772
begin epoch : 5
nll_loss: 21.591153221365847
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 16617
begin the training process
begin epoch : 1
nll_loss: 28.7926749225749
begin epoch : 2
nll_loss: 22.22307303145125
begin epoch : 3
nll_loss: 20.942058489589616
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.49063289303577
begin epoch : 5
nll_loss: 20.392415889902004
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1295
begin the training process
begin epoch : 1
nll_loss: 45.62686634063721
begin epoch : 2
nll_loss: 38.61697006225586
begin epoch : 3
nll_loss: 34.491479110717776
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.707959461212155
begin epoch : 5
nll_loss: 32.124763870239256
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 208475
begin the training process
begin epoch : 1
nll_loss: 21.47590399330146
begin epoch : 2
nll_loss: 20.103252126279695
begin epoch : 3
nll_loss: 19.939955127799223
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.767186664092897
begin epoch : 5
nll_loss: 19.73186875268071
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2263
begin the training process
begin epoch : 1
nll_loss: 42.85822263445173
begin epoch : 2
nll_loss: 34.417430823189875
begin epoch : 3
nll_loss: 29.951087733677454
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.39731330871582
begin epoch : 5
nll_loss: 28.07046127319336
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 20334
begin the training process
begin epoch : 1
nll_loss: 28.982730612769863
begin epoch : 2
nll_loss: 22.70806162740906
begin epoch : 3
nll_loss: 21.565680897950372
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.117966366115052
begin epoch : 5
nll_loss: 21.022505167530912
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 388141
begin the training process
begin epoch : 1
nll_loss: 21.745330325217235
begin epoch : 2
nll_loss: 19.263876707384014
begin epoch : 3
nll_loss: 18.628742890339097
The learning rate has beed reduced
begin epoch : 4
nll_loss: 18.11827574068764
begin epoch : 5
nll_loss: 18.0163124688068
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3725
begin the training process
begin epoch : 1
nll_loss: 38.588304980047816
begin epoch : 2
nll_loss: 29.643688464986866
begin epoch : 3
nll_loss: 26.342464151053594
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.21435412045183
begin epoch : 5
nll_loss: 24.887883548078864
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 22202
begin the training process
begin epoch : 1
nll_loss: 27.696046079514343
begin epoch : 2
nll_loss: 21.351271667921473
begin epoch : 3
nll_loss: 20.23909179599299
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.88377441009345
begin epoch : 5
nll_loss: 19.817049721072863
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 13121
begin the training process
begin epoch : 1
nll_loss: 30.301294075570457
begin epoch : 2
nll_loss: 22.80494354061964
begin epoch : 3
nll_loss: 20.95737616376179
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.424125801644674
begin epoch : 5
nll_loss: 20.312255180172805
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6383
begin the training process
begin epoch : 1
nll_loss: 34.444102354723995
begin epoch : 2
nll_loss: 25.816435919867622
begin epoch : 3
nll_loss: 23.62060610453288
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.702367050479157
begin epoch : 5
nll_loss: 22.484978666209212
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 39657
begin the training process
begin epoch : 1
nll_loss: 26.004374092730643
begin epoch : 2
nll_loss: 21.35264745783151
begin epoch : 3
nll_loss: 20.753225104681704
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.49117018679617
begin epoch : 5
nll_loss: 20.439764537410706
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4271
begin the training process
begin epoch : 1
nll_loss: 39.54886147470185
begin epoch : 2
nll_loss: 29.573051192543723
begin epoch : 3
nll_loss: 26.93820670156768
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.829621892986875
begin epoch : 5
nll_loss: 25.53012521339185
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 17804
begin the training process
begin epoch : 1
nll_loss: 30.101505444204207
begin epoch : 2
nll_loss: 23.544914849370503
begin epoch : 3
nll_loss: 21.991558356250792
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.492044579210898
begin epoch : 5
nll_loss: 21.386728712123077
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3166
begin the training process
begin epoch : 1
nll_loss: 40.8773193359375
begin epoch : 2
nll_loss: 31.541358324946188
begin epoch : 3
nll_loss: 28.488202698376714
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.519343784877233
begin epoch : 5
nll_loss: 27.229487010410853
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 568575
begin the training process
begin epoch : 1
nll_loss: 21.93853628099951
begin epoch : 2
nll_loss: 20.20418158890521
begin epoch : 3
nll_loss: 19.671266156623563
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.212495808342105
begin epoch : 5
nll_loss: 19.12056525596611
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1733
begin the training process
begin epoch : 1
nll_loss: 42.83923085530599
begin epoch : 2
nll_loss: 34.49372835512514
begin epoch : 3
nll_loss: 30.60467493975604
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.754292947274667
begin epoch : 5
nll_loss: 28.28540180347584
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 48553
begin the training process
begin epoch : 1
nll_loss: 25.622175707351563
begin epoch : 2
nll_loss: 21.182599173372214
begin epoch : 3
nll_loss: 20.649704558239133
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.399791712496715
begin epoch : 5
nll_loss: 20.350163336479568
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 43954
begin the training process
begin epoch : 1
nll_loss: 23.97217940172023
begin epoch : 2
nll_loss: 19.895116177661773
begin epoch : 3
nll_loss: 19.560963288688104
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.380993142419932
begin epoch : 5
nll_loss: 19.34863196170017
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 16826
begin the training process
begin epoch : 1
nll_loss: 29.529637919127484
begin epoch : 2
nll_loss: 23.034008113482525
begin epoch : 3
nll_loss: 21.528450419884603
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.002973913236428
begin epoch : 5
nll_loss: 20.888497439959576
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4872
begin the training process
begin epoch : 1
nll_loss: 37.78103223599886
begin epoch : 2
nll_loss: 28.612628911670885
begin epoch : 3
nll_loss: 26.265983380769427
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.31769233000906
begin epoch : 5
nll_loss: 25.07035601766486
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7556
begin the training process
begin epoch : 1
nll_loss: 35.71587864827301
begin epoch : 2
nll_loss: 27.645503868490962
begin epoch : 3
nll_loss: 24.976605156720694
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.8776536553593
begin epoch : 5
nll_loss: 23.633243754758674
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 81781
begin the training process
begin epoch : 1
nll_loss: 24.25329688422458
begin epoch : 2
nll_loss: 20.96198847299455
begin epoch : 3
nll_loss: 20.670642591400266
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.4852956220706
begin epoch : 5
nll_loss: 20.45446537319533
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 881
begin the training process
begin epoch : 1
nll_loss: 47.26270939753606
begin epoch : 2
nll_loss: 41.9922476548415
begin epoch : 3
nll_loss: 37.84569021371695
The learning rate has beed reduced
begin epoch : 4
nll_loss: 36.0579478924091
begin epoch : 5
nll_loss: 35.63273004385141
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1519
begin the training process
begin epoch : 1
nll_loss: 44.53662938657014
begin epoch : 2
nll_loss: 37.606995955757476
begin epoch : 3
nll_loss: 33.77915324335513
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.727123758067254
begin epoch : 5
nll_loss: 31.078434405119523
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 129569
begin the training process
begin epoch : 1
nll_loss: 22.48289556088655
begin epoch : 2
nll_loss: 20.255441741981056
begin epoch : 3
nll_loss: 20.091379943101302
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.944293220052607
begin epoch : 5
nll_loss: 19.920243113408446
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3888
begin the training process
begin epoch : 1
nll_loss: 39.98595371246338
begin epoch : 2
nll_loss: 31.154974492390952
begin epoch : 3
nll_loss: 28.49697717030843
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.518780008951822
begin epoch : 5
nll_loss: 27.211769644419352
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1666
begin the training process
begin epoch : 1
nll_loss: 42.80255537766676
begin epoch : 2
nll_loss: 34.7195918743427
begin epoch : 3
nll_loss: 31.135789137620193
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.404221461369442
begin epoch : 5
nll_loss: 28.902070192190315
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2239
begin the training process
begin epoch : 1
nll_loss: 43.44618584127987
begin epoch : 2
nll_loss: 35.638962128583124
begin epoch : 3
nll_loss: 31.527783449958353
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.91457451091093
begin epoch : 5
nll_loss: 29.545958126292508
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3015
begin the training process
begin epoch : 1
nll_loss: 41.664416455207984
begin epoch : 2
nll_loss: 33.21189653112533
begin epoch : 3
nll_loss: 30.050414227424785
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.93968663317092
begin epoch : 5
nll_loss: 28.638440923487888
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 53303
begin the training process
begin epoch : 1
nll_loss: 23.70690425313436
begin epoch : 2
nll_loss: 19.904339590897926
begin epoch : 3
nll_loss: 19.575095894245003
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.400753484322475
begin epoch : 5
nll_loss: 19.367676008206146
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2978
begin the training process
begin epoch : 1
nll_loss: 39.358296518740445
begin epoch : 2
nll_loss: 30.94710453696873
begin epoch : 3
nll_loss: 27.761876562367316
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.684976204581883
begin epoch : 5
nll_loss: 26.390442060387652
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 51135
begin the training process
begin epoch : 1
nll_loss: 24.817937628667156
begin epoch : 2
nll_loss: 20.878711200895765
begin epoch : 3
nll_loss: 20.03586917533014
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.483776324374933
begin epoch : 5
nll_loss: 19.34320026531554
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 13665
begin the training process
begin epoch : 1
nll_loss: 29.7940142725555
begin epoch : 2
nll_loss: 22.53587650245344
begin epoch : 3
nll_loss: 20.87715252800167
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.340159599769844
begin epoch : 5
nll_loss: 20.239023656352586
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4457
begin the training process
begin epoch : 1
nll_loss: 37.737559525862984
begin epoch : 2
nll_loss: 28.536940975465637
begin epoch : 3
nll_loss: 25.868105819259863
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.882535906805508
begin epoch : 5
nll_loss: 24.598890138709027
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4583
begin the training process
begin epoch : 1
nll_loss: 38.804007812285086
begin epoch : 2
nll_loss: 29.64648652412522
begin epoch : 3
nll_loss: 27.451685354743205
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.494501436260386
begin epoch : 5
nll_loss: 26.19095383227711
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 612
begin the training process
begin epoch : 1
nll_loss: 47.20476404825846
begin epoch : 2
nll_loss: 43.703590393066406
begin epoch : 3
nll_loss: 39.390875498453774
The learning rate has beed reduced
begin epoch : 4
nll_loss: 37.48752297295464
begin epoch : 5
nll_loss: 36.838932037353516
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1756
begin the training process
begin epoch : 1
nll_loss: 45.400299354835795
begin epoch : 2
nll_loss: 37.555641880741824
begin epoch : 3
nll_loss: 33.373082408198606
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.56676299483688
begin epoch : 5
nll_loss: 31.161169122766566
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 11162
begin the training process
begin epoch : 1
nll_loss: 31.26778758257285
begin epoch : 2
nll_loss: 23.354549956047673
begin epoch : 3
nll_loss: 21.64480761823983
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.98059703563822
begin epoch : 5
nll_loss: 20.831184200856878
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2227
begin the training process
begin epoch : 1
nll_loss: 42.87648728314568
begin epoch : 2
nll_loss: 35.06760922600241
begin epoch : 3
nll_loss: 31.28469669117647
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.015597455641803
begin epoch : 5
nll_loss: 29.727004892685834
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2457
begin the training process
begin epoch : 1
nll_loss: 40.58579886587042
begin epoch : 2
nll_loss: 32.39595980393259
begin epoch : 3
nll_loss: 28.978821854842337
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.579975027787057
begin epoch : 5
nll_loss: 27.256264034070465
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9973
begin the training process
begin epoch : 1
nll_loss: 32.087812743648406
begin epoch : 2
nll_loss: 24.678025362568516
begin epoch : 3
nll_loss: 22.524679466985887
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.56300469675372
begin epoch : 5
nll_loss: 21.345226706227947
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2911
begin the training process
begin epoch : 1
nll_loss: 40.73696068657769
begin epoch : 2
nll_loss: 31.20027181837294
begin epoch : 3
nll_loss: 27.519057506985135
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.381663046942815
begin epoch : 5
nll_loss: 26.069791793823242
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 257229
begin the training process
begin epoch : 1
nll_loss: 21.4097420302574
begin epoch : 2
nll_loss: 17.640986728264817
begin epoch : 3
nll_loss: 16.781468569861623
The learning rate has beed reduced
begin epoch : 4
nll_loss: 16.192302639788732
begin epoch : 5
nll_loss: 16.07942850217798
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 49394
begin the training process
begin epoch : 1
nll_loss: 24.099283027896313
begin epoch : 2
nll_loss: 19.964411464646634
begin epoch : 3
nll_loss: 19.597860353620753
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.406188462649492
begin epoch : 5
nll_loss: 19.370281452025576
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 18592
begin the training process
begin epoch : 1
nll_loss: 30.50468465213118
begin epoch : 2
nll_loss: 23.894582524792902
begin epoch : 3
nll_loss: 22.332317247061894
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.75824997342866
begin epoch : 5
nll_loss: 21.630079894230285
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9878
begin the training process
begin epoch : 1
nll_loss: 33.50860194416789
begin epoch : 2
nll_loss: 26.10975290273691
begin epoch : 3
nll_loss: 24.159562730169917
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.321919986179896
begin epoch : 5
nll_loss: 23.09810665675572
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3379
begin the training process
begin epoch : 1
nll_loss: 39.56797563112699
begin epoch : 2
nll_loss: 30.508315306443436
begin epoch : 3
nll_loss: 27.283785820007324
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.24909969476553
begin epoch : 5
nll_loss: 25.984185769007755
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 141744
begin the training process
begin epoch : 1
nll_loss: 22.703982706423158
begin epoch : 2
nll_loss: 20.667784790790286
begin epoch : 3
nll_loss: 20.363155414095417
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.096475516769836
begin epoch : 5
nll_loss: 20.034434713968416
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12384
begin the training process
begin epoch : 1
nll_loss: 30.154450540097884
begin epoch : 2
nll_loss: 23.21702706134381
begin epoch : 3
nll_loss: 21.44699741027516
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.866156513826834
begin epoch : 5
nll_loss: 20.73886894067952
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2742
begin the training process
begin epoch : 1
nll_loss: 42.543674741472515
begin epoch : 2
nll_loss: 33.8004028683617
begin epoch : 3
nll_loss: 29.827831767854235
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.570785295395623
begin epoch : 5
nll_loss: 28.24613348642985
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 25008
begin the training process
begin epoch : 1
nll_loss: 28.21786375779372
begin epoch : 2
nll_loss: 22.228036856039978
begin epoch : 3
nll_loss: 21.310711586781036
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.929260972829965
begin epoch : 5
nll_loss: 20.846764970437075
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2670
begin the training process
begin epoch : 1
nll_loss: 40.179693268566595
begin epoch : 2
nll_loss: 31.96102979706555
begin epoch : 3
nll_loss: 28.183068391753405
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.641235305041803
begin epoch : 5
nll_loss: 26.301204588355088
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3671
begin the training process
begin epoch : 1
nll_loss: 37.52727187307257
begin epoch : 2
nll_loss: 28.822327429788153
begin epoch : 3
nll_loss: 25.789201368365372
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.678349344353926
begin epoch : 5
nll_loss: 24.33803969935367
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9067
begin the training process
begin epoch : 1
nll_loss: 32.07423195264018
begin epoch : 2
nll_loss: 24.34145487792103
begin epoch : 3
nll_loss: 22.304443805775744
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.444392927994965
begin epoch : 5
nll_loss: 21.229964533596174
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1226
begin the training process
begin epoch : 1
nll_loss: 44.63267376548365
begin epoch : 2
nll_loss: 37.461227216218646
begin epoch : 3
nll_loss: 33.74737237629137
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.970991937737715
begin epoch : 5
nll_loss: 31.43019033733167
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 70552
begin the training process
begin epoch : 1
nll_loss: 24.251613835024962
begin epoch : 2
nll_loss: 16.70748743604186
begin epoch : 3
nll_loss: 14.739150755202056
The learning rate has beed reduced
begin epoch : 4
nll_loss: 13.952066794497565
begin epoch : 5
nll_loss: 13.800486958394682
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1104
begin the training process
begin epoch : 1
nll_loss: 45.04123530668371
begin epoch : 2
nll_loss: 38.730430603027344
begin epoch : 3
nll_loss: 34.91369382072897
The learning rate has beed reduced
begin epoch : 4
nll_loss: 33.273948445039636
begin epoch : 5
nll_loss: 32.8423339619356
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 29963
begin the training process
begin epoch : 1
nll_loss: 27.767990780691814
begin epoch : 2
nll_loss: 22.265018259358204
begin epoch : 3
nll_loss: 21.44073137870202
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.12326421493139
begin epoch : 5
nll_loss: 21.05813020722479
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1818
begin the training process
begin epoch : 1
nll_loss: 43.96917833600725
begin epoch : 2
nll_loss: 36.67722347804478
begin epoch : 3
nll_loss: 32.996667112622944
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.346044881003245
begin epoch : 5
nll_loss: 30.966935021536692
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5814
begin the training process
begin epoch : 1
nll_loss: 37.36261850992839
begin epoch : 2
nll_loss: 29.090420786539713
begin epoch : 3
nll_loss: 26.419370248582627
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.542558246188694
begin epoch : 5
nll_loss: 25.327383761935764
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2948
begin the training process
begin epoch : 1
nll_loss: 40.940017783123515
begin epoch : 2
nll_loss: 32.23985456383747
begin epoch : 3
nll_loss: 28.123852895653766
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.90225008259649
begin epoch : 5
nll_loss: 26.634057915729024
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 27498
begin the training process
begin epoch : 1
nll_loss: 27.980508141862206
begin epoch : 2
nll_loss: 21.681246475184157
begin epoch : 3
nll_loss: 18.977122598038964
The learning rate has beed reduced
begin epoch : 4
nll_loss: 17.304851743169042
begin epoch : 5
nll_loss: 16.86806498929893
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3939
begin the training process
begin epoch : 1
nll_loss: 37.39146063757725
begin epoch : 2
nll_loss: 28.260704916031635
begin epoch : 3
nll_loss: 25.479445817040617
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.451899981889568
begin epoch : 5
nll_loss: 24.1691602175353
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3717
begin the training process
begin epoch : 1
nll_loss: 39.35488490400643
begin epoch : 2
nll_loss: 30.847116733419483
begin epoch : 3
nll_loss: 28.14979655167152
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.090629150127544
begin epoch : 5
nll_loss: 26.820197598687535
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 56159
begin the training process
begin epoch : 1
nll_loss: 23.774840395154268
begin epoch : 2
nll_loss: 20.24438961555368
begin epoch : 3
nll_loss: 19.950787525764213
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.759893626144567
begin epoch : 5
nll_loss: 19.722535782556307
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 62845
begin the training process
begin epoch : 1
nll_loss: 24.63736678190552
begin epoch : 2
nll_loss: 21.110531401561307
begin epoch : 3
nll_loss: 20.74176264343884
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.535780814323463
begin epoch : 5
nll_loss: 20.497566818097315
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1973
begin the training process
begin epoch : 1
nll_loss: 43.96603253682454
begin epoch : 2
nll_loss: 35.57419942220052
begin epoch : 3
nll_loss: 31.260713895161945
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.739393297831217
begin epoch : 5
nll_loss: 29.486863327026366
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2476
begin the training process
begin epoch : 1
nll_loss: 41.66869504828202
begin epoch : 2
nll_loss: 33.157051387586094
begin epoch : 3
nll_loss: 29.380874282435368
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.225430588973197
begin epoch : 5
nll_loss: 27.94710063934326
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1549
begin the training process
begin epoch : 1
nll_loss: 42.613790353139244
begin epoch : 2
nll_loss: 35.47206528981527
begin epoch : 3
nll_loss: 31.15695317586263
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.099382877349854
begin epoch : 5
nll_loss: 28.62407382329305
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1491
begin the training process
begin epoch : 1
nll_loss: 44.82596720819888
begin epoch : 2
nll_loss: 37.46123670495075
begin epoch : 3
nll_loss: 34.042379462200664
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.19969301638396
begin epoch : 5
nll_loss: 31.66275521983271
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 105282
begin the training process
begin epoch : 1
nll_loss: 23.476112504860552
begin epoch : 2
nll_loss: 20.622269486076565
begin epoch : 3
nll_loss: 20.385170484966057
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.2078569209322
begin epoch : 5
nll_loss: 20.178403014904823
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8982
begin the training process
begin epoch : 1
nll_loss: 34.41446583611624
begin epoch : 2
nll_loss: 26.549988787514824
begin epoch : 3
nll_loss: 24.396844591413224
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.48932204927717
begin epoch : 5
nll_loss: 23.251303236825127
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5383
begin the training process
begin epoch : 1
nll_loss: 35.68272867656889
begin epoch : 2
nll_loss: 26.00076489221482
begin epoch : 3
nll_loss: 23.413694517953054
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.419593084426154
begin epoch : 5
nll_loss: 22.151227088201615
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3012
begin the training process
begin epoch : 1
nll_loss: 41.53264317613967
begin epoch : 2
nll_loss: 32.4802675044283
begin epoch : 3
nll_loss: 29.349779169610205
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.387564070681307
begin epoch : 5
nll_loss: 28.08507091441053
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 24787
begin the training process
begin epoch : 1
nll_loss: 26.59466200835945
begin epoch : 2
nll_loss: 20.81300944936984
begin epoch : 3
nll_loss: 20.104897255121276
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.825804146069274
begin epoch : 5
nll_loss: 19.767037310341532
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3101
begin the training process
begin epoch : 1
nll_loss: 41.272921880086265
begin epoch : 2
nll_loss: 32.76014578342438
begin epoch : 3
nll_loss: 29.57483160495758
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.518172065416973
begin epoch : 5
nll_loss: 28.246977647145588
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2093
begin the training process
begin epoch : 1
nll_loss: 43.029810428619385
begin epoch : 2
nll_loss: 35.628042340278625
begin epoch : 3
nll_loss: 31.283313751220703
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.718149065971375
begin epoch : 5
nll_loss: 29.370613396167755
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1797
begin the training process
begin epoch : 1
nll_loss: 43.91852501460484
begin epoch : 2
nll_loss: 36.20980439867292
begin epoch : 3
nll_loss: 32.43325458254133
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.57966879435948
begin epoch : 5
nll_loss: 30.179625715528214
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4007
begin the training process
begin epoch : 1
nll_loss: 39.28575195804719
begin epoch : 2
nll_loss: 30.714412012407855
begin epoch : 3
nll_loss: 28.073254708320864
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.14238945130379
begin epoch : 5
nll_loss: 26.85049875320927
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5043
begin the training process
begin epoch : 1
nll_loss: 36.42737371493609
begin epoch : 2
nll_loss: 27.634555963369515
begin epoch : 3
nll_loss: 25.25572040753487
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.205122189644054
begin epoch : 5
nll_loss: 23.918540318806965
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2173
begin the training process
begin epoch : 1
nll_loss: 43.324327526670515
begin epoch : 2
nll_loss: 35.02620581424598
begin epoch : 3
nll_loss: 30.464037519512754
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.778374122850824
begin epoch : 5
nll_loss: 28.388565294670336
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 255711
begin the training process
begin epoch : 1
nll_loss: 21.684046233729816
begin epoch : 2
nll_loss: 20.389345403487454
begin epoch : 3
nll_loss: 20.18798398625418
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.997066641987786
begin epoch : 5
nll_loss: 19.95801837095182
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1250
begin the training process
begin epoch : 1
nll_loss: 46.005000265021074
begin epoch : 2
nll_loss: 39.825333043148646
begin epoch : 3
nll_loss: 35.54484758879009
The learning rate has beed reduced
begin epoch : 4
nll_loss: 33.55079430028012
begin epoch : 5
nll_loss: 32.95226860046387
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 16138
begin the training process
begin epoch : 1
nll_loss: 29.230390412466868
begin epoch : 2
nll_loss: 21.968713313814195
begin epoch : 3
nll_loss: 20.604120716216073
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.20969577819582
begin epoch : 5
nll_loss: 20.12132692337036
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7346
begin the training process
begin epoch : 1
nll_loss: 33.71095975240072
begin epoch : 2
nll_loss: 24.42417425858347
begin epoch : 3
nll_loss: 22.34865705590499
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.51890053665429
begin epoch : 5
nll_loss: 21.306027245103266
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1461
begin the training process
begin epoch : 1
nll_loss: 43.6604605588046
begin epoch : 2
nll_loss: 36.45246540416371
begin epoch : 3
nll_loss: 32.679323109713465
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.919276931069113
begin epoch : 5
nll_loss: 30.455148003318094
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 423591
begin the training process
begin epoch : 1
nll_loss: 21.80418238376123
begin epoch : 2
nll_loss: 18.9031242311235
begin epoch : 3
nll_loss: 18.123924803971597
The learning rate has beed reduced
begin epoch : 4
nll_loss: 17.544654169915557
begin epoch : 5
nll_loss: 17.437495753425743
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 21306
begin the training process
begin epoch : 1
nll_loss: 26.8940261990191
begin epoch : 2
nll_loss: 21.11287748382752
begin epoch : 3
nll_loss: 20.311540977064386
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.015630268188843
begin epoch : 5
nll_loss: 19.952169889427093
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2218
begin the training process
begin epoch : 1
nll_loss: 43.60081212660845
begin epoch : 2
nll_loss: 35.237945556640625
begin epoch : 3
nll_loss: 31.041229135849896
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.384234877193677
begin epoch : 5
nll_loss: 29.00160379970775
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 64871
begin the training process
begin epoch : 1
nll_loss: 24.377570317033953
begin epoch : 2
nll_loss: 20.796778252423692
begin epoch : 3
nll_loss: 20.450019695210433
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.244859177644962
begin epoch : 5
nll_loss: 20.210323258425383
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4171
begin the training process
begin epoch : 1
nll_loss: 38.96856668912447
begin epoch : 2
nll_loss: 29.74243014408992
begin epoch : 3
nll_loss: 27.074000754723183
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.09204594538762
begin epoch : 5
nll_loss: 25.832022681603064
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8621
begin the training process
begin epoch : 1
nll_loss: 34.239088684765264
begin epoch : 2
nll_loss: 25.627625693136185
begin epoch : 3
nll_loss: 23.424242233162495
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.556828669647672
begin epoch : 5
nll_loss: 22.361161046953345
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8691
begin the training process
begin epoch : 1
nll_loss: 33.05346548292372
begin epoch : 2
nll_loss: 25.543025193391024
begin epoch : 3
nll_loss: 23.20813111199273
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.17762170014558
begin epoch : 5
nll_loss: 21.905132194801613
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6142
begin the training process
begin epoch : 1
nll_loss: 37.365736489546926
begin epoch : 2
nll_loss: 28.75388045060007
begin epoch : 3
nll_loss: 26.533605876721833
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.447928759926246
begin epoch : 5
nll_loss: 25.15937524092825
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 51170
begin the training process
begin epoch : 1
nll_loss: 24.282809399543925
begin epoch : 2
nll_loss: 20.245721234547183
begin epoch : 3
nll_loss: 19.916306134010288
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.725309574857672
begin epoch : 5
nll_loss: 19.69022199179562
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 44960
begin the training process
begin epoch : 1
nll_loss: 25.968098374173852
begin epoch : 2
nll_loss: 21.561016990248635
begin epoch : 3
nll_loss: 20.98191058058345
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.71970200878263
begin epoch : 5
nll_loss: 20.671561292773298
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 31193
begin the training process
begin epoch : 1
nll_loss: 27.155852856332515
begin epoch : 2
nll_loss: 21.693069328762423
begin epoch : 3
nll_loss: 20.948823979747857
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.60045454193679
begin epoch : 5
nll_loss: 20.53531741900121
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12876
begin the training process
begin epoch : 1
nll_loss: 30.52823758481154
begin epoch : 2
nll_loss: 23.151255204309873
begin epoch : 3
nll_loss: 21.333258367889556
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.816464447856543
begin epoch : 5
nll_loss: 20.718708275562495
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3042
begin the training process
begin epoch : 1
nll_loss: 39.74754552638277
begin epoch : 2
nll_loss: 30.732301022144075
begin epoch : 3
nll_loss: 26.75383206631275
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.722275794820582
begin epoch : 5
nll_loss: 25.449231086893285
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12050
begin the training process
begin epoch : 1
nll_loss: 32.32397134253319
begin epoch : 2
nll_loss: 24.077797301272128
begin epoch : 3
nll_loss: 20.7879830218376
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.216332141389238
begin epoch : 5
nll_loss: 18.743696476550813
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1815
begin the training process
begin epoch : 1
nll_loss: 44.20240592956543
begin epoch : 2
nll_loss: 35.923578943525044
begin epoch : 3
nll_loss: 31.615506376538956
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.86015374319894
begin epoch : 5
nll_loss: 29.473066057477677
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 19156
begin the training process
begin epoch : 1
nll_loss: 30.248560768306056
begin epoch : 2
nll_loss: 23.96778122637184
begin epoch : 3
nll_loss: 22.516878695790982
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.984699925451373
begin epoch : 5
nll_loss: 21.878152177485337
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3316
begin the training process
begin epoch : 1
nll_loss: 39.015790976730045
begin epoch : 2
nll_loss: 29.883358674890854
begin epoch : 3
nll_loss: 26.84082685732374
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.79765402102003
begin epoch : 5
nll_loss: 25.507116467344996
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 26606
begin the training process
begin epoch : 1
nll_loss: 28.544260774175804
begin epoch : 2
nll_loss: 22.878992140436747
begin epoch : 3
nll_loss: 21.82131909289992
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.399724376632506
begin epoch : 5
nll_loss: 21.312207987222326
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2794
begin the training process
begin epoch : 1
nll_loss: 41.19678719099178
begin epoch : 2
nll_loss: 32.5834100412768
begin epoch : 3
nll_loss: 28.927183151245117
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.848752798036088
begin epoch : 5
nll_loss: 27.530307370562888
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2429
begin the training process
begin epoch : 1
nll_loss: 42.233733821559596
begin epoch : 2
nll_loss: 33.87467616313213
begin epoch : 3
nll_loss: 29.96664031776222
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.74443157299145
begin epoch : 5
nll_loss: 28.458446244935732
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2124
begin the training process
begin epoch : 1
nll_loss: 43.431154655687735
begin epoch : 2
nll_loss: 35.64437588778409
begin epoch : 3
nll_loss: 31.445965853604402
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.165015133944426
begin epoch : 5
nll_loss: 29.880652861161664
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1659
begin the training process
begin epoch : 1
nll_loss: 44.797304992675784
begin epoch : 2
nll_loss: 37.17302474975586
begin epoch : 3
nll_loss: 33.16181694030762
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.557552795410157
begin epoch : 5
nll_loss: 31.070948181152342
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1349
begin the training process
begin epoch : 1
nll_loss: 45.48552903674898
begin epoch : 2
nll_loss: 39.108980269659135
begin epoch : 3
nll_loss: 34.93994649251302
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.929389317830406
begin epoch : 5
nll_loss: 32.359017508370535
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 14587
begin the training process
begin epoch : 1
nll_loss: 30.05975317429866
begin epoch : 2
nll_loss: 23.200056538182732
begin epoch : 3
nll_loss: 21.26745845777873
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.606630711828558
begin epoch : 5
nll_loss: 20.466413632363476
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3043
begin the training process
begin epoch : 1
nll_loss: 39.71655752303752
begin epoch : 2
nll_loss: 30.425378555947162
begin epoch : 3
nll_loss: 26.862740374625997
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.90703136362928
begin epoch : 5
nll_loss: 25.61615647660925
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 22089
begin the training process
begin epoch : 1
nll_loss: 27.965971634353416
begin epoch : 2
nll_loss: 21.312594267250834
begin epoch : 3
nll_loss: 20.330263629858045
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.035004253663878
begin epoch : 5
nll_loss: 19.973727472277655
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2158
begin the training process
begin epoch : 1
nll_loss: 42.920325423731946
begin epoch : 2
nll_loss: 34.94257857582786
begin epoch : 3
nll_loss: 31.00378180995132
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.50151674675219
begin epoch : 5
nll_loss: 29.186950105609316
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3213
begin the training process
begin epoch : 1
nll_loss: 40.93426452636719
begin epoch : 2
nll_loss: 32.24155361175537
begin epoch : 3
nll_loss: 29.067120132446288
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.036875076293946
begin epoch : 5
nll_loss: 27.77573310852051
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 22061
begin the training process
begin epoch : 1
nll_loss: 28.88937615793805
begin epoch : 2
nll_loss: 22.474017614542053
begin epoch : 3
nll_loss: 21.31351355619209
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.910551947216653
begin epoch : 5
nll_loss: 20.823945877163908
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2309
begin the training process
begin epoch : 1
nll_loss: 42.8472384346856
begin epoch : 2
nll_loss: 34.9348857667711
begin epoch : 3
nll_loss: 30.741643216874863
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.419368478986954
begin epoch : 5
nll_loss: 29.124768045213486
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3374
begin the training process
begin epoch : 1
nll_loss: 40.15072734539326
begin epoch : 2
nll_loss: 31.179215357853817
begin epoch : 3
nll_loss: 28.264590190007137
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.377556580763596
begin epoch : 5
nll_loss: 27.130824749286358
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 418042
begin the training process
begin epoch : 1
nll_loss: 21.827460506721327
begin epoch : 2
nll_loss: 19.273627597036086
begin epoch : 3
nll_loss: 18.538721192359485
The learning rate has beed reduced
begin epoch : 4
nll_loss: 17.977915052286317
begin epoch : 5
nll_loss: 17.86913067734893
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1139
begin the training process
begin epoch : 1
nll_loss: 46.325190600226904
begin epoch : 2
nll_loss: 40.33267368989832
begin epoch : 3
nll_loss: 36.83444011912626
The learning rate has beed reduced
begin epoch : 4
nll_loss: 35.10423794914694
begin epoch : 5
nll_loss: 34.63330616670496
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2389
begin the training process
begin epoch : 1
nll_loss: 41.53354716945339
begin epoch : 2
nll_loss: 32.95928800428236
begin epoch : 3
nll_loss: 28.662430067320127
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.032662675187396
begin epoch : 5
nll_loss: 26.712286407883102
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 51901
begin the training process
begin epoch : 1
nll_loss: 25.975719152850868
begin epoch : 2
nll_loss: 21.282558109142162
begin epoch : 3
nll_loss: 19.783962358074422
The learning rate has beed reduced
begin epoch : 4
nll_loss: 18.899188034622757
begin epoch : 5
nll_loss: 18.675565309877747
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1764
begin the training process
begin epoch : 1
nll_loss: 44.40009873001664
begin epoch : 2
nll_loss: 36.69591027719003
begin epoch : 3
nll_loss: 32.56719843546549
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.695124166983145
begin epoch : 5
nll_loss: 30.26884502834744
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4816
begin the training process
begin epoch : 1
nll_loss: 37.98313939412435
begin epoch : 2
nll_loss: 29.827864507039386
begin epoch : 3
nll_loss: 27.572408701578777
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.511633021036783
begin epoch : 5
nll_loss: 26.24495282491048
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 20702
begin the training process
begin epoch : 1
nll_loss: 29.729843623866977
begin epoch : 2
nll_loss: 23.201515823694944
begin epoch : 3
nll_loss: 21.912265393756122
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.450736462147244
begin epoch : 5
nll_loss: 21.349614565586528
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10347
begin the training process
begin epoch : 1
nll_loss: 30.92033893277186
begin epoch : 2
nll_loss: 23.06049112355487
begin epoch : 3
nll_loss: 21.17231963732228
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.553780478720338
begin epoch : 5
nll_loss: 20.41712226630738
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1994
begin the training process
begin epoch : 1
nll_loss: 42.22638124035251
begin epoch : 2
nll_loss: 34.0504406344506
begin epoch : 3
nll_loss: 29.664693524760583
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.81635210590978
begin epoch : 5
nll_loss: 27.438360521870276
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6043
begin the training process
begin epoch : 1
nll_loss: 36.66132829544392
begin epoch : 2
nll_loss: 28.30576732310843
begin epoch : 3
nll_loss: 26.22810822344841
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.306913538182034
begin epoch : 5
nll_loss: 25.025311023630994
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4879
begin the training process
begin epoch : 1
nll_loss: 38.10296869277954
begin epoch : 2
nll_loss: 28.73578563489412
begin epoch : 3
nll_loss: 26.351137362028425
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.306790653027985
begin epoch : 5
nll_loss: 25.014786469308955
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2652
begin the training process
begin epoch : 1
nll_loss: 42.79453463670684
begin epoch : 2
nll_loss: 34.0967789161496
begin epoch : 3
nll_loss: 30.180081576835818
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.82772422418362
begin epoch : 5
nll_loss: 28.52657192509349
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7026
begin the training process
begin epoch : 1
nll_loss: 33.81207474874794
begin epoch : 2
nll_loss: 25.40512728909834
begin epoch : 3
nll_loss: 23.120496312412648
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.097806178101706
begin epoch : 5
nll_loss: 21.82762497718181
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5617
begin the training process
begin epoch : 1
nll_loss: 36.94572731544231
begin epoch : 2
nll_loss: 28.705669863470668
begin epoch : 3
nll_loss: 26.464115164745813
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.476129838790015
begin epoch : 5
nll_loss: 25.157783924848182
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1757
begin the training process
begin epoch : 1
nll_loss: 43.164628205475985
begin epoch : 2
nll_loss: 35.275095763029874
begin epoch : 3
nll_loss: 30.936250827930593
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.028467602199978
begin epoch : 5
nll_loss: 28.569290302417897
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 15612
begin the training process
begin epoch : 1
nll_loss: 29.18029246703097
begin epoch : 2
nll_loss: 22.136194652981228
begin epoch : 3
nll_loss: 20.61698572135266
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.208300610138064
begin epoch : 5
nll_loss: 20.12154303656684
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6559
begin the training process
begin epoch : 1
nll_loss: 34.78926856845033
begin epoch : 2
nll_loss: 26.086530891119263
begin epoch : 3
nll_loss: 24.00449332068948
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.128402579064463
begin epoch : 5
nll_loss: 22.868743728188907
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7875
begin the training process
begin epoch : 1
nll_loss: 33.82809265260774
begin epoch : 2
nll_loss: 25.607673458936738
begin epoch : 3
nll_loss: 23.53238491895722
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.58639712449981
begin epoch : 5
nll_loss: 22.313283703191495
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 33007
begin the training process
begin epoch : 1
nll_loss: 27.209468930438884
begin epoch : 2
nll_loss: 22.13738239992012
begin epoch : 3
nll_loss: 21.307223507038596
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.970066314993552
begin epoch : 5
nll_loss: 20.909072524135553
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 37998
begin the training process
begin epoch : 1
nll_loss: 26.297797703220308
begin epoch : 2
nll_loss: 21.697668998679664
begin epoch : 3
nll_loss: 20.632998532428708
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.88601543368618
begin epoch : 5
nll_loss: 19.664996859597114
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3357
begin the training process
begin epoch : 1
nll_loss: 39.96649632087121
begin epoch : 2
nll_loss: 31.481083539816048
begin epoch : 3
nll_loss: 28.36833088214581
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.250942486983078
begin epoch : 5
nll_loss: 26.923847528604362
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2821
begin the training process
begin epoch : 1
nll_loss: 41.69534267078746
begin epoch : 2
nll_loss: 33.70983995090831
begin epoch : 3
nll_loss: 29.994822762229226
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.651785113594748
begin epoch : 5
nll_loss: 28.325165965340354
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2480
begin the training process
begin epoch : 1
nll_loss: 42.5648385098106
begin epoch : 2
nll_loss: 34.47810579601087
begin epoch : 3
nll_loss: 30.65058422088623
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.280269422029193
begin epoch : 5
nll_loss: 28.918953092474688
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2471
begin the training process
begin epoch : 1
nll_loss: 42.12853522049753
begin epoch : 2
nll_loss: 34.50058706183182
begin epoch : 3
nll_loss: 30.57876722436202
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.126698945697985
begin epoch : 5
nll_loss: 28.86114953693591
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5751
begin the training process
begin epoch : 1
nll_loss: 35.102809863144095
begin epoch : 2
nll_loss: 26.971191727713254
begin epoch : 3
nll_loss: 24.72030502490783
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.857671951979732
begin epoch : 5
nll_loss: 23.634962617681268
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3576
begin the training process
begin epoch : 1
nll_loss: 39.20265371149237
begin epoch : 2
nll_loss: 30.733933743563565
begin epoch : 3
nll_loss: 27.438452217795632
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.463729199496182
begin epoch : 5
nll_loss: 26.222839494185013
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1465
begin the training process
begin epoch : 1
nll_loss: 45.033811742609196
begin epoch : 2
nll_loss: 38.561579617587
begin epoch : 3
nll_loss: 34.75337808782404
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.94400197809393
begin epoch : 5
nll_loss: 32.35725151408803
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1817
begin the training process
begin epoch : 1
nll_loss: 43.763774735586985
begin epoch : 2
nll_loss: 36.33363669259207
begin epoch : 3
nll_loss: 32.50756461279733
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.782947744641984
begin epoch : 5
nll_loss: 30.411022935594833
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 634843
begin the training process
begin epoch : 1
nll_loss: 21.94399755704618
begin epoch : 2
nll_loss: 20.27845455126989
begin epoch : 3
nll_loss: 19.807835601897402
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.38429298423954
begin epoch : 5
nll_loss: 19.303178096132445
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4716
begin the training process
begin epoch : 1
nll_loss: 39.01082436025959
begin epoch : 2
nll_loss: 29.77033118679099
begin epoch : 3
nll_loss: 27.341752849213066
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.31601325779745
begin epoch : 5
nll_loss: 26.01398760651889
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3061
begin the training process
begin epoch : 1
nll_loss: 41.09819980377846
begin epoch : 2
nll_loss: 32.43867736167096
begin epoch : 3
nll_loss: 28.901123371530087
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.52731440929656
begin epoch : 5
nll_loss: 27.159659162480782
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12863
begin the training process
begin epoch : 1
nll_loss: 31.994071311950684
begin epoch : 2
nll_loss: 24.57667624473572
begin epoch : 3
nll_loss: 22.639471530914307
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.900006914138793
begin epoch : 5
nll_loss: 21.75260997772217
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 18330
begin the training process
begin epoch : 1
nll_loss: 28.18480402939803
begin epoch : 2
nll_loss: 22.240866601050318
begin epoch : 3
nll_loss: 20.785737971325855
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.277110079785327
begin epoch : 5
nll_loss: 20.171933814362212
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4812
begin the training process
begin epoch : 1
nll_loss: 36.91543248494466
begin epoch : 2
nll_loss: 28.007659200032553
begin epoch : 3
nll_loss: 25.70087163289388
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.616616897583008
begin epoch : 5
nll_loss: 24.28630376180013
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4878
begin the training process
begin epoch : 1
nll_loss: 38.4803708979958
begin epoch : 2
nll_loss: 29.131770585712633
begin epoch : 3
nll_loss: 26.929746728194388
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.95728557988217
begin epoch : 5
nll_loss: 25.6671236690722
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1278
begin the training process
begin epoch : 1
nll_loss: 45.23448683086195
begin epoch : 2
nll_loss: 38.14371530633224
begin epoch : 3
nll_loss: 34.07605893988358
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.39644582648026
begin epoch : 5
nll_loss: 31.89326286315918
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 31878
begin the training process
begin epoch : 1
nll_loss: 26.733076195161505
begin epoch : 2
nll_loss: 21.77719328010896
begin epoch : 3
nll_loss: 21.04908102104463
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.663754884497706
begin epoch : 5
nll_loss: 20.572932097806508
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4526
begin the training process
begin epoch : 1
nll_loss: 37.437716538565496
begin epoch : 2
nll_loss: 27.608181272234237
begin epoch : 3
nll_loss: 24.76650627681187
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.76023188999721
begin epoch : 5
nll_loss: 23.51746883392334
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 948
begin the training process
begin epoch : 1
nll_loss: 45.426282337733674
begin epoch : 2
nll_loss: 39.651516505650115
begin epoch : 3
nll_loss: 35.5194467817034
The learning rate has beed reduced
begin epoch : 4
nll_loss: 33.8952316556658
begin epoch : 5
nll_loss: 33.394127573285786
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2489
begin the training process
begin epoch : 1
nll_loss: 41.662153143631784
begin epoch : 2
nll_loss: 32.66614873785721
begin epoch : 3
nll_loss: 28.738497533296282
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.173024328131426
begin epoch : 5
nll_loss: 26.791331742939196
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 47391
begin the training process
begin epoch : 1
nll_loss: 23.408628971512254
begin epoch : 2
nll_loss: 19.580436977180273
begin epoch : 3
nll_loss: 19.276806089040395
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.09745530051154
begin epoch : 5
nll_loss: 19.065807373459275
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 11974
begin the training process
begin epoch : 1
nll_loss: 32.54920010898203
begin epoch : 2
nll_loss: 25.227362342059294
begin epoch : 3
nll_loss: 23.268321511579707
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.470226145045643
begin epoch : 5
nll_loss: 22.288901752329128
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 77801
begin the training process
begin epoch : 1
nll_loss: 23.77416536935563
begin epoch : 2
nll_loss: 20.743268297925407
begin epoch : 3
nll_loss: 20.2010739942637
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.77537231602296
begin epoch : 5
nll_loss: 19.66247042589227
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4906
begin the training process
begin epoch : 1
nll_loss: 38.66013042550338
begin epoch : 2
nll_loss: 29.718462492290296
begin epoch : 3
nll_loss: 27.44042662570351
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.397671398363617
begin epoch : 5
nll_loss: 26.114912359338057
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 855532
begin the training process
begin epoch : 1
nll_loss: 21.495882510318445
begin epoch : 2
nll_loss: 20.91296912448929
begin epoch : 3
nll_loss: 20.819393064639165
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.680010834904593
begin epoch : 5
nll_loss: 20.65437773619414
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4371
begin the training process
begin epoch : 1
nll_loss: 38.68129634857178
begin epoch : 2
nll_loss: 30.055673963883343
begin epoch : 3
nll_loss: 27.683981446658862
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.67314077826107
begin epoch : 5
nll_loss: 26.315107598024255
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8794
begin the training process
begin epoch : 1
nll_loss: 32.813876186844205
begin epoch : 2
nll_loss: 24.720232121265717
begin epoch : 3
nll_loss: 22.640845041205413
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.878658698423067
begin epoch : 5
nll_loss: 21.67582648339933
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2458
begin the training process
begin epoch : 1
nll_loss: 42.53342206854569
begin epoch : 2
nll_loss: 34.58942794799805
begin epoch : 3
nll_loss: 31.044514455293353
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.73788703115363
begin epoch : 5
nll_loss: 29.43773661161724
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1165
begin the training process
begin epoch : 1
nll_loss: 45.86130481296115
begin epoch : 2
nll_loss: 37.836158964369034
begin epoch : 3
nll_loss: 33.866990619235565
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.13710859086778
begin epoch : 5
nll_loss: 31.627915170457626
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 19590
begin the training process
begin epoch : 1
nll_loss: 27.957611221114014
begin epoch : 2
nll_loss: 21.487354066636826
begin epoch : 3
nll_loss: 20.25724707086102
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.862789359747193
begin epoch : 5
nll_loss: 19.781667902578715
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3646
begin the training process
begin epoch : 1
nll_loss: 40.66345133100237
begin epoch : 2
nll_loss: 30.494703122547694
begin epoch : 3
nll_loss: 26.87871449334281
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.732915912355697
begin epoch : 5
nll_loss: 25.416019235338485
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2369
begin the training process
begin epoch : 1
nll_loss: 42.49721197179846
begin epoch : 2
nll_loss: 34.56284007510624
begin epoch : 3
nll_loss: 30.44372171969027
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.989532625353014
begin epoch : 5
nll_loss: 28.635352882179053
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8279
begin the training process
begin epoch : 1
nll_loss: 34.67555340315945
begin epoch : 2
nll_loss: 26.9270507014075
begin epoch : 3
nll_loss: 24.78067461649577
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.844348951827648
begin epoch : 5
nll_loss: 23.60589583345162
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 366115
begin the training process
begin epoch : 1
nll_loss: 21.738950839076008
begin epoch : 2
nll_loss: 19.40041774636382
begin epoch : 3
nll_loss: 18.748370099234414
The learning rate has beed reduced
begin epoch : 4
nll_loss: 18.236920459120423
begin epoch : 5
nll_loss: 18.132584437123544
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 36116
begin the training process
begin epoch : 1
nll_loss: 26.827856604934585
begin epoch : 2
nll_loss: 21.832205454508465
begin epoch : 3
nll_loss: 21.148573767208884
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.84511673027742
begin epoch : 5
nll_loss: 20.785999967696817
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3329
begin the training process
begin epoch : 1
nll_loss: 39.41834530463586
begin epoch : 2
nll_loss: 29.631120094886192
begin epoch : 3
nll_loss: 26.1032772064209
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.10324291082529
begin epoch : 5
nll_loss: 24.830381833589993
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4494
begin the training process
begin epoch : 1
nll_loss: 37.12386349269322
begin epoch : 2
nll_loss: 27.466891969953263
begin epoch : 3
nll_loss: 25.006772804260255
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.101039368765694
begin epoch : 5
nll_loss: 23.888810403006417
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4127
begin the training process
begin epoch : 1
nll_loss: 39.30757197737694
begin epoch : 2
nll_loss: 29.92690360546112
begin epoch : 3
nll_loss: 27.254347562789917
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.344600349664688
begin epoch : 5
nll_loss: 26.067446798086166
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 427865
begin the training process
begin epoch : 1
nll_loss: 21.882162409392237
begin epoch : 2
nll_loss: 19.72069120699555
begin epoch : 3
nll_loss: 19.143275498166936
The learning rate has beed reduced
begin epoch : 4
nll_loss: 18.663195761122093
begin epoch : 5
nll_loss: 18.569332450062102
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5059
begin the training process
begin epoch : 1
nll_loss: 37.84650645678556
begin epoch : 2
nll_loss: 29.117299743845493
begin epoch : 3
nll_loss: 26.630510740642308
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.588396193105964
begin epoch : 5
nll_loss: 25.2945361077031
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 230354
begin the training process
begin epoch : 1
nll_loss: 21.310747026834065
begin epoch : 2
nll_loss: 17.366752897709336
begin epoch : 3
nll_loss: 16.49942572827669
The learning rate has beed reduced
begin epoch : 4
nll_loss: 15.91802404694638
begin epoch : 5
nll_loss: 15.808834287649262
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 11805
begin the training process
begin epoch : 1
nll_loss: 32.38563976080521
begin epoch : 2
nll_loss: 25.278470381446507
begin epoch : 3
nll_loss: 23.297078733858854
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.478353987569395
begin epoch : 5
nll_loss: 22.290068066638447
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3532
begin the training process
begin epoch : 1
nll_loss: 39.33166351318359
begin epoch : 2
nll_loss: 29.80180785439231
begin epoch : 3
nll_loss: 26.13906777121804
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.918893467296254
begin epoch : 5
nll_loss: 24.599992960149592
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1670
begin the training process
begin epoch : 1
nll_loss: 44.174622755784256
begin epoch : 2
nll_loss: 36.29435025728666
begin epoch : 3
nll_loss: 32.44389644035926
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.662842677189754
begin epoch : 5
nll_loss: 30.157070306631233
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4582
begin the training process
begin epoch : 1
nll_loss: 38.18873448439047
begin epoch : 2
nll_loss: 29.491487986604934
begin epoch : 3
nll_loss: 27.108818403432068
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.123716945379552
begin epoch : 5
nll_loss: 25.87456918098557
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 40995
begin the training process
begin epoch : 1
nll_loss: 24.795088890194894
begin epoch : 2
nll_loss: 20.494581657648087
begin epoch : 3
nll_loss: 20.064401417970657
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.84037129878998
begin epoch : 5
nll_loss: 19.795205849409104
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 37396
begin the training process
begin epoch : 1
nll_loss: 27.034284532886662
begin epoch : 2
nll_loss: 22.028082155201535
begin epoch : 3
nll_loss: 21.3085935442415
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.994522669543958
begin epoch : 5
nll_loss: 20.935991767334613
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4721
begin the training process
begin epoch : 1
nll_loss: 38.86551104506401
begin epoch : 2
nll_loss: 29.6848060137605
begin epoch : 3
nll_loss: 27.101106068859362
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.910028196360965
begin epoch : 5
nll_loss: 25.62534507333416
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2072
begin the training process
begin epoch : 1
nll_loss: 42.960561871528625
begin epoch : 2
nll_loss: 35.68891251087189
begin epoch : 3
nll_loss: 31.922897398471832
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.455004930496216
begin epoch : 5
nll_loss: 30.08677899837494
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10367
begin the training process
begin epoch : 1
nll_loss: 31.86527970118552
begin epoch : 2
nll_loss: 24.041900457062336
begin epoch : 3
nll_loss: 21.76659669342989
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.968390624715674
begin epoch : 5
nll_loss: 20.790291839504835
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4790
begin the training process
begin epoch : 1
nll_loss: 37.1798264529254
begin epoch : 2
nll_loss: 28.34186193105337
begin epoch : 3
nll_loss: 25.85422201414366
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.818436931919408
begin epoch : 5
nll_loss: 24.486943605783825
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3261
begin the training process
begin epoch : 1
nll_loss: 40.12169319152832
begin epoch : 2
nll_loss: 31.63490264892578
begin epoch : 3
nll_loss: 29.158858604431153
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.106224937438967
begin epoch : 5
nll_loss: 27.83902786254883
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1147
begin the training process
begin epoch : 1
nll_loss: 45.062756931080536
begin epoch : 2
nll_loss: 38.26902075374828
begin epoch : 3
nll_loss: 34.30567730174345
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.419898986816406
begin epoch : 5
nll_loss: 31.935588500078985
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 17460
begin the training process
begin epoch : 1
nll_loss: 28.69470463780796
begin epoch : 2
nll_loss: 22.301372219534482
begin epoch : 3
nll_loss: 20.91978046473335
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.500165630789365
begin epoch : 5
nll_loss: 20.419562529115115
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4527
begin the training process
begin epoch : 1
nll_loss: 38.27331371307373
begin epoch : 2
nll_loss: 30.08155040740967
begin epoch : 3
nll_loss: 27.741090611049106
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.836540058680942
begin epoch : 5
nll_loss: 26.573016221182687
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 274390
begin the training process
begin epoch : 1
nll_loss: 21.61574945745697
begin epoch : 2
nll_loss: 17.472980145782977
begin epoch : 3
nll_loss: 16.639659947661606
The learning rate has beed reduced
begin epoch : 4
nll_loss: 16.055299160501075
begin epoch : 5
nll_loss: 15.94786259175348
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 11445
begin the training process
begin epoch : 1
nll_loss: 31.18253468931391
begin epoch : 2
nll_loss: 23.338268740793293
begin epoch : 3
nll_loss: 21.256443409437544
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.540610988488357
begin epoch : 5
nll_loss: 20.415986253974143
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 43433
begin the training process
begin epoch : 1
nll_loss: 26.114909346476416
begin epoch : 2
nll_loss: 21.659961877670963
begin epoch : 3
nll_loss: 21.136085380846772
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.87919415274201
begin epoch : 5
nll_loss: 20.829899801968825
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5982
begin the training process
begin epoch : 1
nll_loss: 37.390080667311146
begin epoch : 2
nll_loss: 28.620994772962344
begin epoch : 3
nll_loss: 26.385631356188046
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.41489771360992
begin epoch : 5
nll_loss: 25.12996257248745
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2736
begin the training process
begin epoch : 1
nll_loss: 41.86712755475725
begin epoch : 2
nll_loss: 33.14779681251163
begin epoch : 3
nll_loss: 29.154171989077614
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.030777567908878
begin epoch : 5
nll_loss: 27.801730337597075
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1230
begin the training process
begin epoch : 1
nll_loss: 46.015177275005136
begin epoch : 2
nll_loss: 39.52729375738846
begin epoch : 3
nll_loss: 35.75544618305407
The learning rate has beed reduced
begin epoch : 4
nll_loss: 33.897605092901934
begin epoch : 5
nll_loss: 33.3121990404631
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5852
begin the training process
begin epoch : 1
nll_loss: 35.08320942553845
begin epoch : 2
nll_loss: 26.45688004546113
begin epoch : 3
nll_loss: 23.71490321316562
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.694518938169374
begin epoch : 5
nll_loss: 22.436390384212956
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1879
begin the training process
begin epoch : 1
nll_loss: 43.72066931888975
begin epoch : 2
nll_loss: 35.68842697143555
begin epoch : 3
nll_loss: 31.698403654427363
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.073352090243635
begin epoch : 5
nll_loss: 29.77130232186153
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2438
begin the training process
begin epoch : 1
nll_loss: 41.85129687660619
begin epoch : 2
nll_loss: 33.486605192485605
begin epoch : 3
nll_loss: 29.45171652342144
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.276906716196162
begin epoch : 5
nll_loss: 28.006276883577044
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1422
begin the training process
begin epoch : 1
nll_loss: 45.28082049976695
begin epoch : 2
nll_loss: 38.87051582336426
begin epoch : 3
nll_loss: 34.579165892167524
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.532889106056906
begin epoch : 5
nll_loss: 31.99134687943892
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 38807
begin the training process
begin epoch : 1
nll_loss: 24.96281141023038
begin epoch : 2
nll_loss: 20.321138964234407
begin epoch : 3
nll_loss: 19.847663004406215
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.630718350803892
begin epoch : 5
nll_loss: 19.585767327362163
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2556
begin the training process
begin epoch : 1
nll_loss: 42.01479095067733
begin epoch : 2
nll_loss: 34.268718768388794
begin epoch : 3
nll_loss: 30.876751386202297
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.556798103528145
begin epoch : 5
nll_loss: 29.188849767049152
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5087
begin the training process
begin epoch : 1
nll_loss: 35.946698659582985
begin epoch : 2
nll_loss: 27.097050051145917
begin epoch : 3
nll_loss: 24.82831950127324
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.851547434360167
begin epoch : 5
nll_loss: 23.60555474969405
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 14902
begin the training process
begin epoch : 1
nll_loss: 29.39500881063527
begin epoch : 2
nll_loss: 22.135039017118256
begin epoch : 3
nll_loss: 20.80344654773844
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.424239619024867
begin epoch : 5
nll_loss: 20.346542605038348
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5317
begin the training process
begin epoch : 1
nll_loss: 35.487114159457654
begin epoch : 2
nll_loss: 26.774390691734222
begin epoch : 3
nll_loss: 24.52002224290227
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.60121995856963
begin epoch : 5
nll_loss: 23.351115651877528
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2773
begin the training process
begin epoch : 1
nll_loss: 41.98691008811773
begin epoch : 2
nll_loss: 33.57303601641988
begin epoch : 3
nll_loss: 29.94003703982331
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.715014080668606
begin epoch : 5
nll_loss: 28.4300664413807
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4480
begin the training process
begin epoch : 1
nll_loss: 37.31651886531285
begin epoch : 2
nll_loss: 27.492502675737654
begin epoch : 3
nll_loss: 25.064113235473634
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.952631105695453
begin epoch : 5
nll_loss: 23.657741846357073
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 12172
begin the training process
begin epoch : 1
nll_loss: 30.251590538024903
begin epoch : 2
nll_loss: 23.25710220336914
begin epoch : 3
nll_loss: 21.651464592783075
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.008438170583624
begin epoch : 5
nll_loss: 20.868329188698215
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4952
begin the training process
begin epoch : 1
nll_loss: 36.48160032792525
begin epoch : 2
nll_loss: 27.02250963681704
begin epoch : 3
nll_loss: 24.566033202332335
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.418036597115652
begin epoch : 5
nll_loss: 23.120473663528244
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 15238
begin the training process
begin epoch : 1
nll_loss: 30.373182008246413
begin epoch : 2
nll_loss: 23.39130275790431
begin epoch : 3
nll_loss: 22.060154954926308
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.537879991932076
begin epoch : 5
nll_loss: 21.402051733321503
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2394
begin the training process
begin epoch : 1
nll_loss: 43.555012883366764
begin epoch : 2
nll_loss: 35.337292129929004
begin epoch : 3
nll_loss: 30.732634879447318
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.52061952126993
begin epoch : 5
nll_loss: 29.257876782803923
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5269
begin the training process
begin epoch : 1
nll_loss: 36.286273444571144
begin epoch : 2
nll_loss: 27.06266782341934
begin epoch : 3
nll_loss: 24.631023290680677
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.48518406472555
begin epoch : 5
nll_loss: 23.18317273767983
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2037
begin the training process
begin epoch : 1
nll_loss: 42.62232405139554
begin epoch : 2
nll_loss: 34.73376969368227
begin epoch : 3
nll_loss: 30.912959621798606
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.06207976802703
begin epoch : 5
nll_loss: 28.587211547359342
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2314
begin the training process
begin epoch : 1
nll_loss: 42.7144660949707
begin epoch : 2
nll_loss: 34.24531947241889
begin epoch : 3
nll_loss: 30.052498552534317
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.502670023176407
begin epoch : 5
nll_loss: 28.161231411827934
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 37609
begin the training process
begin epoch : 1
nll_loss: 24.824526109321763
begin epoch : 2
nll_loss: 20.02275238167082
begin epoch : 3
nll_loss: 19.56483373040844
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.34798332292339
begin epoch : 5
nll_loss: 19.308727465861903
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5052
begin the training process
begin epoch : 1
nll_loss: 38.01222192324125
begin epoch : 2
nll_loss: 28.4003322552412
begin epoch : 3
nll_loss: 26.060266421391415
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.962427139282227
begin epoch : 5
nll_loss: 24.674098944052673
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 11018
begin the training process
begin epoch : 1
nll_loss: 31.297013349311296
begin epoch : 2
nll_loss: 23.319991566414057
begin epoch : 3
nll_loss: 21.451049959936807
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.762902215469715
begin epoch : 5
nll_loss: 20.61747009809627
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3311
begin the training process
begin epoch : 1
nll_loss: 40.15887668086033
begin epoch : 2
nll_loss: 31.54459108090868
begin epoch : 3
nll_loss: 28.4875716789096
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.51541347129672
begin epoch : 5
nll_loss: 27.236028933057597
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 11296
begin the training process
begin epoch : 1
nll_loss: 33.420208822597154
begin epoch : 2
nll_loss: 25.901897061954845
begin epoch : 3
nll_loss: 23.93884032422846
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.06049972230738
begin epoch : 5
nll_loss: 22.870674295858905
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2874
begin the training process
begin epoch : 1
nll_loss: 41.77703996138139
begin epoch : 2
nll_loss: 32.68950921838934
begin epoch : 3
nll_loss: 29.300710678100586
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.320057088678535
begin epoch : 5
nll_loss: 28.071578415957365
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2327
begin the training process
begin epoch : 1
nll_loss: 42.18273459540473
begin epoch : 2
nll_loss: 33.86773490905762
begin epoch : 3
nll_loss: 30.60999568303426
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.516887664794922
begin epoch : 5
nll_loss: 29.172514491611057
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2273
begin the training process
begin epoch : 1
nll_loss: 42.861556025913785
begin epoch : 2
nll_loss: 34.4518935067313
begin epoch : 3
nll_loss: 30.175769914899554
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.79732142857143
begin epoch : 5
nll_loss: 28.547733579363143
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6556
begin the training process
begin epoch : 1
nll_loss: 35.17140695160511
begin epoch : 2
nll_loss: 26.777124722798664
begin epoch : 3
nll_loss: 24.594924403171913
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.65043888840021
begin epoch : 5
nll_loss: 23.39477492313759
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 34539
begin the training process
begin epoch : 1
nll_loss: 26.466737251777154
begin epoch : 2
nll_loss: 21.06559437413826
begin epoch : 3
nll_loss: 20.040508199490066
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.54710752667655
begin epoch : 5
nll_loss: 19.427352339084603
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5424
begin the training process
begin epoch : 1
nll_loss: 37.8007227125622
begin epoch : 2
nll_loss: 28.94591697057088
begin epoch : 3
nll_loss: 26.55536762873332
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.5787110101609
begin epoch : 5
nll_loss: 25.328198455628893
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 14853
begin the training process
begin epoch : 1
nll_loss: 30.160211061609203
begin epoch : 2
nll_loss: 23.426684001396442
begin epoch : 3
nll_loss: 21.823485859509173
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.252516688971685
begin epoch : 5
nll_loss: 21.126136771563825
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2253
begin the training process
begin epoch : 1
nll_loss: 43.212957218715125
begin epoch : 2
nll_loss: 35.33481946672712
begin epoch : 3
nll_loss: 31.72198976789202
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.381122044154576
begin epoch : 5
nll_loss: 30.024307904924665
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2888
begin the training process
begin epoch : 1
nll_loss: 41.02897669474284
begin epoch : 2
nll_loss: 32.47638104756673
begin epoch : 3
nll_loss: 28.943255954318577
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.829801898532445
begin epoch : 5
nll_loss: 27.48669670952691
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5250
begin the training process
begin epoch : 1
nll_loss: 38.19465048720197
begin epoch : 2
nll_loss: 29.227886479075362
begin epoch : 3
nll_loss: 26.84398820923596
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.828380654497845
begin epoch : 5
nll_loss: 25.561308953820205
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3834
begin the training process
begin epoch : 1
nll_loss: 38.64390706207793
begin epoch : 2
nll_loss: 29.104745994179936
begin epoch : 3
nll_loss: 25.916409153049276
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.94702180765443
begin epoch : 5
nll_loss: 24.692020610227424
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 11831
begin the training process
begin epoch : 1
nll_loss: 32.49326968193054
begin epoch : 2
nll_loss: 25.07407716046209
begin epoch : 3
nll_loss: 23.25169406766477
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.584992553876795
begin epoch : 5
nll_loss: 22.44470679241678
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 241556
begin the training process
begin epoch : 1
nll_loss: 20.988889697498912
begin epoch : 2
nll_loss: 16.679550817041846
begin epoch : 3
nll_loss: 15.877861730497731
The learning rate has beed reduced
begin epoch : 4
nll_loss: 15.327043956338127
begin epoch : 5
nll_loss: 15.22287284828837
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 569
begin the training process
begin epoch : 1
nll_loss: 47.279356479644775
begin epoch : 2
nll_loss: 44.35593938827515
begin epoch : 3
nll_loss: 41.109192848205566
The learning rate has beed reduced
begin epoch : 4
nll_loss: 39.022751808166504
begin epoch : 5
nll_loss: 38.57996892929077
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 35421
begin the training process
begin epoch : 1
nll_loss: 26.54885365863821
begin epoch : 2
nll_loss: 21.58622238131587
begin epoch : 3
nll_loss: 20.95336111113564
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.660782712277623
begin epoch : 5
nll_loss: 20.603337962200584
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 810
begin the training process
begin epoch : 1
nll_loss: 46.155893325805664
begin epoch : 2
nll_loss: 41.39746348063151
begin epoch : 3
nll_loss: 36.958450635274254
The learning rate has beed reduced
begin epoch : 4
nll_loss: 35.30327161153158
begin epoch : 5
nll_loss: 34.89326254526774
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5448
begin the training process
begin epoch : 1
nll_loss: 36.290922838098865
begin epoch : 2
nll_loss: 26.833692460901595
begin epoch : 3
nll_loss: 24.34017084907083
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.209971394258385
begin epoch : 5
nll_loss: 22.909113020055436
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 45856
begin the training process
begin epoch : 1
nll_loss: 24.641045682257115
begin epoch : 2
nll_loss: 20.122918150278444
begin epoch : 3
nll_loss: 19.703877867267117
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.498673212594827
begin epoch : 5
nll_loss: 19.462424086458856
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 48422
begin the training process
begin epoch : 1
nll_loss: 23.36818551764917
begin epoch : 2
nll_loss: 19.66230329886946
begin epoch : 3
nll_loss: 19.380007097960778
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.203560195902668
begin epoch : 5
nll_loss: 19.17233136091283
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 621
begin the training process
begin epoch : 1
nll_loss: 47.74588097466363
begin epoch : 2
nll_loss: 44.155944400363495
begin epoch : 3
nll_loss: 40.210542890760635
The learning rate has beed reduced
begin epoch : 4
nll_loss: 38.3457162645128
begin epoch : 5
nll_loss: 37.985527462429474
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5033
begin the training process
begin epoch : 1
nll_loss: 35.81529607528295
begin epoch : 2
nll_loss: 26.420864276396923
begin epoch : 3
nll_loss: 24.004392868433243
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.142690536303398
begin epoch : 5
nll_loss: 22.891992886861164
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 546511
begin the training process
begin epoch : 1
nll_loss: 21.609425190363712
begin epoch : 2
nll_loss: 20.76619973737192
begin epoch : 3
nll_loss: 20.544379852041175
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.30595033120489
begin epoch : 5
nll_loss: 20.254071531062355
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 228869
begin the training process
begin epoch : 1
nll_loss: 21.482095825592143
begin epoch : 2
nll_loss: 20.1839813871405
begin epoch : 3
nll_loss: 20.054569848698524
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.911920429076126
begin epoch : 5
nll_loss: 19.88724028664147
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9594
begin the training process
begin epoch : 1
nll_loss: 32.68895875047517
begin epoch : 2
nll_loss: 24.46014694879519
begin epoch : 3
nll_loss: 22.31256808850589
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.486808418427536
begin epoch : 5
nll_loss: 21.295792010006487
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1810
begin the training process
begin epoch : 1
nll_loss: 43.7985566002982
begin epoch : 2
nll_loss: 36.19813483101981
begin epoch : 3
nll_loss: 32.17211627960205
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.294027192252024
begin epoch : 5
nll_loss: 29.88989496231079
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4936
begin the training process
begin epoch : 1
nll_loss: 36.43292439448369
begin epoch : 2
nll_loss: 27.03384711525657
begin epoch : 3
nll_loss: 24.56365714135108
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.58435633275416
begin epoch : 5
nll_loss: 23.32764462062291
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1391
begin the training process
begin epoch : 1
nll_loss: 44.72264535086496
begin epoch : 2
nll_loss: 38.27388291131882
begin epoch : 3
nll_loss: 34.979686373756046
The learning rate has beed reduced
begin epoch : 4
nll_loss: 33.445619492303756
begin epoch : 5
nll_loss: 32.807572501046316
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 18741
begin the training process
begin epoch : 1
nll_loss: 28.47571631653668
begin epoch : 2
nll_loss: 21.654584087737618
begin epoch : 3
nll_loss: 20.419998025240965
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.05151633040546
begin epoch : 5
nll_loss: 19.973635020321364
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2013
begin the training process
begin epoch : 1
nll_loss: 43.889817637781945
begin epoch : 2
nll_loss: 36.01785524429813
begin epoch : 3
nll_loss: 32.39446609250961
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.860325844057144
begin epoch : 5
nll_loss: 30.482947257257276
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2449
begin the training process
begin epoch : 1
nll_loss: 42.86610492907072
begin epoch : 2
nll_loss: 34.37057831412867
begin epoch : 3
nll_loss: 30.316954964085628
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.990923329403525
begin epoch : 5
nll_loss: 28.687834890265215
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2256
begin the training process
begin epoch : 1
nll_loss: 42.20293524605887
begin epoch : 2
nll_loss: 34.198908833095004
begin epoch : 3
nll_loss: 29.87890614100865
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.354583086286272
begin epoch : 5
nll_loss: 28.08282846723284
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9551
begin the training process
begin epoch : 1
nll_loss: 34.068773730489234
begin epoch : 2
nll_loss: 26.06422632972666
begin epoch : 3
nll_loss: 24.107880445134718
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.291260994520762
begin epoch : 5
nll_loss: 23.082916118954653
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7309
begin the training process
begin epoch : 1
nll_loss: 33.387577977096825
begin epoch : 2
nll_loss: 24.60021105983801
begin epoch : 3
nll_loss: 22.601120614168938
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.771343716403894
begin epoch : 5
nll_loss: 21.551617287752922
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1606
begin the training process
begin epoch : 1
nll_loss: 44.131620178222654
begin epoch : 2
nll_loss: 36.51096618652344
begin epoch : 3
nll_loss: 32.39586647033691
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.60368522644043
begin epoch : 5
nll_loss: 30.156636581420898
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2062
begin the training process
begin epoch : 1
nll_loss: 42.72547662258148
begin epoch : 2
nll_loss: 34.79793953895569
begin epoch : 3
nll_loss: 31.07801628112793
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.70494168996811
begin epoch : 5
nll_loss: 29.336325526237488
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 503073
begin the training process
begin epoch : 1
nll_loss: 22.083317239290583
begin epoch : 2
nll_loss: 20.630366905348296
begin epoch : 3
nll_loss: 20.143211867791095
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.740024880659185
begin epoch : 5
nll_loss: 19.655585987634634
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7737
begin the training process
begin epoch : 1
nll_loss: 33.52311708132426
begin epoch : 2
nll_loss: 25.38475907643636
begin epoch : 3
nll_loss: 23.20468726158142
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.36182443300883
begin epoch : 5
nll_loss: 22.152003733317056
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 258039
begin the training process
begin epoch : 1
nll_loss: 21.486757516920107
begin epoch : 2
nll_loss: 17.812270319689535
begin epoch : 3
nll_loss: 17.025327977753253
The learning rate has beed reduced
begin epoch : 4
nll_loss: 16.467062258359604
begin epoch : 5
nll_loss: 16.361738320409557
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3914
begin the training process
begin epoch : 1
nll_loss: 39.010055604528205
begin epoch : 2
nll_loss: 29.22876886461602
begin epoch : 3
nll_loss: 26.76879294973905
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.958085450969758
begin epoch : 5
nll_loss: 25.715468672455334
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 19736
begin the training process
begin epoch : 1
nll_loss: 27.72569565339522
begin epoch : 2
nll_loss: 21.193636888033385
begin epoch : 3
nll_loss: 20.057896093888715
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.695262048151587
begin epoch : 5
nll_loss: 19.62883966000049
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5467
begin the training process
begin epoch : 1
nll_loss: 35.232464913760914
begin epoch : 2
nll_loss: 26.035625973869774
begin epoch : 3
nll_loss: 23.60420588325052
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.725634967579563
begin epoch : 5
nll_loss: 22.463495276955996
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5170
begin the training process
begin epoch : 1
nll_loss: 36.47517337799072
begin epoch : 2
nll_loss: 26.87832248210907
begin epoch : 3
nll_loss: 24.593495655059815
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.37215130329132
begin epoch : 5
nll_loss: 23.016590857505797
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2445
begin the training process
begin epoch : 1
nll_loss: 43.083153774863796
begin epoch : 2
nll_loss: 34.788656786868444
begin epoch : 3
nll_loss: 30.77349682858116
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.375416153355648
begin epoch : 5
nll_loss: 29.08234355324193
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4849
begin the training process
begin epoch : 1
nll_loss: 38.77519808451335
begin epoch : 2
nll_loss: 29.448219197591147
begin epoch : 3
nll_loss: 26.842446594238282
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.799085388183595
begin epoch : 5
nll_loss: 25.525835520426433
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1943
begin the training process
begin epoch : 1
nll_loss: 43.926800918579104
begin epoch : 2
nll_loss: 36.39399846394857
begin epoch : 3
nll_loss: 32.09597816467285
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.114058367411296
begin epoch : 5
nll_loss: 29.659718449910482
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 709
begin the training process
begin epoch : 1
nll_loss: 46.2052563753995
begin epoch : 2
nll_loss: 41.687129280783914
begin epoch : 3
nll_loss: 37.66514136574485
The learning rate has beed reduced
begin epoch : 4
nll_loss: 35.78961320356889
begin epoch : 5
nll_loss: 35.196567882191054
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2878
begin the training process
begin epoch : 1
nll_loss: 41.30093089017001
begin epoch : 2
nll_loss: 33.10784396258268
begin epoch : 3
nll_loss: 29.0261118628762
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.68613962693648
begin epoch : 5
nll_loss: 27.407630270177666
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 112181
begin the training process
begin epoch : 1
nll_loss: 23.541677709039487
begin epoch : 2
nll_loss: 21.047425208026414
begin epoch : 3
nll_loss: 20.829490094424383
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.663634503813096
begin epoch : 5
nll_loss: 20.63559397170533
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6494
begin the training process
begin epoch : 1
nll_loss: 34.984391486290654
begin epoch : 2
nll_loss: 25.920435877129584
begin epoch : 3
nll_loss: 23.564539711074072
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.611742831692837
begin epoch : 5
nll_loss: 22.33998151344828
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9988
begin the training process
begin epoch : 1
nll_loss: 31.56603881640312
begin epoch : 2
nll_loss: 23.58593112994463
begin epoch : 3
nll_loss: 21.58479294410119
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.859442026187214
begin epoch : 5
nll_loss: 20.69887274962205
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2218
begin the training process
begin epoch : 1
nll_loss: 42.57309689241297
begin epoch : 2
nll_loss: 34.648803262149585
begin epoch : 3
nll_loss: 30.692381185643814
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.12831974029541
begin epoch : 5
nll_loss: 28.80289027270149
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6062
begin the training process
begin epoch : 1
nll_loss: 35.39863044657606
begin epoch : 2
nll_loss: 26.40288012078468
begin epoch : 3
nll_loss: 24.038827733790622
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.045226949326537
begin epoch : 5
nll_loss: 22.76347064971924
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8002
begin the training process
begin epoch : 1
nll_loss: 32.66276577758789
begin epoch : 2
nll_loss: 24.35454556274414
begin epoch : 3
nll_loss: 22.504314208984376
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.75286053466797
begin epoch : 5
nll_loss: 21.55490200805664
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2858
begin the training process
begin epoch : 1
nll_loss: 41.966853315179996
begin epoch : 2
nll_loss: 32.187804135409266
begin epoch : 3
nll_loss: 28.199847524816338
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.18013962832364
begin epoch : 5
nll_loss: 26.89169099114158
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2280
begin the training process
begin epoch : 1
nll_loss: 42.395799255371095
begin epoch : 2
nll_loss: 34.28921078273228
begin epoch : 3
nll_loss: 30.259364863804407
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.584833690098353
begin epoch : 5
nll_loss: 28.27442910330636
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1582
begin the training process
begin epoch : 1
nll_loss: 43.28291050593058
begin epoch : 2
nll_loss: 35.34445651372274
begin epoch : 3
nll_loss: 30.782857418060303
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.64111574490865
begin epoch : 5
nll_loss: 28.104424238204956
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1696
begin the training process
begin epoch : 1
nll_loss: 44.314637697660004
begin epoch : 2
nll_loss: 36.35984142010029
begin epoch : 3
nll_loss: 32.513311899625336
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.81842825962947
begin epoch : 5
nll_loss: 30.380431688748875
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2081
begin the training process
begin epoch : 1
nll_loss: 41.82291221618652
begin epoch : 2
nll_loss: 33.670391857624054
begin epoch : 3
nll_loss: 29.573565423488617
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.89726734161377
begin epoch : 5
nll_loss: 27.54904955625534
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 25376
begin the training process
begin epoch : 1
nll_loss: 26.570260905256173
begin epoch : 2
nll_loss: 20.646276440283266
begin epoch : 3
nll_loss: 19.939081866331776
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.659709232022063
begin epoch : 5
nll_loss: 19.60307474329014
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9149
begin the training process
begin epoch : 1
nll_loss: 34.23065067344988
begin epoch : 2
nll_loss: 26.54285303303893
begin epoch : 3
nll_loss: 24.32384507085236
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.390215672237773
begin epoch : 5
nll_loss: 23.128721626711563
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7973
begin the training process
begin epoch : 1
nll_loss: 33.24172721370574
begin epoch : 2
nll_loss: 25.070274999064782
begin epoch : 3
nll_loss: 23.264591586205267
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.5037097161816
begin epoch : 5
nll_loss: 22.278597800962388
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3472
begin the training process
begin epoch : 1
nll_loss: 40.399123439082395
begin epoch : 2
nll_loss: 31.370298915439182
begin epoch : 3
nll_loss: 28.207157700150102
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.085642885278773
begin epoch : 5
nll_loss: 26.772011085792823
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3284
begin the training process
begin epoch : 1
nll_loss: 40.859477622836245
begin epoch : 2
nll_loss: 31.5977627249325
begin epoch : 3
nll_loss: 28.867336123597386
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.991370967790193
begin epoch : 5
nll_loss: 27.778105081296435
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3429
begin the training process
begin epoch : 1
nll_loss: 39.8305112730782
begin epoch : 2
nll_loss: 31.16205039114322
begin epoch : 3
nll_loss: 27.957018654301482
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.894106091193432
begin epoch : 5
nll_loss: 26.652489392262584
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 47142
begin the training process
begin epoch : 1
nll_loss: 23.859600074913192
begin epoch : 2
nll_loss: 19.85326557314914
begin epoch : 3
nll_loss: 19.558886162612747
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.38227690561958
begin epoch : 5
nll_loss: 19.350708380989406
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 9566
begin the training process
begin epoch : 1
nll_loss: 31.851494833927028
begin epoch : 2
nll_loss: 23.968756118876822
begin epoch : 3
nll_loss: 22.014998365568633
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.083406563573234
begin epoch : 5
nll_loss: 20.88307488204649
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8720
begin the training process
begin epoch : 1
nll_loss: 32.61851083531099
begin epoch : 2
nll_loss: 24.610359654707068
begin epoch : 3
nll_loss: 22.376412195317886
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.42754901156706
begin epoch : 5
nll_loss: 21.200268675299252
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10921
begin the training process
begin epoch : 1
nll_loss: 30.83130449407241
begin epoch : 2
nll_loss: 23.35168528837316
begin epoch : 3
nll_loss: 21.269130897521972
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.569757012759936
begin epoch : 5
nll_loss: 20.429512988819795
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 81306
begin the training process
begin epoch : 1
nll_loss: 23.388694411750855
begin epoch : 2
nll_loss: 20.373393455265074
begin epoch : 3
nll_loss: 20.103628119521254
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.923747728002354
begin epoch : 5
nll_loss: 19.89463227339617
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2697
begin the training process
begin epoch : 1
nll_loss: 42.10440544855027
begin epoch : 2
nll_loss: 33.60844421386719
begin epoch : 3
nll_loss: 29.44597171601795
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.12400486355736
begin epoch : 5
nll_loss: 27.866250583103724
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 22058
begin the training process
begin epoch : 1
nll_loss: 28.586271579875504
begin epoch : 2
nll_loss: 22.609434610189393
begin epoch : 3
nll_loss: 21.60975762300713
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.198733135711315
begin epoch : 5
nll_loss: 21.10773535661919
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1762
begin the training process
begin epoch : 1
nll_loss: 44.6499725624367
begin epoch : 2
nll_loss: 36.545556668882014
begin epoch : 3
nll_loss: 32.06198035346137
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.120479795667862
begin epoch : 5
nll_loss: 29.745645028573495
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5284
begin the training process
begin epoch : 1
nll_loss: 37.346829879574656
begin epoch : 2
nll_loss: 28.762640069170697
begin epoch : 3
nll_loss: 26.43309302446319
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.300975055229372
begin epoch : 5
nll_loss: 24.96601935130794
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 55508
begin the training process
begin epoch : 1
nll_loss: 24.74055447737926
begin epoch : 2
nll_loss: 20.922077174555195
begin epoch : 3
nll_loss: 20.52979682033587
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.319967569089403
begin epoch : 5
nll_loss: 20.282151588519138
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5359
begin the training process
begin epoch : 1
nll_loss: 36.891015018325255
begin epoch : 2
nll_loss: 28.46280173795769
begin epoch : 3
nll_loss: 26.128274136279003
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.016172110316266
begin epoch : 5
nll_loss: 24.673015893223774
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 22807
begin the training process
begin epoch : 1
nll_loss: 27.496220599399525
begin epoch : 2
nll_loss: 21.26540202237247
begin epoch : 3
nll_loss: 20.279561594630895
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.97692949852247
begin epoch : 5
nll_loss: 19.914541673124507
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 544
begin the training process
begin epoch : 1
nll_loss: 47.097519874572754
begin epoch : 2
nll_loss: 44.13780355453491
begin epoch : 3
nll_loss: 40.4937801361084
The learning rate has beed reduced
begin epoch : 4
nll_loss: 38.49016857147217
begin epoch : 5
nll_loss: 37.75316047668457
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 657204
begin the training process
begin epoch : 1
nll_loss: 21.690507336353857
begin epoch : 2
nll_loss: 19.719012884950658
begin epoch : 3
nll_loss: 19.17906311991431
The learning rate has beed reduced
begin epoch : 4
nll_loss: 18.689759819341347
begin epoch : 5
nll_loss: 18.599410868266887
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4798
begin the training process
begin epoch : 1
nll_loss: 36.646265519631875
begin epoch : 2
nll_loss: 26.235213047749287
begin epoch : 3
nll_loss: 23.864387022482383
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.895183382807552
begin epoch : 5
nll_loss: 22.666712425850534
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4125
begin the training process
begin epoch : 1
nll_loss: 38.8615183532238
begin epoch : 2
nll_loss: 30.085263699293137
begin epoch : 3
nll_loss: 27.66911679506302
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.597266107797623
begin epoch : 5
nll_loss: 26.281019061803818
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10188
begin the training process
begin epoch : 1
nll_loss: 32.26301160848366
begin epoch : 2
nll_loss: 25.18414533363198
begin epoch : 3
nll_loss: 22.653506848797107
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.061050391047257
begin epoch : 5
nll_loss: 20.571259180704754
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3163
begin the training process
begin epoch : 1
nll_loss: 41.288568847033446
begin epoch : 2
nll_loss: 32.076542484517
begin epoch : 3
nll_loss: 28.49584349807428
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.442244393484934
begin epoch : 5
nll_loss: 27.134884736975845
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 52103
begin the training process
begin epoch : 1
nll_loss: 24.773454223276648
begin epoch : 2
nll_loss: 20.858228578028573
begin epoch : 3
nll_loss: 20.29680970962862
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.939705858066567
begin epoch : 5
nll_loss: 19.86017504839698
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5352
begin the training process
begin epoch : 1
nll_loss: 36.14231415254524
begin epoch : 2
nll_loss: 26.944064289690502
begin epoch : 3
nll_loss: 24.64392910233463
The learning rate has beed reduced
begin epoch : 4
nll_loss: 23.536618772759496
begin epoch : 5
nll_loss: 23.26379635822342
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 52463
begin the training process
begin epoch : 1
nll_loss: 25.775902434874222
begin epoch : 2
nll_loss: 21.881453307993684
begin epoch : 3
nll_loss: 20.76000880379962
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.956133110037072
begin epoch : 5
nll_loss: 19.72822500002981
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 18026
begin the training process
begin epoch : 1
nll_loss: 28.813473609842863
begin epoch : 2
nll_loss: 22.24344139506384
begin epoch : 3
nll_loss: 20.677457117101053
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.21541937559949
begin epoch : 5
nll_loss: 20.120338168432703
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 23689
begin the training process
begin epoch : 1
nll_loss: 27.252878998421334
begin epoch : 2
nll_loss: 20.995875513231432
begin epoch : 3
nll_loss: 20.06812883841025
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.751732625188055
begin epoch : 5
nll_loss: 19.6833840653703
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3957
begin the training process
begin epoch : 1
nll_loss: 39.39819723660828
begin epoch : 2
nll_loss: 30.736058469678536
begin epoch : 3
nll_loss: 27.83587136815806
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.74796141952765
begin epoch : 5
nll_loss: 26.417600350301775
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2808
begin the training process
begin epoch : 1
nll_loss: 41.544343460437865
begin epoch : 2
nll_loss: 33.32635218598122
begin epoch : 3
nll_loss: 29.76968002319336
The learning rate has beed reduced
begin epoch : 4
nll_loss: 28.52447815828545
begin epoch : 5
nll_loss: 28.245755971864213
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3129
begin the training process
begin epoch : 1
nll_loss: 40.95627419153849
begin epoch : 2
nll_loss: 31.83294427394867
begin epoch : 3
nll_loss: 28.652640740076702
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.74441401163737
begin epoch : 5
nll_loss: 27.53441607952118
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1947
begin the training process
begin epoch : 1
nll_loss: 43.734153747558594
begin epoch : 2
nll_loss: 36.208201217651364
begin epoch : 3
nll_loss: 32.77636375427246
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.173513730367024
begin epoch : 5
nll_loss: 30.749385515848797
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10908
begin the training process
begin epoch : 1
nll_loss: 33.14247018028708
begin epoch : 2
nll_loss: 25.80566193075741
begin epoch : 3
nll_loss: 23.7006010167739
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.866735144222485
begin epoch : 5
nll_loss: 22.6716370863073
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1681
begin the training process
begin epoch : 1
nll_loss: 43.83300297076885
begin epoch : 2
nll_loss: 36.82274847764235
begin epoch : 3
nll_loss: 33.157371080838715
The learning rate has beed reduced
begin epoch : 4
nll_loss: 31.121149429908165
begin epoch : 5
nll_loss: 30.526855615469124
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1999
begin the training process
begin epoch : 1
nll_loss: 42.43925069993542
begin epoch : 2
nll_loss: 34.39723919283959
begin epoch : 3
nll_loss: 29.927446180774318
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.790541925737934
begin epoch : 5
nll_loss: 27.33720108770555
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1529
begin the training process
begin epoch : 1
nll_loss: 43.81155611121136
begin epoch : 2
nll_loss: 35.82999569436778
begin epoch : 3
nll_loss: 31.952624113663383
The learning rate has beed reduced
begin epoch : 4
nll_loss: 30.04062785273013
begin epoch : 5
nll_loss: 29.535452884176504
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3748
begin the training process
begin epoch : 1
nll_loss: 39.73233203230233
begin epoch : 2
nll_loss: 30.346459520274195
begin epoch : 3
nll_loss: 27.23337311580263
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.262774303041656
begin epoch : 5
nll_loss: 25.99094976227859
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 4444
begin the training process
begin epoch : 1
nll_loss: 39.16120824952056
begin epoch : 2
nll_loss: 29.736273226530656
begin epoch : 3
nll_loss: 27.137277603149414
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.058364232381184
begin epoch : 5
nll_loss: 25.75452544723732
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5046
begin the training process
begin epoch : 1
nll_loss: 38.544130520942886
begin epoch : 2
nll_loss: 28.999656970684345
begin epoch : 3
nll_loss: 26.72779716589512
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.716218972817444
begin epoch : 5
nll_loss: 25.456927372859074
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3521
begin the training process
begin epoch : 1
nll_loss: 39.89403311989524
begin epoch : 2
nll_loss: 30.39350724653764
begin epoch : 3
nll_loss: 27.178631349043414
The learning rate has beed reduced
begin epoch : 4
nll_loss: 26.116635166515003
begin epoch : 5
nll_loss: 25.81117373379794
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 240645
begin the training process
begin epoch : 1
nll_loss: 21.748606580876288
begin epoch : 2
nll_loss: 20.53365805098351
begin epoch : 3
nll_loss: 20.380885513792645
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.215855378292975
begin epoch : 5
nll_loss: 20.18242943489805
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 24946
begin the training process
begin epoch : 1
nll_loss: 28.281855247321044
begin epoch : 2
nll_loss: 22.16914911932075
begin epoch : 3
nll_loss: 21.17547247035951
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.79934934601379
begin epoch : 5
nll_loss: 20.722192828023953
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3464
begin the training process
begin epoch : 1
nll_loss: 40.64348355046025
begin epoch : 2
nll_loss: 31.562645417672616
begin epoch : 3
nll_loss: 28.7187726409347
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.77250530101635
begin epoch : 5
nll_loss: 27.478045569525825
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5408
begin the training process
begin epoch : 1
nll_loss: 37.74159726642427
begin epoch : 2
nll_loss: 28.80644094376337
begin epoch : 3
nll_loss: 26.678338232494536
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.71137455531529
begin epoch : 5
nll_loss: 25.434933594294957
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1961
begin the training process
begin epoch : 1
nll_loss: 43.682626724243164
begin epoch : 2
nll_loss: 36.14095942179362
begin epoch : 3
nll_loss: 31.486719767252605
The learning rate has beed reduced
begin epoch : 4
nll_loss: 29.59498996734619
begin epoch : 5
nll_loss: 29.25343837738037
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 2499
begin the training process
begin epoch : 1
nll_loss: 41.509231763008316
begin epoch : 2
nll_loss: 32.819997298411835
begin epoch : 3
nll_loss: 28.55319076929337
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.24823780548878
begin epoch : 5
nll_loss: 26.979152386005108
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 693
begin the training process
begin epoch : 1
nll_loss: 46.512211608886716
begin epoch : 2
nll_loss: 43.04212646484375
begin epoch : 3
nll_loss: 39.11179618835449
The learning rate has beed reduced
begin epoch : 4
nll_loss: 37.07643814086914
begin epoch : 5
nll_loss: 36.525896072387695
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 7507
begin the training process
begin epoch : 1
nll_loss: 33.91355821006319
begin epoch : 2
nll_loss: 25.513563270242805
begin epoch : 3
nll_loss: 23.317145290537777
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.516737196180557
begin epoch : 5
nll_loss: 22.277726915147568
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 8005
begin the training process
begin epoch : 1
nll_loss: 33.479634841918944
begin epoch : 2
nll_loss: 25.13812028503418
begin epoch : 3
nll_loss: 22.695082168579102
The learning rate has beed reduced
begin epoch : 4
nll_loss: 21.711950378417967
begin epoch : 5
nll_loss: 21.47104557800293
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 6002
begin the training process
begin epoch : 1
nll_loss: 36.31016665633007
begin epoch : 2
nll_loss: 27.664566450221564
begin epoch : 3
nll_loss: 25.301667715913506
The learning rate has beed reduced
begin epoch : 4
nll_loss: 24.247485991447203
begin epoch : 5
nll_loss: 23.965159446962417
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 97724
begin the training process
begin epoch : 1
nll_loss: 21.771643679857565
begin epoch : 2
nll_loss: 19.3662712727118
begin epoch : 3
nll_loss: 19.21137577646838
The learning rate has beed reduced
begin epoch : 4
nll_loss: 19.072751826415054
begin epoch : 5
nll_loss: 19.049787861335325
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 19883
begin the training process
begin epoch : 1
nll_loss: 28.65481428946218
begin epoch : 2
nll_loss: 22.21422603976342
begin epoch : 3
nll_loss: 21.10666540822675
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.697695572145523
begin epoch : 5
nll_loss: 20.601330326449485
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 1437
begin the training process
begin epoch : 1
nll_loss: 45.97402156483043
begin epoch : 2
nll_loss: 37.796415155584164
begin epoch : 3
nll_loss: 34.30746988816695
The learning rate has beed reduced
begin epoch : 4
nll_loss: 32.6173321984031
begin epoch : 5
nll_loss: 32.040054147893734
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 211
begin the training process
begin epoch : 1
nll_loss: 47.576639811197914
begin epoch : 2
nll_loss: 46.746019999186196
begin epoch : 3
nll_loss: 45.663065592447914
The learning rate has beed reduced
begin epoch : 4
nll_loss: 45.04868698120117
begin epoch : 5
nll_loss: 44.510677337646484
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 10941
begin the training process
begin epoch : 1
nll_loss: 33.03452241560992
begin epoch : 2
nll_loss: 25.58352252735811
begin epoch : 3
nll_loss: 23.72322826385498
The learning rate has beed reduced
begin epoch : 4
nll_loss: 22.935574486676384
begin epoch : 5
nll_loss: 22.76085689769072
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 3285
begin the training process
begin epoch : 1
nll_loss: 41.07719877654431
begin epoch : 2
nll_loss: 31.683089761173022
begin epoch : 3
nll_loss: 28.60120605019962
The learning rate has beed reduced
begin epoch : 4
nll_loss: 27.656319674323587
begin epoch : 5
nll_loss: 27.380879607855103
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 55938
begin the training process
begin epoch : 1
nll_loss: 25.08368250761752
begin epoch : 2
nll_loss: 21.08034701096384
begin epoch : 3
nll_loss: 20.62641151655184
The learning rate has beed reduced
begin epoch : 4
nll_loss: 20.381938137778974
begin epoch : 5
nll_loss: 20.337177929125335
The learning rate has beed reduced
Done training
Have loaded the data, total training seqs : 5225
begin the training process
begin epoch : 1
nll_loss: 37.59537225888099
begin epoch : 2
nll_loss: 28.718379103107218
begin epoch : 3
nll_loss: 26.261379430323473
The learning rate has beed reduced
begin epoch : 4
nll_loss: 25.24574253882891
begin epoch : 5
nll_loss: 24.98646053267114
The learning rate has beed reduced
Done training
